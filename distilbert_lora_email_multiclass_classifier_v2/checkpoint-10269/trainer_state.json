{
  "best_global_step": 10269,
  "best_metric": 0.9670245398773006,
  "best_model_checkpoint": "./distilbert_lora_email_multiclass_classifier_v2\\checkpoint-10269",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 10269,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004869023273931249,
      "grad_norm": 0.5020726323127747,
      "learning_rate": 0.0001996818904794365,
      "loss": 0.5462,
      "step": 50
    },
    {
      "epoch": 0.009738046547862499,
      "grad_norm": 4.340796947479248,
      "learning_rate": 0.0001993572889278411,
      "loss": 0.4486,
      "step": 100
    },
    {
      "epoch": 0.014607069821793748,
      "grad_norm": 1.9161505699157715,
      "learning_rate": 0.00019903268737624569,
      "loss": 0.3342,
      "step": 150
    },
    {
      "epoch": 0.019476093095724997,
      "grad_norm": 0.32863807678222656,
      "learning_rate": 0.00019870808582465025,
      "loss": 0.2688,
      "step": 200
    },
    {
      "epoch": 0.024345116369656247,
      "grad_norm": 0.3870668411254883,
      "learning_rate": 0.00019838348427305485,
      "loss": 0.3785,
      "step": 250
    },
    {
      "epoch": 0.029214139643587496,
      "grad_norm": 3.682255744934082,
      "learning_rate": 0.00019805888272145944,
      "loss": 0.2459,
      "step": 300
    },
    {
      "epoch": 0.03408316291751875,
      "grad_norm": 4.619438171386719,
      "learning_rate": 0.000197734281169864,
      "loss": 0.317,
      "step": 350
    },
    {
      "epoch": 0.038952186191449995,
      "grad_norm": 0.3285713195800781,
      "learning_rate": 0.0001974096796182686,
      "loss": 0.2978,
      "step": 400
    },
    {
      "epoch": 0.04382120946538125,
      "grad_norm": 1.7232129573822021,
      "learning_rate": 0.0001970850780666732,
      "loss": 0.3266,
      "step": 450
    },
    {
      "epoch": 0.04869023273931249,
      "grad_norm": 0.4331020712852478,
      "learning_rate": 0.00019676047651507773,
      "loss": 0.3298,
      "step": 500
    },
    {
      "epoch": 0.053559256013243746,
      "grad_norm": 0.1369490623474121,
      "learning_rate": 0.00019643587496348232,
      "loss": 0.3238,
      "step": 550
    },
    {
      "epoch": 0.05842827928717499,
      "grad_norm": 0.4261898696422577,
      "learning_rate": 0.00019611127341188691,
      "loss": 0.1809,
      "step": 600
    },
    {
      "epoch": 0.06329730256110624,
      "grad_norm": 0.2718597948551178,
      "learning_rate": 0.00019578667186029148,
      "loss": 0.3075,
      "step": 650
    },
    {
      "epoch": 0.0681663258350375,
      "grad_norm": 4.385133266448975,
      "learning_rate": 0.00019546207030869607,
      "loss": 0.2611,
      "step": 700
    },
    {
      "epoch": 0.07303534910896874,
      "grad_norm": 4.009751319885254,
      "learning_rate": 0.00019513746875710067,
      "loss": 0.3475,
      "step": 750
    },
    {
      "epoch": 0.07790437238289999,
      "grad_norm": 0.0564703531563282,
      "learning_rate": 0.00019481286720550523,
      "loss": 0.2012,
      "step": 800
    },
    {
      "epoch": 0.08277339565683124,
      "grad_norm": 2.142505407333374,
      "learning_rate": 0.00019448826565390983,
      "loss": 0.3126,
      "step": 850
    },
    {
      "epoch": 0.0876424189307625,
      "grad_norm": 2.029510021209717,
      "learning_rate": 0.00019416366410231442,
      "loss": 0.2973,
      "step": 900
    },
    {
      "epoch": 0.09251144220469373,
      "grad_norm": 0.3596062958240509,
      "learning_rate": 0.00019383906255071898,
      "loss": 0.2488,
      "step": 950
    },
    {
      "epoch": 0.09738046547862499,
      "grad_norm": 0.07501451671123505,
      "learning_rate": 0.00019351446099912358,
      "loss": 0.3306,
      "step": 1000
    },
    {
      "epoch": 0.10224948875255624,
      "grad_norm": 4.156335353851318,
      "learning_rate": 0.00019318985944752817,
      "loss": 0.284,
      "step": 1050
    },
    {
      "epoch": 0.10711851202648749,
      "grad_norm": 1.9840939044952393,
      "learning_rate": 0.00019286525789593276,
      "loss": 0.2347,
      "step": 1100
    },
    {
      "epoch": 0.11198753530041873,
      "grad_norm": 0.25947538018226624,
      "learning_rate": 0.00019254065634433733,
      "loss": 0.1482,
      "step": 1150
    },
    {
      "epoch": 0.11685655857434998,
      "grad_norm": 0.03804156184196472,
      "learning_rate": 0.00019221605479274192,
      "loss": 0.1678,
      "step": 1200
    },
    {
      "epoch": 0.12172558184828124,
      "grad_norm": 1.828066110610962,
      "learning_rate": 0.00019189145324114651,
      "loss": 0.2424,
      "step": 1250
    },
    {
      "epoch": 0.1265946051222125,
      "grad_norm": 3.0098958015441895,
      "learning_rate": 0.00019156685168955108,
      "loss": 0.1944,
      "step": 1300
    },
    {
      "epoch": 0.13146362839614373,
      "grad_norm": 0.00445729773491621,
      "learning_rate": 0.00019124225013795567,
      "loss": 0.1958,
      "step": 1350
    },
    {
      "epoch": 0.136332651670075,
      "grad_norm": 3.5223474502563477,
      "learning_rate": 0.00019091764858636027,
      "loss": 0.2752,
      "step": 1400
    },
    {
      "epoch": 0.14120167494400623,
      "grad_norm": 5.251436233520508,
      "learning_rate": 0.00019059304703476483,
      "loss": 0.2669,
      "step": 1450
    },
    {
      "epoch": 0.14607069821793747,
      "grad_norm": 0.33100101351737976,
      "learning_rate": 0.00019026844548316943,
      "loss": 0.1519,
      "step": 1500
    },
    {
      "epoch": 0.15093972149186874,
      "grad_norm": 3.992882490158081,
      "learning_rate": 0.00018994384393157402,
      "loss": 0.1816,
      "step": 1550
    },
    {
      "epoch": 0.15580874476579998,
      "grad_norm": 7.6399688720703125,
      "learning_rate": 0.00018961924237997858,
      "loss": 0.2458,
      "step": 1600
    },
    {
      "epoch": 0.16067776803973122,
      "grad_norm": 4.505169868469238,
      "learning_rate": 0.00018929464082838318,
      "loss": 0.1935,
      "step": 1650
    },
    {
      "epoch": 0.16554679131366248,
      "grad_norm": 2.5373289585113525,
      "learning_rate": 0.00018897003927678777,
      "loss": 0.1768,
      "step": 1700
    },
    {
      "epoch": 0.17041581458759372,
      "grad_norm": 2.873872995376587,
      "learning_rate": 0.00018864543772519234,
      "loss": 0.261,
      "step": 1750
    },
    {
      "epoch": 0.175284837861525,
      "grad_norm": 3.735078811645508,
      "learning_rate": 0.00018832083617359693,
      "loss": 0.201,
      "step": 1800
    },
    {
      "epoch": 0.18015386113545623,
      "grad_norm": 2.1963021755218506,
      "learning_rate": 0.00018799623462200152,
      "loss": 0.2139,
      "step": 1850
    },
    {
      "epoch": 0.18502288440938747,
      "grad_norm": 3.548754930496216,
      "learning_rate": 0.0001876716330704061,
      "loss": 0.2631,
      "step": 1900
    },
    {
      "epoch": 0.18989190768331873,
      "grad_norm": 0.18612970411777496,
      "learning_rate": 0.00018734703151881068,
      "loss": 0.2006,
      "step": 1950
    },
    {
      "epoch": 0.19476093095724997,
      "grad_norm": 2.1787383556365967,
      "learning_rate": 0.00018702242996721527,
      "loss": 0.1907,
      "step": 2000
    },
    {
      "epoch": 0.1996299542311812,
      "grad_norm": 3.988905191421509,
      "learning_rate": 0.00018669782841561984,
      "loss": 0.2585,
      "step": 2050
    },
    {
      "epoch": 0.20449897750511248,
      "grad_norm": 3.1954877376556396,
      "learning_rate": 0.0001863732268640244,
      "loss": 0.2268,
      "step": 2100
    },
    {
      "epoch": 0.20936800077904372,
      "grad_norm": 0.11408567428588867,
      "learning_rate": 0.000186048625312429,
      "loss": 0.1826,
      "step": 2150
    },
    {
      "epoch": 0.21423702405297498,
      "grad_norm": 4.191470146179199,
      "learning_rate": 0.00018572402376083356,
      "loss": 0.221,
      "step": 2200
    },
    {
      "epoch": 0.21910604732690622,
      "grad_norm": 3.4700064659118652,
      "learning_rate": 0.00018539942220923816,
      "loss": 0.1847,
      "step": 2250
    },
    {
      "epoch": 0.22397507060083746,
      "grad_norm": 0.18720988929271698,
      "learning_rate": 0.00018507482065764275,
      "loss": 0.1598,
      "step": 2300
    },
    {
      "epoch": 0.22884409387476873,
      "grad_norm": 0.8378230333328247,
      "learning_rate": 0.00018475021910604732,
      "loss": 0.2479,
      "step": 2350
    },
    {
      "epoch": 0.23371311714869997,
      "grad_norm": 0.035435162484645844,
      "learning_rate": 0.0001844256175544519,
      "loss": 0.1823,
      "step": 2400
    },
    {
      "epoch": 0.23858214042263123,
      "grad_norm": 6.038914203643799,
      "learning_rate": 0.0001841010160028565,
      "loss": 0.2114,
      "step": 2450
    },
    {
      "epoch": 0.24345116369656247,
      "grad_norm": 0.025362528860569,
      "learning_rate": 0.00018377641445126107,
      "loss": 0.2323,
      "step": 2500
    },
    {
      "epoch": 0.2483201869704937,
      "grad_norm": 0.5127596259117126,
      "learning_rate": 0.00018345181289966566,
      "loss": 0.2261,
      "step": 2550
    },
    {
      "epoch": 0.253189210244425,
      "grad_norm": 2.63519549369812,
      "learning_rate": 0.00018312721134807025,
      "loss": 0.2029,
      "step": 2600
    },
    {
      "epoch": 0.2580582335183562,
      "grad_norm": 0.48841139674186707,
      "learning_rate": 0.00018280260979647482,
      "loss": 0.1959,
      "step": 2650
    },
    {
      "epoch": 0.26292725679228746,
      "grad_norm": 4.235299587249756,
      "learning_rate": 0.0001824780082448794,
      "loss": 0.245,
      "step": 2700
    },
    {
      "epoch": 0.2677962800662187,
      "grad_norm": 1.2537410259246826,
      "learning_rate": 0.000182153406693284,
      "loss": 0.1611,
      "step": 2750
    },
    {
      "epoch": 0.27266530334015,
      "grad_norm": 0.3016315698623657,
      "learning_rate": 0.0001818288051416886,
      "loss": 0.2392,
      "step": 2800
    },
    {
      "epoch": 0.27753432661408123,
      "grad_norm": 3.0802948474884033,
      "learning_rate": 0.00018150420359009316,
      "loss": 0.197,
      "step": 2850
    },
    {
      "epoch": 0.28240334988801247,
      "grad_norm": 4.516900539398193,
      "learning_rate": 0.00018117960203849776,
      "loss": 0.1585,
      "step": 2900
    },
    {
      "epoch": 0.2872723731619437,
      "grad_norm": 0.10263089090585709,
      "learning_rate": 0.00018085500048690235,
      "loss": 0.2043,
      "step": 2950
    },
    {
      "epoch": 0.29214139643587494,
      "grad_norm": 0.24313992261886597,
      "learning_rate": 0.00018053039893530692,
      "loss": 0.2039,
      "step": 3000
    },
    {
      "epoch": 0.29701041970980624,
      "grad_norm": 3.1413307189941406,
      "learning_rate": 0.0001802057973837115,
      "loss": 0.217,
      "step": 3050
    },
    {
      "epoch": 0.3018794429837375,
      "grad_norm": 0.03421034663915634,
      "learning_rate": 0.0001798811958321161,
      "loss": 0.1443,
      "step": 3100
    },
    {
      "epoch": 0.3067484662576687,
      "grad_norm": 0.01030429732054472,
      "learning_rate": 0.00017955659428052067,
      "loss": 0.1063,
      "step": 3150
    },
    {
      "epoch": 0.31161748953159996,
      "grad_norm": 0.3231252431869507,
      "learning_rate": 0.00017923199272892526,
      "loss": 0.2492,
      "step": 3200
    },
    {
      "epoch": 0.3164865128055312,
      "grad_norm": 0.15063896775245667,
      "learning_rate": 0.00017890739117732985,
      "loss": 0.2245,
      "step": 3250
    },
    {
      "epoch": 0.32135553607946243,
      "grad_norm": 6.199244976043701,
      "learning_rate": 0.00017858278962573442,
      "loss": 0.1595,
      "step": 3300
    },
    {
      "epoch": 0.32622455935339373,
      "grad_norm": 0.02856016717851162,
      "learning_rate": 0.000178258188074139,
      "loss": 0.1597,
      "step": 3350
    },
    {
      "epoch": 0.33109358262732497,
      "grad_norm": 1.9401929378509521,
      "learning_rate": 0.0001779335865225436,
      "loss": 0.1841,
      "step": 3400
    },
    {
      "epoch": 0.3359626059012562,
      "grad_norm": 0.5824338793754578,
      "learning_rate": 0.00017760898497094817,
      "loss": 0.1505,
      "step": 3450
    },
    {
      "epoch": 0.34083162917518744,
      "grad_norm": 0.1618143916130066,
      "learning_rate": 0.00017728438341935276,
      "loss": 0.1725,
      "step": 3500
    },
    {
      "epoch": 0.3457006524491187,
      "grad_norm": 0.20058754086494446,
      "learning_rate": 0.00017695978186775736,
      "loss": 0.1474,
      "step": 3550
    },
    {
      "epoch": 0.35056967572305,
      "grad_norm": 4.860381126403809,
      "learning_rate": 0.00017663518031616192,
      "loss": 0.1818,
      "step": 3600
    },
    {
      "epoch": 0.3554386989969812,
      "grad_norm": 0.01293440442532301,
      "learning_rate": 0.00017631057876456652,
      "loss": 0.1164,
      "step": 3650
    },
    {
      "epoch": 0.36030772227091246,
      "grad_norm": 4.648614883422852,
      "learning_rate": 0.00017598597721297108,
      "loss": 0.2075,
      "step": 3700
    },
    {
      "epoch": 0.3651767455448437,
      "grad_norm": 1.0224980115890503,
      "learning_rate": 0.00017566137566137565,
      "loss": 0.2354,
      "step": 3750
    },
    {
      "epoch": 0.37004576881877493,
      "grad_norm": 6.763546943664551,
      "learning_rate": 0.00017533677410978024,
      "loss": 0.1737,
      "step": 3800
    },
    {
      "epoch": 0.37491479209270623,
      "grad_norm": 0.09156077355146408,
      "learning_rate": 0.00017501217255818483,
      "loss": 0.1918,
      "step": 3850
    },
    {
      "epoch": 0.37978381536663747,
      "grad_norm": 7.531727313995361,
      "learning_rate": 0.0001746875710065894,
      "loss": 0.2174,
      "step": 3900
    },
    {
      "epoch": 0.3846528386405687,
      "grad_norm": 0.028367118909955025,
      "learning_rate": 0.000174362969454994,
      "loss": 0.1312,
      "step": 3950
    },
    {
      "epoch": 0.38952186191449995,
      "grad_norm": 1.1024008989334106,
      "learning_rate": 0.00017403836790339859,
      "loss": 0.2185,
      "step": 4000
    },
    {
      "epoch": 0.3943908851884312,
      "grad_norm": 4.017037868499756,
      "learning_rate": 0.00017371376635180315,
      "loss": 0.2005,
      "step": 4050
    },
    {
      "epoch": 0.3992599084623624,
      "grad_norm": 0.013017741963267326,
      "learning_rate": 0.00017338916480020774,
      "loss": 0.2004,
      "step": 4100
    },
    {
      "epoch": 0.4041289317362937,
      "grad_norm": 0.24573856592178345,
      "learning_rate": 0.00017306456324861234,
      "loss": 0.1856,
      "step": 4150
    },
    {
      "epoch": 0.40899795501022496,
      "grad_norm": 0.10186515003442764,
      "learning_rate": 0.0001727399616970169,
      "loss": 0.1922,
      "step": 4200
    },
    {
      "epoch": 0.4138669782841562,
      "grad_norm": 0.5903805494308472,
      "learning_rate": 0.0001724153601454215,
      "loss": 0.1332,
      "step": 4250
    },
    {
      "epoch": 0.41873600155808743,
      "grad_norm": 0.1536387950181961,
      "learning_rate": 0.0001720907585938261,
      "loss": 0.2243,
      "step": 4300
    },
    {
      "epoch": 0.4236050248320187,
      "grad_norm": 4.765903949737549,
      "learning_rate": 0.00017176615704223068,
      "loss": 0.1989,
      "step": 4350
    },
    {
      "epoch": 0.42847404810594997,
      "grad_norm": 5.74289608001709,
      "learning_rate": 0.00017144155549063525,
      "loss": 0.1925,
      "step": 4400
    },
    {
      "epoch": 0.4333430713798812,
      "grad_norm": 0.16580995917320251,
      "learning_rate": 0.00017111695393903984,
      "loss": 0.1634,
      "step": 4450
    },
    {
      "epoch": 0.43821209465381245,
      "grad_norm": 0.25259867310523987,
      "learning_rate": 0.00017079235238744443,
      "loss": 0.1991,
      "step": 4500
    },
    {
      "epoch": 0.4430811179277437,
      "grad_norm": 3.083449602127075,
      "learning_rate": 0.000170467750835849,
      "loss": 0.1607,
      "step": 4550
    },
    {
      "epoch": 0.4479501412016749,
      "grad_norm": 0.16725224256515503,
      "learning_rate": 0.0001701431492842536,
      "loss": 0.1709,
      "step": 4600
    },
    {
      "epoch": 0.4528191644756062,
      "grad_norm": 0.1544051468372345,
      "learning_rate": 0.00016981854773265819,
      "loss": 0.1584,
      "step": 4650
    },
    {
      "epoch": 0.45768818774953746,
      "grad_norm": 5.51550817489624,
      "learning_rate": 0.00016949394618106275,
      "loss": 0.1612,
      "step": 4700
    },
    {
      "epoch": 0.4625572110234687,
      "grad_norm": 0.09305446594953537,
      "learning_rate": 0.00016916934462946734,
      "loss": 0.1729,
      "step": 4750
    },
    {
      "epoch": 0.46742623429739993,
      "grad_norm": 5.926943302154541,
      "learning_rate": 0.00016884474307787194,
      "loss": 0.1906,
      "step": 4800
    },
    {
      "epoch": 0.4722952575713312,
      "grad_norm": 0.0019509963458403945,
      "learning_rate": 0.0001685201415262765,
      "loss": 0.194,
      "step": 4850
    },
    {
      "epoch": 0.47716428084526247,
      "grad_norm": 0.05785977840423584,
      "learning_rate": 0.0001681955399746811,
      "loss": 0.1214,
      "step": 4900
    },
    {
      "epoch": 0.4820333041191937,
      "grad_norm": 1.977953553199768,
      "learning_rate": 0.0001678709384230857,
      "loss": 0.3303,
      "step": 4950
    },
    {
      "epoch": 0.48690232739312495,
      "grad_norm": 0.19796667993068695,
      "learning_rate": 0.00016754633687149026,
      "loss": 0.1438,
      "step": 5000
    },
    {
      "epoch": 0.4917713506670562,
      "grad_norm": 0.013983462937176228,
      "learning_rate": 0.00016722173531989485,
      "loss": 0.0833,
      "step": 5050
    },
    {
      "epoch": 0.4966403739409874,
      "grad_norm": 0.7454021573066711,
      "learning_rate": 0.00016689713376829944,
      "loss": 0.2393,
      "step": 5100
    },
    {
      "epoch": 0.5015093972149187,
      "grad_norm": 0.21062058210372925,
      "learning_rate": 0.000166572532216704,
      "loss": 0.1281,
      "step": 5150
    },
    {
      "epoch": 0.50637842048885,
      "grad_norm": 0.006422732956707478,
      "learning_rate": 0.0001662479306651086,
      "loss": 0.2111,
      "step": 5200
    },
    {
      "epoch": 0.5112474437627812,
      "grad_norm": 0.9621927738189697,
      "learning_rate": 0.00016592332911351317,
      "loss": 0.1452,
      "step": 5250
    },
    {
      "epoch": 0.5161164670367124,
      "grad_norm": 0.039616793394088745,
      "learning_rate": 0.00016559872756191773,
      "loss": 0.1847,
      "step": 5300
    },
    {
      "epoch": 0.5209854903106437,
      "grad_norm": 0.21732963621616364,
      "learning_rate": 0.00016527412601032232,
      "loss": 0.142,
      "step": 5350
    },
    {
      "epoch": 0.5258545135845749,
      "grad_norm": 0.06562231481075287,
      "learning_rate": 0.00016494952445872692,
      "loss": 0.1568,
      "step": 5400
    },
    {
      "epoch": 0.5307235368585062,
      "grad_norm": 0.06697734445333481,
      "learning_rate": 0.00016462492290713148,
      "loss": 0.1758,
      "step": 5450
    },
    {
      "epoch": 0.5355925601324374,
      "grad_norm": 0.9026795625686646,
      "learning_rate": 0.00016430032135553608,
      "loss": 0.1487,
      "step": 5500
    },
    {
      "epoch": 0.5404615834063686,
      "grad_norm": 0.10524938255548477,
      "learning_rate": 0.00016397571980394067,
      "loss": 0.213,
      "step": 5550
    },
    {
      "epoch": 0.5453306066803,
      "grad_norm": 1.4029422998428345,
      "learning_rate": 0.00016365111825234524,
      "loss": 0.1838,
      "step": 5600
    },
    {
      "epoch": 0.5501996299542312,
      "grad_norm": 1.7401328086853027,
      "learning_rate": 0.00016332651670074983,
      "loss": 0.0558,
      "step": 5650
    },
    {
      "epoch": 0.5550686532281625,
      "grad_norm": 0.4831448495388031,
      "learning_rate": 0.00016300191514915442,
      "loss": 0.1334,
      "step": 5700
    },
    {
      "epoch": 0.5599376765020937,
      "grad_norm": 0.0774197205901146,
      "learning_rate": 0.000162677313597559,
      "loss": 0.103,
      "step": 5750
    },
    {
      "epoch": 0.5648066997760249,
      "grad_norm": 0.14664986729621887,
      "learning_rate": 0.00016235271204596358,
      "loss": 0.2193,
      "step": 5800
    },
    {
      "epoch": 0.5696757230499562,
      "grad_norm": 4.7449870109558105,
      "learning_rate": 0.00016202811049436817,
      "loss": 0.2374,
      "step": 5850
    },
    {
      "epoch": 0.5745447463238874,
      "grad_norm": 0.3313435912132263,
      "learning_rate": 0.00016170350894277277,
      "loss": 0.1155,
      "step": 5900
    },
    {
      "epoch": 0.5794137695978187,
      "grad_norm": 0.0807417780160904,
      "learning_rate": 0.00016137890739117733,
      "loss": 0.1604,
      "step": 5950
    },
    {
      "epoch": 0.5842827928717499,
      "grad_norm": 0.2653450071811676,
      "learning_rate": 0.00016105430583958192,
      "loss": 0.2017,
      "step": 6000
    },
    {
      "epoch": 0.5891518161456811,
      "grad_norm": 2.991978406906128,
      "learning_rate": 0.00016072970428798652,
      "loss": 0.2484,
      "step": 6050
    },
    {
      "epoch": 0.5940208394196125,
      "grad_norm": 0.19129310548305511,
      "learning_rate": 0.00016040510273639108,
      "loss": 0.1885,
      "step": 6100
    },
    {
      "epoch": 0.5988898626935437,
      "grad_norm": 7.246367454528809,
      "learning_rate": 0.00016008050118479568,
      "loss": 0.1748,
      "step": 6150
    },
    {
      "epoch": 0.603758885967475,
      "grad_norm": 0.3700542449951172,
      "learning_rate": 0.00015975589963320027,
      "loss": 0.155,
      "step": 6200
    },
    {
      "epoch": 0.6086279092414062,
      "grad_norm": 0.016028577461838722,
      "learning_rate": 0.00015943129808160484,
      "loss": 0.1611,
      "step": 6250
    },
    {
      "epoch": 0.6134969325153374,
      "grad_norm": 0.2081301361322403,
      "learning_rate": 0.00015910669653000943,
      "loss": 0.227,
      "step": 6300
    },
    {
      "epoch": 0.6183659557892687,
      "grad_norm": 5.097681522369385,
      "learning_rate": 0.00015878209497841402,
      "loss": 0.1561,
      "step": 6350
    },
    {
      "epoch": 0.6232349790631999,
      "grad_norm": 2.571794271469116,
      "learning_rate": 0.0001584574934268186,
      "loss": 0.2058,
      "step": 6400
    },
    {
      "epoch": 0.6281040023371312,
      "grad_norm": 2.6688098907470703,
      "learning_rate": 0.00015813289187522318,
      "loss": 0.1465,
      "step": 6450
    },
    {
      "epoch": 0.6329730256110624,
      "grad_norm": 0.014929240569472313,
      "learning_rate": 0.00015780829032362777,
      "loss": 0.1049,
      "step": 6500
    },
    {
      "epoch": 0.6378420488849936,
      "grad_norm": 0.506626546382904,
      "learning_rate": 0.00015748368877203234,
      "loss": 0.1537,
      "step": 6550
    },
    {
      "epoch": 0.6427110721589249,
      "grad_norm": 0.14072392880916595,
      "learning_rate": 0.00015715908722043693,
      "loss": 0.1646,
      "step": 6600
    },
    {
      "epoch": 0.6475800954328562,
      "grad_norm": 0.16166236996650696,
      "learning_rate": 0.00015683448566884152,
      "loss": 0.1466,
      "step": 6650
    },
    {
      "epoch": 0.6524491187067875,
      "grad_norm": 0.11819420009851456,
      "learning_rate": 0.0001565098841172461,
      "loss": 0.1657,
      "step": 6700
    },
    {
      "epoch": 0.6573181419807187,
      "grad_norm": 0.05490690469741821,
      "learning_rate": 0.00015618528256565068,
      "loss": 0.1756,
      "step": 6750
    },
    {
      "epoch": 0.6621871652546499,
      "grad_norm": 0.14420707523822784,
      "learning_rate": 0.00015586068101405528,
      "loss": 0.1346,
      "step": 6800
    },
    {
      "epoch": 0.6670561885285812,
      "grad_norm": 0.004882034845650196,
      "learning_rate": 0.00015553607946245982,
      "loss": 0.059,
      "step": 6850
    },
    {
      "epoch": 0.6719252118025124,
      "grad_norm": 0.24763338267803192,
      "learning_rate": 0.0001552114779108644,
      "loss": 0.1629,
      "step": 6900
    },
    {
      "epoch": 0.6767942350764437,
      "grad_norm": 0.01109315361827612,
      "learning_rate": 0.000154886876359269,
      "loss": 0.1128,
      "step": 6950
    },
    {
      "epoch": 0.6816632583503749,
      "grad_norm": 0.02434738166630268,
      "learning_rate": 0.00015456227480767357,
      "loss": 0.1483,
      "step": 7000
    },
    {
      "epoch": 0.6865322816243061,
      "grad_norm": 6.114081382751465,
      "learning_rate": 0.00015423767325607816,
      "loss": 0.1554,
      "step": 7050
    },
    {
      "epoch": 0.6914013048982374,
      "grad_norm": 0.11063014715909958,
      "learning_rate": 0.00015391307170448275,
      "loss": 0.2379,
      "step": 7100
    },
    {
      "epoch": 0.6962703281721687,
      "grad_norm": 6.041334629058838,
      "learning_rate": 0.00015358847015288732,
      "loss": 0.1104,
      "step": 7150
    },
    {
      "epoch": 0.7011393514461,
      "grad_norm": 0.003787245601415634,
      "learning_rate": 0.0001532638686012919,
      "loss": 0.0739,
      "step": 7200
    },
    {
      "epoch": 0.7060083747200312,
      "grad_norm": 3.6740927696228027,
      "learning_rate": 0.0001529392670496965,
      "loss": 0.1922,
      "step": 7250
    },
    {
      "epoch": 0.7108773979939624,
      "grad_norm": 2.6227729320526123,
      "learning_rate": 0.00015261466549810107,
      "loss": 0.096,
      "step": 7300
    },
    {
      "epoch": 0.7157464212678937,
      "grad_norm": 0.23822656273841858,
      "learning_rate": 0.00015229006394650566,
      "loss": 0.1201,
      "step": 7350
    },
    {
      "epoch": 0.7206154445418249,
      "grad_norm": 1.353472113609314,
      "learning_rate": 0.00015196546239491026,
      "loss": 0.1962,
      "step": 7400
    },
    {
      "epoch": 0.7254844678157562,
      "grad_norm": 0.4046362638473511,
      "learning_rate": 0.00015164086084331482,
      "loss": 0.1528,
      "step": 7450
    },
    {
      "epoch": 0.7303534910896874,
      "grad_norm": 0.006981267593801022,
      "learning_rate": 0.00015131625929171942,
      "loss": 0.0509,
      "step": 7500
    },
    {
      "epoch": 0.7352225143636186,
      "grad_norm": 0.017334233969449997,
      "learning_rate": 0.000150991657740124,
      "loss": 0.0954,
      "step": 7550
    },
    {
      "epoch": 0.7400915376375499,
      "grad_norm": 6.108504295349121,
      "learning_rate": 0.0001506670561885286,
      "loss": 0.1336,
      "step": 7600
    },
    {
      "epoch": 0.7449605609114811,
      "grad_norm": 1.2644110918045044,
      "learning_rate": 0.00015034245463693317,
      "loss": 0.2464,
      "step": 7650
    },
    {
      "epoch": 0.7498295841854125,
      "grad_norm": 0.08735877275466919,
      "learning_rate": 0.00015001785308533776,
      "loss": 0.1466,
      "step": 7700
    },
    {
      "epoch": 0.7546986074593437,
      "grad_norm": 0.1725689321756363,
      "learning_rate": 0.00014969325153374235,
      "loss": 0.1845,
      "step": 7750
    },
    {
      "epoch": 0.7595676307332749,
      "grad_norm": 0.10510572791099548,
      "learning_rate": 0.00014936864998214692,
      "loss": 0.121,
      "step": 7800
    },
    {
      "epoch": 0.7644366540072062,
      "grad_norm": 0.22790253162384033,
      "learning_rate": 0.0001490440484305515,
      "loss": 0.2191,
      "step": 7850
    },
    {
      "epoch": 0.7693056772811374,
      "grad_norm": 0.4300120770931244,
      "learning_rate": 0.0001487194468789561,
      "loss": 0.181,
      "step": 7900
    },
    {
      "epoch": 0.7741747005550687,
      "grad_norm": 0.15645889937877655,
      "learning_rate": 0.00014839484532736067,
      "loss": 0.1171,
      "step": 7950
    },
    {
      "epoch": 0.7790437238289999,
      "grad_norm": 0.11238038539886475,
      "learning_rate": 0.00014807024377576526,
      "loss": 0.1882,
      "step": 8000
    },
    {
      "epoch": 0.7839127471029311,
      "grad_norm": 0.24523228406906128,
      "learning_rate": 0.00014774564222416986,
      "loss": 0.1554,
      "step": 8050
    },
    {
      "epoch": 0.7887817703768624,
      "grad_norm": 0.5939401984214783,
      "learning_rate": 0.00014742104067257442,
      "loss": 0.16,
      "step": 8100
    },
    {
      "epoch": 0.7936507936507936,
      "grad_norm": 0.1644219607114792,
      "learning_rate": 0.00014709643912097902,
      "loss": 0.1575,
      "step": 8150
    },
    {
      "epoch": 0.7985198169247248,
      "grad_norm": 1.769766092300415,
      "learning_rate": 0.0001467718375693836,
      "loss": 0.0954,
      "step": 8200
    },
    {
      "epoch": 0.8033888401986562,
      "grad_norm": 0.004425823222845793,
      "learning_rate": 0.00014644723601778817,
      "loss": 0.0672,
      "step": 8250
    },
    {
      "epoch": 0.8082578634725874,
      "grad_norm": 0.041768383234739304,
      "learning_rate": 0.00014612263446619277,
      "loss": 0.1993,
      "step": 8300
    },
    {
      "epoch": 0.8131268867465187,
      "grad_norm": 0.049513038247823715,
      "learning_rate": 0.00014579803291459736,
      "loss": 0.1172,
      "step": 8350
    },
    {
      "epoch": 0.8179959100204499,
      "grad_norm": 0.2172282338142395,
      "learning_rate": 0.00014547343136300193,
      "loss": 0.2038,
      "step": 8400
    },
    {
      "epoch": 0.8228649332943812,
      "grad_norm": 3.7592356204986572,
      "learning_rate": 0.0001451488298114065,
      "loss": 0.1542,
      "step": 8450
    },
    {
      "epoch": 0.8277339565683124,
      "grad_norm": 4.799158573150635,
      "learning_rate": 0.00014482422825981108,
      "loss": 0.1604,
      "step": 8500
    },
    {
      "epoch": 0.8326029798422436,
      "grad_norm": 1.933556318283081,
      "learning_rate": 0.00014449962670821565,
      "loss": 0.0899,
      "step": 8550
    },
    {
      "epoch": 0.8374720031161749,
      "grad_norm": 0.7173540592193604,
      "learning_rate": 0.00014417502515662024,
      "loss": 0.1061,
      "step": 8600
    },
    {
      "epoch": 0.8423410263901061,
      "grad_norm": 0.5535163283348083,
      "learning_rate": 0.00014385042360502484,
      "loss": 0.1379,
      "step": 8650
    },
    {
      "epoch": 0.8472100496640373,
      "grad_norm": 0.40769481658935547,
      "learning_rate": 0.0001435258220534294,
      "loss": 0.1514,
      "step": 8700
    },
    {
      "epoch": 0.8520790729379687,
      "grad_norm": 0.017380766570568085,
      "learning_rate": 0.000143201220501834,
      "loss": 0.0658,
      "step": 8750
    },
    {
      "epoch": 0.8569480962118999,
      "grad_norm": 5.170172214508057,
      "learning_rate": 0.0001428766189502386,
      "loss": 0.171,
      "step": 8800
    },
    {
      "epoch": 0.8618171194858312,
      "grad_norm": 0.2707490026950836,
      "learning_rate": 0.00014255201739864315,
      "loss": 0.1275,
      "step": 8850
    },
    {
      "epoch": 0.8666861427597624,
      "grad_norm": 2.8433592319488525,
      "learning_rate": 0.00014222741584704775,
      "loss": 0.2131,
      "step": 8900
    },
    {
      "epoch": 0.8715551660336937,
      "grad_norm": 0.052196189761161804,
      "learning_rate": 0.00014190281429545234,
      "loss": 0.1438,
      "step": 8950
    },
    {
      "epoch": 0.8764241893076249,
      "grad_norm": 0.037723250687122345,
      "learning_rate": 0.0001415782127438569,
      "loss": 0.1244,
      "step": 9000
    },
    {
      "epoch": 0.8812932125815561,
      "grad_norm": 0.029000140726566315,
      "learning_rate": 0.0001412536111922615,
      "loss": 0.1225,
      "step": 9050
    },
    {
      "epoch": 0.8861622358554874,
      "grad_norm": 0.04214491695165634,
      "learning_rate": 0.0001409290096406661,
      "loss": 0.1504,
      "step": 9100
    },
    {
      "epoch": 0.8910312591294186,
      "grad_norm": 0.3220621943473816,
      "learning_rate": 0.00014060440808907069,
      "loss": 0.1954,
      "step": 9150
    },
    {
      "epoch": 0.8959002824033498,
      "grad_norm": 0.24968905746936798,
      "learning_rate": 0.00014027980653747525,
      "loss": 0.1085,
      "step": 9200
    },
    {
      "epoch": 0.9007693056772811,
      "grad_norm": 0.48637309670448303,
      "learning_rate": 0.00013995520498587984,
      "loss": 0.094,
      "step": 9250
    },
    {
      "epoch": 0.9056383289512124,
      "grad_norm": 0.02715534158051014,
      "learning_rate": 0.00013963060343428444,
      "loss": 0.1136,
      "step": 9300
    },
    {
      "epoch": 0.9105073522251437,
      "grad_norm": 0.2803507447242737,
      "learning_rate": 0.000139306001882689,
      "loss": 0.1346,
      "step": 9350
    },
    {
      "epoch": 0.9153763754990749,
      "grad_norm": 0.03536125645041466,
      "learning_rate": 0.0001389814003310936,
      "loss": 0.1602,
      "step": 9400
    },
    {
      "epoch": 0.9202453987730062,
      "grad_norm": 0.04522949457168579,
      "learning_rate": 0.0001386567987794982,
      "loss": 0.1892,
      "step": 9450
    },
    {
      "epoch": 0.9251144220469374,
      "grad_norm": 3.0804097652435303,
      "learning_rate": 0.00013833219722790275,
      "loss": 0.1426,
      "step": 9500
    },
    {
      "epoch": 0.9299834453208686,
      "grad_norm": 2.8787126541137695,
      "learning_rate": 0.00013800759567630735,
      "loss": 0.1258,
      "step": 9550
    },
    {
      "epoch": 0.9348524685947999,
      "grad_norm": 0.10193086415529251,
      "learning_rate": 0.00013768299412471194,
      "loss": 0.1629,
      "step": 9600
    },
    {
      "epoch": 0.9397214918687311,
      "grad_norm": 0.2732335329055786,
      "learning_rate": 0.0001373583925731165,
      "loss": 0.1372,
      "step": 9650
    },
    {
      "epoch": 0.9445905151426623,
      "grad_norm": 3.8624391555786133,
      "learning_rate": 0.0001370337910215211,
      "loss": 0.1376,
      "step": 9700
    },
    {
      "epoch": 0.9494595384165936,
      "grad_norm": 3.566873550415039,
      "learning_rate": 0.0001367091894699257,
      "loss": 0.1506,
      "step": 9750
    },
    {
      "epoch": 0.9543285616905249,
      "grad_norm": 3.188394546508789,
      "learning_rate": 0.00013638458791833026,
      "loss": 0.1279,
      "step": 9800
    },
    {
      "epoch": 0.9591975849644562,
      "grad_norm": 0.7150695323944092,
      "learning_rate": 0.00013605998636673485,
      "loss": 0.1513,
      "step": 9850
    },
    {
      "epoch": 0.9640666082383874,
      "grad_norm": 0.836780846118927,
      "learning_rate": 0.00013573538481513944,
      "loss": 0.1309,
      "step": 9900
    },
    {
      "epoch": 0.9689356315123187,
      "grad_norm": 0.05653085932135582,
      "learning_rate": 0.000135410783263544,
      "loss": 0.1475,
      "step": 9950
    },
    {
      "epoch": 0.9738046547862499,
      "grad_norm": 0.06737629324197769,
      "learning_rate": 0.0001350861817119486,
      "loss": 0.0951,
      "step": 10000
    },
    {
      "epoch": 0.9786736780601811,
      "grad_norm": 0.015336256474256516,
      "learning_rate": 0.00013476158016035317,
      "loss": 0.1443,
      "step": 10050
    },
    {
      "epoch": 0.9835427013341124,
      "grad_norm": 0.06609038263559341,
      "learning_rate": 0.00013443697860875773,
      "loss": 0.1437,
      "step": 10100
    },
    {
      "epoch": 0.9884117246080436,
      "grad_norm": 0.07187248021364212,
      "learning_rate": 0.00013411237705716233,
      "loss": 0.1654,
      "step": 10150
    },
    {
      "epoch": 0.9932807478819748,
      "grad_norm": 0.07881209254264832,
      "learning_rate": 0.00013378777550556692,
      "loss": 0.1213,
      "step": 10200
    },
    {
      "epoch": 0.9981497711559061,
      "grad_norm": 0.027917329221963882,
      "learning_rate": 0.00013346317395397149,
      "loss": 0.099,
      "step": 10250
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9670245398773006,
      "eval_loss": 0.13904884457588196,
      "eval_runtime": 80.3634,
      "eval_samples_per_second": 113.584,
      "eval_steps_per_second": 7.105,
      "step": 10269
    }
  ],
  "logging_steps": 50,
  "max_steps": 30807,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9858698838977976.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
