{
  "best_global_step": 30807,
  "best_metric": 0.9751314636283961,
  "best_model_checkpoint": "./distilbert_lora_email_multiclass_classifier_v2\\checkpoint-30807",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 30807,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004869023273931249,
      "grad_norm": 0.5020726323127747,
      "learning_rate": 0.0001996818904794365,
      "loss": 0.5462,
      "step": 50
    },
    {
      "epoch": 0.009738046547862499,
      "grad_norm": 4.340796947479248,
      "learning_rate": 0.0001993572889278411,
      "loss": 0.4486,
      "step": 100
    },
    {
      "epoch": 0.014607069821793748,
      "grad_norm": 1.9161505699157715,
      "learning_rate": 0.00019903268737624569,
      "loss": 0.3342,
      "step": 150
    },
    {
      "epoch": 0.019476093095724997,
      "grad_norm": 0.32863807678222656,
      "learning_rate": 0.00019870808582465025,
      "loss": 0.2688,
      "step": 200
    },
    {
      "epoch": 0.024345116369656247,
      "grad_norm": 0.3870668411254883,
      "learning_rate": 0.00019838348427305485,
      "loss": 0.3785,
      "step": 250
    },
    {
      "epoch": 0.029214139643587496,
      "grad_norm": 3.682255744934082,
      "learning_rate": 0.00019805888272145944,
      "loss": 0.2459,
      "step": 300
    },
    {
      "epoch": 0.03408316291751875,
      "grad_norm": 4.619438171386719,
      "learning_rate": 0.000197734281169864,
      "loss": 0.317,
      "step": 350
    },
    {
      "epoch": 0.038952186191449995,
      "grad_norm": 0.3285713195800781,
      "learning_rate": 0.0001974096796182686,
      "loss": 0.2978,
      "step": 400
    },
    {
      "epoch": 0.04382120946538125,
      "grad_norm": 1.7232129573822021,
      "learning_rate": 0.0001970850780666732,
      "loss": 0.3266,
      "step": 450
    },
    {
      "epoch": 0.04869023273931249,
      "grad_norm": 0.4331020712852478,
      "learning_rate": 0.00019676047651507773,
      "loss": 0.3298,
      "step": 500
    },
    {
      "epoch": 0.053559256013243746,
      "grad_norm": 0.1369490623474121,
      "learning_rate": 0.00019643587496348232,
      "loss": 0.3238,
      "step": 550
    },
    {
      "epoch": 0.05842827928717499,
      "grad_norm": 0.4261898696422577,
      "learning_rate": 0.00019611127341188691,
      "loss": 0.1809,
      "step": 600
    },
    {
      "epoch": 0.06329730256110624,
      "grad_norm": 0.2718597948551178,
      "learning_rate": 0.00019578667186029148,
      "loss": 0.3075,
      "step": 650
    },
    {
      "epoch": 0.0681663258350375,
      "grad_norm": 4.385133266448975,
      "learning_rate": 0.00019546207030869607,
      "loss": 0.2611,
      "step": 700
    },
    {
      "epoch": 0.07303534910896874,
      "grad_norm": 4.009751319885254,
      "learning_rate": 0.00019513746875710067,
      "loss": 0.3475,
      "step": 750
    },
    {
      "epoch": 0.07790437238289999,
      "grad_norm": 0.0564703531563282,
      "learning_rate": 0.00019481286720550523,
      "loss": 0.2012,
      "step": 800
    },
    {
      "epoch": 0.08277339565683124,
      "grad_norm": 2.142505407333374,
      "learning_rate": 0.00019448826565390983,
      "loss": 0.3126,
      "step": 850
    },
    {
      "epoch": 0.0876424189307625,
      "grad_norm": 2.029510021209717,
      "learning_rate": 0.00019416366410231442,
      "loss": 0.2973,
      "step": 900
    },
    {
      "epoch": 0.09251144220469373,
      "grad_norm": 0.3596062958240509,
      "learning_rate": 0.00019383906255071898,
      "loss": 0.2488,
      "step": 950
    },
    {
      "epoch": 0.09738046547862499,
      "grad_norm": 0.07501451671123505,
      "learning_rate": 0.00019351446099912358,
      "loss": 0.3306,
      "step": 1000
    },
    {
      "epoch": 0.10224948875255624,
      "grad_norm": 4.156335353851318,
      "learning_rate": 0.00019318985944752817,
      "loss": 0.284,
      "step": 1050
    },
    {
      "epoch": 0.10711851202648749,
      "grad_norm": 1.9840939044952393,
      "learning_rate": 0.00019286525789593276,
      "loss": 0.2347,
      "step": 1100
    },
    {
      "epoch": 0.11198753530041873,
      "grad_norm": 0.25947538018226624,
      "learning_rate": 0.00019254065634433733,
      "loss": 0.1482,
      "step": 1150
    },
    {
      "epoch": 0.11685655857434998,
      "grad_norm": 0.03804156184196472,
      "learning_rate": 0.00019221605479274192,
      "loss": 0.1678,
      "step": 1200
    },
    {
      "epoch": 0.12172558184828124,
      "grad_norm": 1.828066110610962,
      "learning_rate": 0.00019189145324114651,
      "loss": 0.2424,
      "step": 1250
    },
    {
      "epoch": 0.1265946051222125,
      "grad_norm": 3.0098958015441895,
      "learning_rate": 0.00019156685168955108,
      "loss": 0.1944,
      "step": 1300
    },
    {
      "epoch": 0.13146362839614373,
      "grad_norm": 0.00445729773491621,
      "learning_rate": 0.00019124225013795567,
      "loss": 0.1958,
      "step": 1350
    },
    {
      "epoch": 0.136332651670075,
      "grad_norm": 3.5223474502563477,
      "learning_rate": 0.00019091764858636027,
      "loss": 0.2752,
      "step": 1400
    },
    {
      "epoch": 0.14120167494400623,
      "grad_norm": 5.251436233520508,
      "learning_rate": 0.00019059304703476483,
      "loss": 0.2669,
      "step": 1450
    },
    {
      "epoch": 0.14607069821793747,
      "grad_norm": 0.33100101351737976,
      "learning_rate": 0.00019026844548316943,
      "loss": 0.1519,
      "step": 1500
    },
    {
      "epoch": 0.15093972149186874,
      "grad_norm": 3.992882490158081,
      "learning_rate": 0.00018994384393157402,
      "loss": 0.1816,
      "step": 1550
    },
    {
      "epoch": 0.15580874476579998,
      "grad_norm": 7.6399688720703125,
      "learning_rate": 0.00018961924237997858,
      "loss": 0.2458,
      "step": 1600
    },
    {
      "epoch": 0.16067776803973122,
      "grad_norm": 4.505169868469238,
      "learning_rate": 0.00018929464082838318,
      "loss": 0.1935,
      "step": 1650
    },
    {
      "epoch": 0.16554679131366248,
      "grad_norm": 2.5373289585113525,
      "learning_rate": 0.00018897003927678777,
      "loss": 0.1768,
      "step": 1700
    },
    {
      "epoch": 0.17041581458759372,
      "grad_norm": 2.873872995376587,
      "learning_rate": 0.00018864543772519234,
      "loss": 0.261,
      "step": 1750
    },
    {
      "epoch": 0.175284837861525,
      "grad_norm": 3.735078811645508,
      "learning_rate": 0.00018832083617359693,
      "loss": 0.201,
      "step": 1800
    },
    {
      "epoch": 0.18015386113545623,
      "grad_norm": 2.1963021755218506,
      "learning_rate": 0.00018799623462200152,
      "loss": 0.2139,
      "step": 1850
    },
    {
      "epoch": 0.18502288440938747,
      "grad_norm": 3.548754930496216,
      "learning_rate": 0.0001876716330704061,
      "loss": 0.2631,
      "step": 1900
    },
    {
      "epoch": 0.18989190768331873,
      "grad_norm": 0.18612970411777496,
      "learning_rate": 0.00018734703151881068,
      "loss": 0.2006,
      "step": 1950
    },
    {
      "epoch": 0.19476093095724997,
      "grad_norm": 2.1787383556365967,
      "learning_rate": 0.00018702242996721527,
      "loss": 0.1907,
      "step": 2000
    },
    {
      "epoch": 0.1996299542311812,
      "grad_norm": 3.988905191421509,
      "learning_rate": 0.00018669782841561984,
      "loss": 0.2585,
      "step": 2050
    },
    {
      "epoch": 0.20449897750511248,
      "grad_norm": 3.1954877376556396,
      "learning_rate": 0.0001863732268640244,
      "loss": 0.2268,
      "step": 2100
    },
    {
      "epoch": 0.20936800077904372,
      "grad_norm": 0.11408567428588867,
      "learning_rate": 0.000186048625312429,
      "loss": 0.1826,
      "step": 2150
    },
    {
      "epoch": 0.21423702405297498,
      "grad_norm": 4.191470146179199,
      "learning_rate": 0.00018572402376083356,
      "loss": 0.221,
      "step": 2200
    },
    {
      "epoch": 0.21910604732690622,
      "grad_norm": 3.4700064659118652,
      "learning_rate": 0.00018539942220923816,
      "loss": 0.1847,
      "step": 2250
    },
    {
      "epoch": 0.22397507060083746,
      "grad_norm": 0.18720988929271698,
      "learning_rate": 0.00018507482065764275,
      "loss": 0.1598,
      "step": 2300
    },
    {
      "epoch": 0.22884409387476873,
      "grad_norm": 0.8378230333328247,
      "learning_rate": 0.00018475021910604732,
      "loss": 0.2479,
      "step": 2350
    },
    {
      "epoch": 0.23371311714869997,
      "grad_norm": 0.035435162484645844,
      "learning_rate": 0.0001844256175544519,
      "loss": 0.1823,
      "step": 2400
    },
    {
      "epoch": 0.23858214042263123,
      "grad_norm": 6.038914203643799,
      "learning_rate": 0.0001841010160028565,
      "loss": 0.2114,
      "step": 2450
    },
    {
      "epoch": 0.24345116369656247,
      "grad_norm": 0.025362528860569,
      "learning_rate": 0.00018377641445126107,
      "loss": 0.2323,
      "step": 2500
    },
    {
      "epoch": 0.2483201869704937,
      "grad_norm": 0.5127596259117126,
      "learning_rate": 0.00018345181289966566,
      "loss": 0.2261,
      "step": 2550
    },
    {
      "epoch": 0.253189210244425,
      "grad_norm": 2.63519549369812,
      "learning_rate": 0.00018312721134807025,
      "loss": 0.2029,
      "step": 2600
    },
    {
      "epoch": 0.2580582335183562,
      "grad_norm": 0.48841139674186707,
      "learning_rate": 0.00018280260979647482,
      "loss": 0.1959,
      "step": 2650
    },
    {
      "epoch": 0.26292725679228746,
      "grad_norm": 4.235299587249756,
      "learning_rate": 0.0001824780082448794,
      "loss": 0.245,
      "step": 2700
    },
    {
      "epoch": 0.2677962800662187,
      "grad_norm": 1.2537410259246826,
      "learning_rate": 0.000182153406693284,
      "loss": 0.1611,
      "step": 2750
    },
    {
      "epoch": 0.27266530334015,
      "grad_norm": 0.3016315698623657,
      "learning_rate": 0.0001818288051416886,
      "loss": 0.2392,
      "step": 2800
    },
    {
      "epoch": 0.27753432661408123,
      "grad_norm": 3.0802948474884033,
      "learning_rate": 0.00018150420359009316,
      "loss": 0.197,
      "step": 2850
    },
    {
      "epoch": 0.28240334988801247,
      "grad_norm": 4.516900539398193,
      "learning_rate": 0.00018117960203849776,
      "loss": 0.1585,
      "step": 2900
    },
    {
      "epoch": 0.2872723731619437,
      "grad_norm": 0.10263089090585709,
      "learning_rate": 0.00018085500048690235,
      "loss": 0.2043,
      "step": 2950
    },
    {
      "epoch": 0.29214139643587494,
      "grad_norm": 0.24313992261886597,
      "learning_rate": 0.00018053039893530692,
      "loss": 0.2039,
      "step": 3000
    },
    {
      "epoch": 0.29701041970980624,
      "grad_norm": 3.1413307189941406,
      "learning_rate": 0.0001802057973837115,
      "loss": 0.217,
      "step": 3050
    },
    {
      "epoch": 0.3018794429837375,
      "grad_norm": 0.03421034663915634,
      "learning_rate": 0.0001798811958321161,
      "loss": 0.1443,
      "step": 3100
    },
    {
      "epoch": 0.3067484662576687,
      "grad_norm": 0.01030429732054472,
      "learning_rate": 0.00017955659428052067,
      "loss": 0.1063,
      "step": 3150
    },
    {
      "epoch": 0.31161748953159996,
      "grad_norm": 0.3231252431869507,
      "learning_rate": 0.00017923199272892526,
      "loss": 0.2492,
      "step": 3200
    },
    {
      "epoch": 0.3164865128055312,
      "grad_norm": 0.15063896775245667,
      "learning_rate": 0.00017890739117732985,
      "loss": 0.2245,
      "step": 3250
    },
    {
      "epoch": 0.32135553607946243,
      "grad_norm": 6.199244976043701,
      "learning_rate": 0.00017858278962573442,
      "loss": 0.1595,
      "step": 3300
    },
    {
      "epoch": 0.32622455935339373,
      "grad_norm": 0.02856016717851162,
      "learning_rate": 0.000178258188074139,
      "loss": 0.1597,
      "step": 3350
    },
    {
      "epoch": 0.33109358262732497,
      "grad_norm": 1.9401929378509521,
      "learning_rate": 0.0001779335865225436,
      "loss": 0.1841,
      "step": 3400
    },
    {
      "epoch": 0.3359626059012562,
      "grad_norm": 0.5824338793754578,
      "learning_rate": 0.00017760898497094817,
      "loss": 0.1505,
      "step": 3450
    },
    {
      "epoch": 0.34083162917518744,
      "grad_norm": 0.1618143916130066,
      "learning_rate": 0.00017728438341935276,
      "loss": 0.1725,
      "step": 3500
    },
    {
      "epoch": 0.3457006524491187,
      "grad_norm": 0.20058754086494446,
      "learning_rate": 0.00017695978186775736,
      "loss": 0.1474,
      "step": 3550
    },
    {
      "epoch": 0.35056967572305,
      "grad_norm": 4.860381126403809,
      "learning_rate": 0.00017663518031616192,
      "loss": 0.1818,
      "step": 3600
    },
    {
      "epoch": 0.3554386989969812,
      "grad_norm": 0.01293440442532301,
      "learning_rate": 0.00017631057876456652,
      "loss": 0.1164,
      "step": 3650
    },
    {
      "epoch": 0.36030772227091246,
      "grad_norm": 4.648614883422852,
      "learning_rate": 0.00017598597721297108,
      "loss": 0.2075,
      "step": 3700
    },
    {
      "epoch": 0.3651767455448437,
      "grad_norm": 1.0224980115890503,
      "learning_rate": 0.00017566137566137565,
      "loss": 0.2354,
      "step": 3750
    },
    {
      "epoch": 0.37004576881877493,
      "grad_norm": 6.763546943664551,
      "learning_rate": 0.00017533677410978024,
      "loss": 0.1737,
      "step": 3800
    },
    {
      "epoch": 0.37491479209270623,
      "grad_norm": 0.09156077355146408,
      "learning_rate": 0.00017501217255818483,
      "loss": 0.1918,
      "step": 3850
    },
    {
      "epoch": 0.37978381536663747,
      "grad_norm": 7.531727313995361,
      "learning_rate": 0.0001746875710065894,
      "loss": 0.2174,
      "step": 3900
    },
    {
      "epoch": 0.3846528386405687,
      "grad_norm": 0.028367118909955025,
      "learning_rate": 0.000174362969454994,
      "loss": 0.1312,
      "step": 3950
    },
    {
      "epoch": 0.38952186191449995,
      "grad_norm": 1.1024008989334106,
      "learning_rate": 0.00017403836790339859,
      "loss": 0.2185,
      "step": 4000
    },
    {
      "epoch": 0.3943908851884312,
      "grad_norm": 4.017037868499756,
      "learning_rate": 0.00017371376635180315,
      "loss": 0.2005,
      "step": 4050
    },
    {
      "epoch": 0.3992599084623624,
      "grad_norm": 0.013017741963267326,
      "learning_rate": 0.00017338916480020774,
      "loss": 0.2004,
      "step": 4100
    },
    {
      "epoch": 0.4041289317362937,
      "grad_norm": 0.24573856592178345,
      "learning_rate": 0.00017306456324861234,
      "loss": 0.1856,
      "step": 4150
    },
    {
      "epoch": 0.40899795501022496,
      "grad_norm": 0.10186515003442764,
      "learning_rate": 0.0001727399616970169,
      "loss": 0.1922,
      "step": 4200
    },
    {
      "epoch": 0.4138669782841562,
      "grad_norm": 0.5903805494308472,
      "learning_rate": 0.0001724153601454215,
      "loss": 0.1332,
      "step": 4250
    },
    {
      "epoch": 0.41873600155808743,
      "grad_norm": 0.1536387950181961,
      "learning_rate": 0.0001720907585938261,
      "loss": 0.2243,
      "step": 4300
    },
    {
      "epoch": 0.4236050248320187,
      "grad_norm": 4.765903949737549,
      "learning_rate": 0.00017176615704223068,
      "loss": 0.1989,
      "step": 4350
    },
    {
      "epoch": 0.42847404810594997,
      "grad_norm": 5.74289608001709,
      "learning_rate": 0.00017144155549063525,
      "loss": 0.1925,
      "step": 4400
    },
    {
      "epoch": 0.4333430713798812,
      "grad_norm": 0.16580995917320251,
      "learning_rate": 0.00017111695393903984,
      "loss": 0.1634,
      "step": 4450
    },
    {
      "epoch": 0.43821209465381245,
      "grad_norm": 0.25259867310523987,
      "learning_rate": 0.00017079235238744443,
      "loss": 0.1991,
      "step": 4500
    },
    {
      "epoch": 0.4430811179277437,
      "grad_norm": 3.083449602127075,
      "learning_rate": 0.000170467750835849,
      "loss": 0.1607,
      "step": 4550
    },
    {
      "epoch": 0.4479501412016749,
      "grad_norm": 0.16725224256515503,
      "learning_rate": 0.0001701431492842536,
      "loss": 0.1709,
      "step": 4600
    },
    {
      "epoch": 0.4528191644756062,
      "grad_norm": 0.1544051468372345,
      "learning_rate": 0.00016981854773265819,
      "loss": 0.1584,
      "step": 4650
    },
    {
      "epoch": 0.45768818774953746,
      "grad_norm": 5.51550817489624,
      "learning_rate": 0.00016949394618106275,
      "loss": 0.1612,
      "step": 4700
    },
    {
      "epoch": 0.4625572110234687,
      "grad_norm": 0.09305446594953537,
      "learning_rate": 0.00016916934462946734,
      "loss": 0.1729,
      "step": 4750
    },
    {
      "epoch": 0.46742623429739993,
      "grad_norm": 5.926943302154541,
      "learning_rate": 0.00016884474307787194,
      "loss": 0.1906,
      "step": 4800
    },
    {
      "epoch": 0.4722952575713312,
      "grad_norm": 0.0019509963458403945,
      "learning_rate": 0.0001685201415262765,
      "loss": 0.194,
      "step": 4850
    },
    {
      "epoch": 0.47716428084526247,
      "grad_norm": 0.05785977840423584,
      "learning_rate": 0.0001681955399746811,
      "loss": 0.1214,
      "step": 4900
    },
    {
      "epoch": 0.4820333041191937,
      "grad_norm": 1.977953553199768,
      "learning_rate": 0.0001678709384230857,
      "loss": 0.3303,
      "step": 4950
    },
    {
      "epoch": 0.48690232739312495,
      "grad_norm": 0.19796667993068695,
      "learning_rate": 0.00016754633687149026,
      "loss": 0.1438,
      "step": 5000
    },
    {
      "epoch": 0.4917713506670562,
      "grad_norm": 0.013983462937176228,
      "learning_rate": 0.00016722173531989485,
      "loss": 0.0833,
      "step": 5050
    },
    {
      "epoch": 0.4966403739409874,
      "grad_norm": 0.7454021573066711,
      "learning_rate": 0.00016689713376829944,
      "loss": 0.2393,
      "step": 5100
    },
    {
      "epoch": 0.5015093972149187,
      "grad_norm": 0.21062058210372925,
      "learning_rate": 0.000166572532216704,
      "loss": 0.1281,
      "step": 5150
    },
    {
      "epoch": 0.50637842048885,
      "grad_norm": 0.006422732956707478,
      "learning_rate": 0.0001662479306651086,
      "loss": 0.2111,
      "step": 5200
    },
    {
      "epoch": 0.5112474437627812,
      "grad_norm": 0.9621927738189697,
      "learning_rate": 0.00016592332911351317,
      "loss": 0.1452,
      "step": 5250
    },
    {
      "epoch": 0.5161164670367124,
      "grad_norm": 0.039616793394088745,
      "learning_rate": 0.00016559872756191773,
      "loss": 0.1847,
      "step": 5300
    },
    {
      "epoch": 0.5209854903106437,
      "grad_norm": 0.21732963621616364,
      "learning_rate": 0.00016527412601032232,
      "loss": 0.142,
      "step": 5350
    },
    {
      "epoch": 0.5258545135845749,
      "grad_norm": 0.06562231481075287,
      "learning_rate": 0.00016494952445872692,
      "loss": 0.1568,
      "step": 5400
    },
    {
      "epoch": 0.5307235368585062,
      "grad_norm": 0.06697734445333481,
      "learning_rate": 0.00016462492290713148,
      "loss": 0.1758,
      "step": 5450
    },
    {
      "epoch": 0.5355925601324374,
      "grad_norm": 0.9026795625686646,
      "learning_rate": 0.00016430032135553608,
      "loss": 0.1487,
      "step": 5500
    },
    {
      "epoch": 0.5404615834063686,
      "grad_norm": 0.10524938255548477,
      "learning_rate": 0.00016397571980394067,
      "loss": 0.213,
      "step": 5550
    },
    {
      "epoch": 0.5453306066803,
      "grad_norm": 1.4029422998428345,
      "learning_rate": 0.00016365111825234524,
      "loss": 0.1838,
      "step": 5600
    },
    {
      "epoch": 0.5501996299542312,
      "grad_norm": 1.7401328086853027,
      "learning_rate": 0.00016332651670074983,
      "loss": 0.0558,
      "step": 5650
    },
    {
      "epoch": 0.5550686532281625,
      "grad_norm": 0.4831448495388031,
      "learning_rate": 0.00016300191514915442,
      "loss": 0.1334,
      "step": 5700
    },
    {
      "epoch": 0.5599376765020937,
      "grad_norm": 0.0774197205901146,
      "learning_rate": 0.000162677313597559,
      "loss": 0.103,
      "step": 5750
    },
    {
      "epoch": 0.5648066997760249,
      "grad_norm": 0.14664986729621887,
      "learning_rate": 0.00016235271204596358,
      "loss": 0.2193,
      "step": 5800
    },
    {
      "epoch": 0.5696757230499562,
      "grad_norm": 4.7449870109558105,
      "learning_rate": 0.00016202811049436817,
      "loss": 0.2374,
      "step": 5850
    },
    {
      "epoch": 0.5745447463238874,
      "grad_norm": 0.3313435912132263,
      "learning_rate": 0.00016170350894277277,
      "loss": 0.1155,
      "step": 5900
    },
    {
      "epoch": 0.5794137695978187,
      "grad_norm": 0.0807417780160904,
      "learning_rate": 0.00016137890739117733,
      "loss": 0.1604,
      "step": 5950
    },
    {
      "epoch": 0.5842827928717499,
      "grad_norm": 0.2653450071811676,
      "learning_rate": 0.00016105430583958192,
      "loss": 0.2017,
      "step": 6000
    },
    {
      "epoch": 0.5891518161456811,
      "grad_norm": 2.991978406906128,
      "learning_rate": 0.00016072970428798652,
      "loss": 0.2484,
      "step": 6050
    },
    {
      "epoch": 0.5940208394196125,
      "grad_norm": 0.19129310548305511,
      "learning_rate": 0.00016040510273639108,
      "loss": 0.1885,
      "step": 6100
    },
    {
      "epoch": 0.5988898626935437,
      "grad_norm": 7.246367454528809,
      "learning_rate": 0.00016008050118479568,
      "loss": 0.1748,
      "step": 6150
    },
    {
      "epoch": 0.603758885967475,
      "grad_norm": 0.3700542449951172,
      "learning_rate": 0.00015975589963320027,
      "loss": 0.155,
      "step": 6200
    },
    {
      "epoch": 0.6086279092414062,
      "grad_norm": 0.016028577461838722,
      "learning_rate": 0.00015943129808160484,
      "loss": 0.1611,
      "step": 6250
    },
    {
      "epoch": 0.6134969325153374,
      "grad_norm": 0.2081301361322403,
      "learning_rate": 0.00015910669653000943,
      "loss": 0.227,
      "step": 6300
    },
    {
      "epoch": 0.6183659557892687,
      "grad_norm": 5.097681522369385,
      "learning_rate": 0.00015878209497841402,
      "loss": 0.1561,
      "step": 6350
    },
    {
      "epoch": 0.6232349790631999,
      "grad_norm": 2.571794271469116,
      "learning_rate": 0.0001584574934268186,
      "loss": 0.2058,
      "step": 6400
    },
    {
      "epoch": 0.6281040023371312,
      "grad_norm": 2.6688098907470703,
      "learning_rate": 0.00015813289187522318,
      "loss": 0.1465,
      "step": 6450
    },
    {
      "epoch": 0.6329730256110624,
      "grad_norm": 0.014929240569472313,
      "learning_rate": 0.00015780829032362777,
      "loss": 0.1049,
      "step": 6500
    },
    {
      "epoch": 0.6378420488849936,
      "grad_norm": 0.506626546382904,
      "learning_rate": 0.00015748368877203234,
      "loss": 0.1537,
      "step": 6550
    },
    {
      "epoch": 0.6427110721589249,
      "grad_norm": 0.14072392880916595,
      "learning_rate": 0.00015715908722043693,
      "loss": 0.1646,
      "step": 6600
    },
    {
      "epoch": 0.6475800954328562,
      "grad_norm": 0.16166236996650696,
      "learning_rate": 0.00015683448566884152,
      "loss": 0.1466,
      "step": 6650
    },
    {
      "epoch": 0.6524491187067875,
      "grad_norm": 0.11819420009851456,
      "learning_rate": 0.0001565098841172461,
      "loss": 0.1657,
      "step": 6700
    },
    {
      "epoch": 0.6573181419807187,
      "grad_norm": 0.05490690469741821,
      "learning_rate": 0.00015618528256565068,
      "loss": 0.1756,
      "step": 6750
    },
    {
      "epoch": 0.6621871652546499,
      "grad_norm": 0.14420707523822784,
      "learning_rate": 0.00015586068101405528,
      "loss": 0.1346,
      "step": 6800
    },
    {
      "epoch": 0.6670561885285812,
      "grad_norm": 0.004882034845650196,
      "learning_rate": 0.00015553607946245982,
      "loss": 0.059,
      "step": 6850
    },
    {
      "epoch": 0.6719252118025124,
      "grad_norm": 0.24763338267803192,
      "learning_rate": 0.0001552114779108644,
      "loss": 0.1629,
      "step": 6900
    },
    {
      "epoch": 0.6767942350764437,
      "grad_norm": 0.01109315361827612,
      "learning_rate": 0.000154886876359269,
      "loss": 0.1128,
      "step": 6950
    },
    {
      "epoch": 0.6816632583503749,
      "grad_norm": 0.02434738166630268,
      "learning_rate": 0.00015456227480767357,
      "loss": 0.1483,
      "step": 7000
    },
    {
      "epoch": 0.6865322816243061,
      "grad_norm": 6.114081382751465,
      "learning_rate": 0.00015423767325607816,
      "loss": 0.1554,
      "step": 7050
    },
    {
      "epoch": 0.6914013048982374,
      "grad_norm": 0.11063014715909958,
      "learning_rate": 0.00015391307170448275,
      "loss": 0.2379,
      "step": 7100
    },
    {
      "epoch": 0.6962703281721687,
      "grad_norm": 6.041334629058838,
      "learning_rate": 0.00015358847015288732,
      "loss": 0.1104,
      "step": 7150
    },
    {
      "epoch": 0.7011393514461,
      "grad_norm": 0.003787245601415634,
      "learning_rate": 0.0001532638686012919,
      "loss": 0.0739,
      "step": 7200
    },
    {
      "epoch": 0.7060083747200312,
      "grad_norm": 3.6740927696228027,
      "learning_rate": 0.0001529392670496965,
      "loss": 0.1922,
      "step": 7250
    },
    {
      "epoch": 0.7108773979939624,
      "grad_norm": 2.6227729320526123,
      "learning_rate": 0.00015261466549810107,
      "loss": 0.096,
      "step": 7300
    },
    {
      "epoch": 0.7157464212678937,
      "grad_norm": 0.23822656273841858,
      "learning_rate": 0.00015229006394650566,
      "loss": 0.1201,
      "step": 7350
    },
    {
      "epoch": 0.7206154445418249,
      "grad_norm": 1.353472113609314,
      "learning_rate": 0.00015196546239491026,
      "loss": 0.1962,
      "step": 7400
    },
    {
      "epoch": 0.7254844678157562,
      "grad_norm": 0.4046362638473511,
      "learning_rate": 0.00015164086084331482,
      "loss": 0.1528,
      "step": 7450
    },
    {
      "epoch": 0.7303534910896874,
      "grad_norm": 0.006981267593801022,
      "learning_rate": 0.00015131625929171942,
      "loss": 0.0509,
      "step": 7500
    },
    {
      "epoch": 0.7352225143636186,
      "grad_norm": 0.017334233969449997,
      "learning_rate": 0.000150991657740124,
      "loss": 0.0954,
      "step": 7550
    },
    {
      "epoch": 0.7400915376375499,
      "grad_norm": 6.108504295349121,
      "learning_rate": 0.0001506670561885286,
      "loss": 0.1336,
      "step": 7600
    },
    {
      "epoch": 0.7449605609114811,
      "grad_norm": 1.2644110918045044,
      "learning_rate": 0.00015034245463693317,
      "loss": 0.2464,
      "step": 7650
    },
    {
      "epoch": 0.7498295841854125,
      "grad_norm": 0.08735877275466919,
      "learning_rate": 0.00015001785308533776,
      "loss": 0.1466,
      "step": 7700
    },
    {
      "epoch": 0.7546986074593437,
      "grad_norm": 0.1725689321756363,
      "learning_rate": 0.00014969325153374235,
      "loss": 0.1845,
      "step": 7750
    },
    {
      "epoch": 0.7595676307332749,
      "grad_norm": 0.10510572791099548,
      "learning_rate": 0.00014936864998214692,
      "loss": 0.121,
      "step": 7800
    },
    {
      "epoch": 0.7644366540072062,
      "grad_norm": 0.22790253162384033,
      "learning_rate": 0.0001490440484305515,
      "loss": 0.2191,
      "step": 7850
    },
    {
      "epoch": 0.7693056772811374,
      "grad_norm": 0.4300120770931244,
      "learning_rate": 0.0001487194468789561,
      "loss": 0.181,
      "step": 7900
    },
    {
      "epoch": 0.7741747005550687,
      "grad_norm": 0.15645889937877655,
      "learning_rate": 0.00014839484532736067,
      "loss": 0.1171,
      "step": 7950
    },
    {
      "epoch": 0.7790437238289999,
      "grad_norm": 0.11238038539886475,
      "learning_rate": 0.00014807024377576526,
      "loss": 0.1882,
      "step": 8000
    },
    {
      "epoch": 0.7839127471029311,
      "grad_norm": 0.24523228406906128,
      "learning_rate": 0.00014774564222416986,
      "loss": 0.1554,
      "step": 8050
    },
    {
      "epoch": 0.7887817703768624,
      "grad_norm": 0.5939401984214783,
      "learning_rate": 0.00014742104067257442,
      "loss": 0.16,
      "step": 8100
    },
    {
      "epoch": 0.7936507936507936,
      "grad_norm": 0.1644219607114792,
      "learning_rate": 0.00014709643912097902,
      "loss": 0.1575,
      "step": 8150
    },
    {
      "epoch": 0.7985198169247248,
      "grad_norm": 1.769766092300415,
      "learning_rate": 0.0001467718375693836,
      "loss": 0.0954,
      "step": 8200
    },
    {
      "epoch": 0.8033888401986562,
      "grad_norm": 0.004425823222845793,
      "learning_rate": 0.00014644723601778817,
      "loss": 0.0672,
      "step": 8250
    },
    {
      "epoch": 0.8082578634725874,
      "grad_norm": 0.041768383234739304,
      "learning_rate": 0.00014612263446619277,
      "loss": 0.1993,
      "step": 8300
    },
    {
      "epoch": 0.8131268867465187,
      "grad_norm": 0.049513038247823715,
      "learning_rate": 0.00014579803291459736,
      "loss": 0.1172,
      "step": 8350
    },
    {
      "epoch": 0.8179959100204499,
      "grad_norm": 0.2172282338142395,
      "learning_rate": 0.00014547343136300193,
      "loss": 0.2038,
      "step": 8400
    },
    {
      "epoch": 0.8228649332943812,
      "grad_norm": 3.7592356204986572,
      "learning_rate": 0.0001451488298114065,
      "loss": 0.1542,
      "step": 8450
    },
    {
      "epoch": 0.8277339565683124,
      "grad_norm": 4.799158573150635,
      "learning_rate": 0.00014482422825981108,
      "loss": 0.1604,
      "step": 8500
    },
    {
      "epoch": 0.8326029798422436,
      "grad_norm": 1.933556318283081,
      "learning_rate": 0.00014449962670821565,
      "loss": 0.0899,
      "step": 8550
    },
    {
      "epoch": 0.8374720031161749,
      "grad_norm": 0.7173540592193604,
      "learning_rate": 0.00014417502515662024,
      "loss": 0.1061,
      "step": 8600
    },
    {
      "epoch": 0.8423410263901061,
      "grad_norm": 0.5535163283348083,
      "learning_rate": 0.00014385042360502484,
      "loss": 0.1379,
      "step": 8650
    },
    {
      "epoch": 0.8472100496640373,
      "grad_norm": 0.40769481658935547,
      "learning_rate": 0.0001435258220534294,
      "loss": 0.1514,
      "step": 8700
    },
    {
      "epoch": 0.8520790729379687,
      "grad_norm": 0.017380766570568085,
      "learning_rate": 0.000143201220501834,
      "loss": 0.0658,
      "step": 8750
    },
    {
      "epoch": 0.8569480962118999,
      "grad_norm": 5.170172214508057,
      "learning_rate": 0.0001428766189502386,
      "loss": 0.171,
      "step": 8800
    },
    {
      "epoch": 0.8618171194858312,
      "grad_norm": 0.2707490026950836,
      "learning_rate": 0.00014255201739864315,
      "loss": 0.1275,
      "step": 8850
    },
    {
      "epoch": 0.8666861427597624,
      "grad_norm": 2.8433592319488525,
      "learning_rate": 0.00014222741584704775,
      "loss": 0.2131,
      "step": 8900
    },
    {
      "epoch": 0.8715551660336937,
      "grad_norm": 0.052196189761161804,
      "learning_rate": 0.00014190281429545234,
      "loss": 0.1438,
      "step": 8950
    },
    {
      "epoch": 0.8764241893076249,
      "grad_norm": 0.037723250687122345,
      "learning_rate": 0.0001415782127438569,
      "loss": 0.1244,
      "step": 9000
    },
    {
      "epoch": 0.8812932125815561,
      "grad_norm": 0.029000140726566315,
      "learning_rate": 0.0001412536111922615,
      "loss": 0.1225,
      "step": 9050
    },
    {
      "epoch": 0.8861622358554874,
      "grad_norm": 0.04214491695165634,
      "learning_rate": 0.0001409290096406661,
      "loss": 0.1504,
      "step": 9100
    },
    {
      "epoch": 0.8910312591294186,
      "grad_norm": 0.3220621943473816,
      "learning_rate": 0.00014060440808907069,
      "loss": 0.1954,
      "step": 9150
    },
    {
      "epoch": 0.8959002824033498,
      "grad_norm": 0.24968905746936798,
      "learning_rate": 0.00014027980653747525,
      "loss": 0.1085,
      "step": 9200
    },
    {
      "epoch": 0.9007693056772811,
      "grad_norm": 0.48637309670448303,
      "learning_rate": 0.00013995520498587984,
      "loss": 0.094,
      "step": 9250
    },
    {
      "epoch": 0.9056383289512124,
      "grad_norm": 0.02715534158051014,
      "learning_rate": 0.00013963060343428444,
      "loss": 0.1136,
      "step": 9300
    },
    {
      "epoch": 0.9105073522251437,
      "grad_norm": 0.2803507447242737,
      "learning_rate": 0.000139306001882689,
      "loss": 0.1346,
      "step": 9350
    },
    {
      "epoch": 0.9153763754990749,
      "grad_norm": 0.03536125645041466,
      "learning_rate": 0.0001389814003310936,
      "loss": 0.1602,
      "step": 9400
    },
    {
      "epoch": 0.9202453987730062,
      "grad_norm": 0.04522949457168579,
      "learning_rate": 0.0001386567987794982,
      "loss": 0.1892,
      "step": 9450
    },
    {
      "epoch": 0.9251144220469374,
      "grad_norm": 3.0804097652435303,
      "learning_rate": 0.00013833219722790275,
      "loss": 0.1426,
      "step": 9500
    },
    {
      "epoch": 0.9299834453208686,
      "grad_norm": 2.8787126541137695,
      "learning_rate": 0.00013800759567630735,
      "loss": 0.1258,
      "step": 9550
    },
    {
      "epoch": 0.9348524685947999,
      "grad_norm": 0.10193086415529251,
      "learning_rate": 0.00013768299412471194,
      "loss": 0.1629,
      "step": 9600
    },
    {
      "epoch": 0.9397214918687311,
      "grad_norm": 0.2732335329055786,
      "learning_rate": 0.0001373583925731165,
      "loss": 0.1372,
      "step": 9650
    },
    {
      "epoch": 0.9445905151426623,
      "grad_norm": 3.8624391555786133,
      "learning_rate": 0.0001370337910215211,
      "loss": 0.1376,
      "step": 9700
    },
    {
      "epoch": 0.9494595384165936,
      "grad_norm": 3.566873550415039,
      "learning_rate": 0.0001367091894699257,
      "loss": 0.1506,
      "step": 9750
    },
    {
      "epoch": 0.9543285616905249,
      "grad_norm": 3.188394546508789,
      "learning_rate": 0.00013638458791833026,
      "loss": 0.1279,
      "step": 9800
    },
    {
      "epoch": 0.9591975849644562,
      "grad_norm": 0.7150695323944092,
      "learning_rate": 0.00013605998636673485,
      "loss": 0.1513,
      "step": 9850
    },
    {
      "epoch": 0.9640666082383874,
      "grad_norm": 0.836780846118927,
      "learning_rate": 0.00013573538481513944,
      "loss": 0.1309,
      "step": 9900
    },
    {
      "epoch": 0.9689356315123187,
      "grad_norm": 0.05653085932135582,
      "learning_rate": 0.000135410783263544,
      "loss": 0.1475,
      "step": 9950
    },
    {
      "epoch": 0.9738046547862499,
      "grad_norm": 0.06737629324197769,
      "learning_rate": 0.0001350861817119486,
      "loss": 0.0951,
      "step": 10000
    },
    {
      "epoch": 0.9786736780601811,
      "grad_norm": 0.015336256474256516,
      "learning_rate": 0.00013476158016035317,
      "loss": 0.1443,
      "step": 10050
    },
    {
      "epoch": 0.9835427013341124,
      "grad_norm": 0.06609038263559341,
      "learning_rate": 0.00013443697860875773,
      "loss": 0.1437,
      "step": 10100
    },
    {
      "epoch": 0.9884117246080436,
      "grad_norm": 0.07187248021364212,
      "learning_rate": 0.00013411237705716233,
      "loss": 0.1654,
      "step": 10150
    },
    {
      "epoch": 0.9932807478819748,
      "grad_norm": 0.07881209254264832,
      "learning_rate": 0.00013378777550556692,
      "loss": 0.1213,
      "step": 10200
    },
    {
      "epoch": 0.9981497711559061,
      "grad_norm": 0.027917329221963882,
      "learning_rate": 0.00013346317395397149,
      "loss": 0.099,
      "step": 10250
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9670245398773006,
      "eval_loss": 0.13904884457588196,
      "eval_runtime": 80.3634,
      "eval_samples_per_second": 113.584,
      "eval_steps_per_second": 7.105,
      "step": 10269
    },
    {
      "epoch": 1.0030187944298374,
      "grad_norm": 0.021690096706151962,
      "learning_rate": 0.00013313857240237608,
      "loss": 0.103,
      "step": 10300
    },
    {
      "epoch": 1.0078878177037687,
      "grad_norm": 0.01277091819792986,
      "learning_rate": 0.00013281397085078067,
      "loss": 0.134,
      "step": 10350
    },
    {
      "epoch": 1.0127568409777,
      "grad_norm": 5.379951477050781,
      "learning_rate": 0.00013248936929918524,
      "loss": 0.164,
      "step": 10400
    },
    {
      "epoch": 1.0176258642516312,
      "grad_norm": 6.156336307525635,
      "learning_rate": 0.00013216476774758983,
      "loss": 0.0875,
      "step": 10450
    },
    {
      "epoch": 1.0224948875255624,
      "grad_norm": 0.19793091714382172,
      "learning_rate": 0.00013184016619599442,
      "loss": 0.1313,
      "step": 10500
    },
    {
      "epoch": 1.0273639107994936,
      "grad_norm": 0.04858769103884697,
      "learning_rate": 0.000131515564644399,
      "loss": 0.1483,
      "step": 10550
    },
    {
      "epoch": 1.0322329340734249,
      "grad_norm": 6.176114082336426,
      "learning_rate": 0.00013119096309280358,
      "loss": 0.141,
      "step": 10600
    },
    {
      "epoch": 1.037101957347356,
      "grad_norm": 0.14951840043067932,
      "learning_rate": 0.00013086636154120818,
      "loss": 0.0981,
      "step": 10650
    },
    {
      "epoch": 1.0419709806212873,
      "grad_norm": 5.489030838012695,
      "learning_rate": 0.00013054175998961277,
      "loss": 0.1711,
      "step": 10700
    },
    {
      "epoch": 1.0468400038952186,
      "grad_norm": 5.180001735687256,
      "learning_rate": 0.00013021715843801733,
      "loss": 0.1679,
      "step": 10750
    },
    {
      "epoch": 1.0517090271691498,
      "grad_norm": 0.04673606529831886,
      "learning_rate": 0.00012989255688642193,
      "loss": 0.1289,
      "step": 10800
    },
    {
      "epoch": 1.056578050443081,
      "grad_norm": 3.4728825092315674,
      "learning_rate": 0.00012956795533482652,
      "loss": 0.1409,
      "step": 10850
    },
    {
      "epoch": 1.0614470737170123,
      "grad_norm": 0.06707736104726791,
      "learning_rate": 0.00012924335378323109,
      "loss": 0.1207,
      "step": 10900
    },
    {
      "epoch": 1.0663160969909435,
      "grad_norm": 0.3224714994430542,
      "learning_rate": 0.00012891875223163568,
      "loss": 0.1744,
      "step": 10950
    },
    {
      "epoch": 1.0711851202648748,
      "grad_norm": 0.1640463024377823,
      "learning_rate": 0.00012859415068004027,
      "loss": 0.1445,
      "step": 11000
    },
    {
      "epoch": 1.076054143538806,
      "grad_norm": 2.0685877799987793,
      "learning_rate": 0.00012826954912844484,
      "loss": 0.1007,
      "step": 11050
    },
    {
      "epoch": 1.0809231668127373,
      "grad_norm": 4.802799701690674,
      "learning_rate": 0.00012794494757684943,
      "loss": 0.1561,
      "step": 11100
    },
    {
      "epoch": 1.0857921900866687,
      "grad_norm": 0.055809445679187775,
      "learning_rate": 0.00012762034602525402,
      "loss": 0.1427,
      "step": 11150
    },
    {
      "epoch": 1.0906612133606,
      "grad_norm": 6.204370021820068,
      "learning_rate": 0.0001272957444736586,
      "loss": 0.1583,
      "step": 11200
    },
    {
      "epoch": 1.0955302366345312,
      "grad_norm": 0.7545446157455444,
      "learning_rate": 0.00012697114292206318,
      "loss": 0.1168,
      "step": 11250
    },
    {
      "epoch": 1.1003992599084624,
      "grad_norm": 0.039817824959754944,
      "learning_rate": 0.00012664654137046778,
      "loss": 0.1041,
      "step": 11300
    },
    {
      "epoch": 1.1052682831823937,
      "grad_norm": 0.14496482908725739,
      "learning_rate": 0.00012632193981887234,
      "loss": 0.1001,
      "step": 11350
    },
    {
      "epoch": 1.110137306456325,
      "grad_norm": 0.015796590596437454,
      "learning_rate": 0.00012599733826727693,
      "loss": 0.101,
      "step": 11400
    },
    {
      "epoch": 1.1150063297302562,
      "grad_norm": 2.498575210571289,
      "learning_rate": 0.00012567273671568153,
      "loss": 0.1711,
      "step": 11450
    },
    {
      "epoch": 1.1198753530041874,
      "grad_norm": 0.8079307079315186,
      "learning_rate": 0.0001253481351640861,
      "loss": 0.1519,
      "step": 11500
    },
    {
      "epoch": 1.1247443762781186,
      "grad_norm": 0.5947559475898743,
      "learning_rate": 0.0001250235336124907,
      "loss": 0.0946,
      "step": 11550
    },
    {
      "epoch": 1.1296133995520499,
      "grad_norm": 5.891097068786621,
      "learning_rate": 0.00012469893206089525,
      "loss": 0.1156,
      "step": 11600
    },
    {
      "epoch": 1.134482422825981,
      "grad_norm": 0.053390249609947205,
      "learning_rate": 0.00012437433050929982,
      "loss": 0.1211,
      "step": 11650
    },
    {
      "epoch": 1.1393514460999123,
      "grad_norm": 3.823282480239868,
      "learning_rate": 0.0001240497289577044,
      "loss": 0.1072,
      "step": 11700
    },
    {
      "epoch": 1.1442204693738436,
      "grad_norm": 0.11560961604118347,
      "learning_rate": 0.000123725127406109,
      "loss": 0.1417,
      "step": 11750
    },
    {
      "epoch": 1.1490894926477748,
      "grad_norm": 0.7049930095672607,
      "learning_rate": 0.00012340052585451357,
      "loss": 0.0711,
      "step": 11800
    },
    {
      "epoch": 1.153958515921706,
      "grad_norm": 6.886002063751221,
      "learning_rate": 0.00012307592430291816,
      "loss": 0.1232,
      "step": 11850
    },
    {
      "epoch": 1.1588275391956373,
      "grad_norm": 0.7462264895439148,
      "learning_rate": 0.00012275132275132276,
      "loss": 0.1261,
      "step": 11900
    },
    {
      "epoch": 1.1636965624695685,
      "grad_norm": 0.24279606342315674,
      "learning_rate": 0.00012242672119972732,
      "loss": 0.1352,
      "step": 11950
    },
    {
      "epoch": 1.1685655857434998,
      "grad_norm": 7.814925670623779,
      "learning_rate": 0.00012210211964813191,
      "loss": 0.1359,
      "step": 12000
    },
    {
      "epoch": 1.173434609017431,
      "grad_norm": 0.03138815611600876,
      "learning_rate": 0.00012177751809653651,
      "loss": 0.129,
      "step": 12050
    },
    {
      "epoch": 1.1783036322913623,
      "grad_norm": 0.049384430050849915,
      "learning_rate": 0.00012145291654494109,
      "loss": 0.1127,
      "step": 12100
    },
    {
      "epoch": 1.1831726555652935,
      "grad_norm": 0.3869766294956207,
      "learning_rate": 0.00012112831499334567,
      "loss": 0.1354,
      "step": 12150
    },
    {
      "epoch": 1.188041678839225,
      "grad_norm": 7.7605366706848145,
      "learning_rate": 0.00012080371344175026,
      "loss": 0.1774,
      "step": 12200
    },
    {
      "epoch": 1.1929107021131562,
      "grad_norm": 0.03322892636060715,
      "learning_rate": 0.00012047911189015484,
      "loss": 0.0976,
      "step": 12250
    },
    {
      "epoch": 1.1977797253870874,
      "grad_norm": 0.16265951097011566,
      "learning_rate": 0.00012015451033855942,
      "loss": 0.1508,
      "step": 12300
    },
    {
      "epoch": 1.2026487486610187,
      "grad_norm": 0.011837738566100597,
      "learning_rate": 0.00011982990878696401,
      "loss": 0.1784,
      "step": 12350
    },
    {
      "epoch": 1.20751777193495,
      "grad_norm": 1.9598491191864014,
      "learning_rate": 0.00011950530723536859,
      "loss": 0.1054,
      "step": 12400
    },
    {
      "epoch": 1.2123867952088812,
      "grad_norm": 0.3392914831638336,
      "learning_rate": 0.00011918070568377317,
      "loss": 0.0754,
      "step": 12450
    },
    {
      "epoch": 1.2172558184828124,
      "grad_norm": 0.0940060168504715,
      "learning_rate": 0.00011885610413217776,
      "loss": 0.1613,
      "step": 12500
    },
    {
      "epoch": 1.2221248417567436,
      "grad_norm": 0.11032754927873611,
      "learning_rate": 0.00011853150258058234,
      "loss": 0.1233,
      "step": 12550
    },
    {
      "epoch": 1.2269938650306749,
      "grad_norm": 0.2856519818305969,
      "learning_rate": 0.00011820690102898692,
      "loss": 0.1227,
      "step": 12600
    },
    {
      "epoch": 1.231862888304606,
      "grad_norm": 0.04365531727671623,
      "learning_rate": 0.00011788229947739151,
      "loss": 0.1339,
      "step": 12650
    },
    {
      "epoch": 1.2367319115785373,
      "grad_norm": 0.016182873398065567,
      "learning_rate": 0.0001175576979257961,
      "loss": 0.0713,
      "step": 12700
    },
    {
      "epoch": 1.2416009348524686,
      "grad_norm": 0.24185936152935028,
      "learning_rate": 0.00011723309637420067,
      "loss": 0.1022,
      "step": 12750
    },
    {
      "epoch": 1.2464699581263998,
      "grad_norm": 0.03140754997730255,
      "learning_rate": 0.00011690849482260527,
      "loss": 0.0546,
      "step": 12800
    },
    {
      "epoch": 1.251338981400331,
      "grad_norm": 7.876496315002441,
      "learning_rate": 0.00011658389327100985,
      "loss": 0.1697,
      "step": 12850
    },
    {
      "epoch": 1.2562080046742623,
      "grad_norm": 0.047209326177835464,
      "learning_rate": 0.00011625929171941443,
      "loss": 0.1378,
      "step": 12900
    },
    {
      "epoch": 1.2610770279481935,
      "grad_norm": 0.010168462060391903,
      "learning_rate": 0.00011593469016781902,
      "loss": 0.1248,
      "step": 12950
    },
    {
      "epoch": 1.2659460512221248,
      "grad_norm": 1.0396586656570435,
      "learning_rate": 0.0001156100886162236,
      "loss": 0.1016,
      "step": 13000
    },
    {
      "epoch": 1.270815074496056,
      "grad_norm": 0.17535120248794556,
      "learning_rate": 0.00011528548706462818,
      "loss": 0.0811,
      "step": 13050
    },
    {
      "epoch": 1.2756840977699873,
      "grad_norm": 2.0994679927825928,
      "learning_rate": 0.00011496088551303277,
      "loss": 0.1412,
      "step": 13100
    },
    {
      "epoch": 1.2805531210439187,
      "grad_norm": 0.003170436481013894,
      "learning_rate": 0.00011463628396143735,
      "loss": 0.0923,
      "step": 13150
    },
    {
      "epoch": 1.2854221443178497,
      "grad_norm": 3.8612587451934814,
      "learning_rate": 0.00011431168240984192,
      "loss": 0.2567,
      "step": 13200
    },
    {
      "epoch": 1.2902911675917812,
      "grad_norm": 2.427999258041382,
      "learning_rate": 0.0001139870808582465,
      "loss": 0.1375,
      "step": 13250
    },
    {
      "epoch": 1.2951601908657122,
      "grad_norm": 4.382237911224365,
      "learning_rate": 0.00011366247930665109,
      "loss": 0.1509,
      "step": 13300
    },
    {
      "epoch": 1.3000292141396437,
      "grad_norm": 0.09832976758480072,
      "learning_rate": 0.00011333787775505567,
      "loss": 0.0959,
      "step": 13350
    },
    {
      "epoch": 1.304898237413575,
      "grad_norm": 0.48025164008140564,
      "learning_rate": 0.00011301327620346025,
      "loss": 0.1242,
      "step": 13400
    },
    {
      "epoch": 1.3097672606875062,
      "grad_norm": 2.084824323654175,
      "learning_rate": 0.00011268867465186484,
      "loss": 0.1829,
      "step": 13450
    },
    {
      "epoch": 1.3146362839614374,
      "grad_norm": 4.43394660949707,
      "learning_rate": 0.00011236407310026942,
      "loss": 0.1085,
      "step": 13500
    },
    {
      "epoch": 1.3195053072353686,
      "grad_norm": 1.8469526767730713,
      "learning_rate": 0.000112039471548674,
      "loss": 0.1093,
      "step": 13550
    },
    {
      "epoch": 1.3243743305092999,
      "grad_norm": 0.11444120854139328,
      "learning_rate": 0.00011171486999707859,
      "loss": 0.1148,
      "step": 13600
    },
    {
      "epoch": 1.329243353783231,
      "grad_norm": 0.030574221163988113,
      "learning_rate": 0.00011139026844548317,
      "loss": 0.1213,
      "step": 13650
    },
    {
      "epoch": 1.3341123770571623,
      "grad_norm": 0.10856929421424866,
      "learning_rate": 0.00011106566689388775,
      "loss": 0.1241,
      "step": 13700
    },
    {
      "epoch": 1.3389814003310936,
      "grad_norm": 0.039617057889699936,
      "learning_rate": 0.00011074106534229234,
      "loss": 0.1324,
      "step": 13750
    },
    {
      "epoch": 1.3438504236050248,
      "grad_norm": 0.005136923864483833,
      "learning_rate": 0.00011041646379069692,
      "loss": 0.1786,
      "step": 13800
    },
    {
      "epoch": 1.348719446878956,
      "grad_norm": 0.0037289734464138746,
      "learning_rate": 0.0001100918622391015,
      "loss": 0.1107,
      "step": 13850
    },
    {
      "epoch": 1.3535884701528873,
      "grad_norm": 0.04823588207364082,
      "learning_rate": 0.0001097672606875061,
      "loss": 0.1337,
      "step": 13900
    },
    {
      "epoch": 1.3584574934268185,
      "grad_norm": 0.09850360453128815,
      "learning_rate": 0.00010944265913591067,
      "loss": 0.1816,
      "step": 13950
    },
    {
      "epoch": 1.3633265167007498,
      "grad_norm": 5.009829521179199,
      "learning_rate": 0.00010911805758431525,
      "loss": 0.172,
      "step": 14000
    },
    {
      "epoch": 1.368195539974681,
      "grad_norm": 0.04356569051742554,
      "learning_rate": 0.00010879345603271985,
      "loss": 0.1928,
      "step": 14050
    },
    {
      "epoch": 1.3730645632486123,
      "grad_norm": 0.2247566282749176,
      "learning_rate": 0.00010846885448112443,
      "loss": 0.134,
      "step": 14100
    },
    {
      "epoch": 1.3779335865225435,
      "grad_norm": 4.8854875564575195,
      "learning_rate": 0.000108144252929529,
      "loss": 0.1125,
      "step": 14150
    },
    {
      "epoch": 1.382802609796475,
      "grad_norm": 0.7147636413574219,
      "learning_rate": 0.0001078196513779336,
      "loss": 0.1695,
      "step": 14200
    },
    {
      "epoch": 1.387671633070406,
      "grad_norm": 0.4438174068927765,
      "learning_rate": 0.00010749504982633818,
      "loss": 0.1279,
      "step": 14250
    },
    {
      "epoch": 1.3925406563443374,
      "grad_norm": 4.500607490539551,
      "learning_rate": 0.00010717044827474276,
      "loss": 0.127,
      "step": 14300
    },
    {
      "epoch": 1.3974096796182685,
      "grad_norm": 1.1227399110794067,
      "learning_rate": 0.00010684584672314735,
      "loss": 0.1546,
      "step": 14350
    },
    {
      "epoch": 1.4022787028922,
      "grad_norm": 4.976474761962891,
      "learning_rate": 0.00010652124517155193,
      "loss": 0.089,
      "step": 14400
    },
    {
      "epoch": 1.4071477261661312,
      "grad_norm": 0.08737073838710785,
      "learning_rate": 0.00010619664361995651,
      "loss": 0.1135,
      "step": 14450
    },
    {
      "epoch": 1.4120167494400624,
      "grad_norm": 9.127182960510254,
      "learning_rate": 0.0001058720420683611,
      "loss": 0.1257,
      "step": 14500
    },
    {
      "epoch": 1.4168857727139936,
      "grad_norm": 0.054801374673843384,
      "learning_rate": 0.00010554744051676568,
      "loss": 0.094,
      "step": 14550
    },
    {
      "epoch": 1.4217547959879249,
      "grad_norm": 2.477821111679077,
      "learning_rate": 0.00010522283896517026,
      "loss": 0.1563,
      "step": 14600
    },
    {
      "epoch": 1.426623819261856,
      "grad_norm": 4.243681907653809,
      "learning_rate": 0.00010489823741357485,
      "loss": 0.0934,
      "step": 14650
    },
    {
      "epoch": 1.4314928425357873,
      "grad_norm": 3.8035647869110107,
      "learning_rate": 0.00010457363586197943,
      "loss": 0.091,
      "step": 14700
    },
    {
      "epoch": 1.4363618658097186,
      "grad_norm": 6.282561779022217,
      "learning_rate": 0.00010424903431038401,
      "loss": 0.0684,
      "step": 14750
    },
    {
      "epoch": 1.4412308890836498,
      "grad_norm": 0.18923038244247437,
      "learning_rate": 0.00010392443275878858,
      "loss": 0.1489,
      "step": 14800
    },
    {
      "epoch": 1.446099912357581,
      "grad_norm": 6.20518684387207,
      "learning_rate": 0.00010359983120719317,
      "loss": 0.1151,
      "step": 14850
    },
    {
      "epoch": 1.4509689356315123,
      "grad_norm": 0.004054018296301365,
      "learning_rate": 0.00010327522965559775,
      "loss": 0.0996,
      "step": 14900
    },
    {
      "epoch": 1.4558379589054435,
      "grad_norm": 2.4210264682769775,
      "learning_rate": 0.00010295062810400233,
      "loss": 0.087,
      "step": 14950
    },
    {
      "epoch": 1.4607069821793748,
      "grad_norm": 8.108960151672363,
      "learning_rate": 0.00010262602655240692,
      "loss": 0.1206,
      "step": 15000
    },
    {
      "epoch": 1.465576005453306,
      "grad_norm": 0.0031722045969218016,
      "learning_rate": 0.0001023014250008115,
      "loss": 0.078,
      "step": 15050
    },
    {
      "epoch": 1.4704450287272373,
      "grad_norm": 0.21456126868724823,
      "learning_rate": 0.00010197682344921608,
      "loss": 0.0422,
      "step": 15100
    },
    {
      "epoch": 1.4753140520011685,
      "grad_norm": 7.592084884643555,
      "learning_rate": 0.00010165222189762068,
      "loss": 0.17,
      "step": 15150
    },
    {
      "epoch": 1.4801830752750997,
      "grad_norm": 0.06955686211585999,
      "learning_rate": 0.00010132762034602525,
      "loss": 0.1582,
      "step": 15200
    },
    {
      "epoch": 1.4850520985490312,
      "grad_norm": 6.533183574676514,
      "learning_rate": 0.00010100301879442983,
      "loss": 0.0871,
      "step": 15250
    },
    {
      "epoch": 1.4899211218229622,
      "grad_norm": 0.02223365567624569,
      "learning_rate": 0.00010067841724283443,
      "loss": 0.1015,
      "step": 15300
    },
    {
      "epoch": 1.4947901450968937,
      "grad_norm": 0.0849127247929573,
      "learning_rate": 0.000100353815691239,
      "loss": 0.1852,
      "step": 15350
    },
    {
      "epoch": 1.4996591683708247,
      "grad_norm": 0.07648547738790512,
      "learning_rate": 0.00010002921413964359,
      "loss": 0.2007,
      "step": 15400
    },
    {
      "epoch": 1.5045281916447562,
      "grad_norm": 0.09692301601171494,
      "learning_rate": 9.970461258804818e-05,
      "loss": 0.125,
      "step": 15450
    },
    {
      "epoch": 1.5093972149186872,
      "grad_norm": 1.2525970935821533,
      "learning_rate": 9.938001103645276e-05,
      "loss": 0.0731,
      "step": 15500
    },
    {
      "epoch": 1.5142662381926186,
      "grad_norm": 0.001183451502583921,
      "learning_rate": 9.905540948485734e-05,
      "loss": 0.1176,
      "step": 15550
    },
    {
      "epoch": 1.5191352614665496,
      "grad_norm": 0.004294280894100666,
      "learning_rate": 9.873080793326193e-05,
      "loss": 0.1571,
      "step": 15600
    },
    {
      "epoch": 1.524004284740481,
      "grad_norm": 9.428216934204102,
      "learning_rate": 9.840620638166651e-05,
      "loss": 0.1094,
      "step": 15650
    },
    {
      "epoch": 1.5288733080144123,
      "grad_norm": 0.04637496545910835,
      "learning_rate": 9.808160483007109e-05,
      "loss": 0.1257,
      "step": 15700
    },
    {
      "epoch": 1.5337423312883436,
      "grad_norm": 0.005120106972754002,
      "learning_rate": 9.775700327847568e-05,
      "loss": 0.1255,
      "step": 15750
    },
    {
      "epoch": 1.5386113545622748,
      "grad_norm": 0.08521254360675812,
      "learning_rate": 9.743240172688026e-05,
      "loss": 0.0991,
      "step": 15800
    },
    {
      "epoch": 1.543480377836206,
      "grad_norm": 0.6950593590736389,
      "learning_rate": 9.710780017528484e-05,
      "loss": 0.0946,
      "step": 15850
    },
    {
      "epoch": 1.5483494011101373,
      "grad_norm": 0.009166548028588295,
      "learning_rate": 9.678319862368943e-05,
      "loss": 0.0875,
      "step": 15900
    },
    {
      "epoch": 1.5532184243840685,
      "grad_norm": 1.7329710721969604,
      "learning_rate": 9.645859707209401e-05,
      "loss": 0.1996,
      "step": 15950
    },
    {
      "epoch": 1.5580874476579998,
      "grad_norm": 0.036889247596263885,
      "learning_rate": 9.613399552049859e-05,
      "loss": 0.0854,
      "step": 16000
    },
    {
      "epoch": 1.562956470931931,
      "grad_norm": 0.06888146698474884,
      "learning_rate": 9.580939396890317e-05,
      "loss": 0.1582,
      "step": 16050
    },
    {
      "epoch": 1.5678254942058623,
      "grad_norm": 0.44141334295272827,
      "learning_rate": 9.548479241730775e-05,
      "loss": 0.1042,
      "step": 16100
    },
    {
      "epoch": 1.5726945174797935,
      "grad_norm": 0.06409565359354019,
      "learning_rate": 9.516019086571234e-05,
      "loss": 0.0917,
      "step": 16150
    },
    {
      "epoch": 1.577563540753725,
      "grad_norm": 0.861509382724762,
      "learning_rate": 9.483558931411692e-05,
      "loss": 0.2652,
      "step": 16200
    },
    {
      "epoch": 1.582432564027656,
      "grad_norm": 0.09522640705108643,
      "learning_rate": 9.45109877625215e-05,
      "loss": 0.0927,
      "step": 16250
    },
    {
      "epoch": 1.5873015873015874,
      "grad_norm": 0.038468580693006516,
      "learning_rate": 9.41863862109261e-05,
      "loss": 0.1176,
      "step": 16300
    },
    {
      "epoch": 1.5921706105755185,
      "grad_norm": 0.9677308201789856,
      "learning_rate": 9.386178465933068e-05,
      "loss": 0.1133,
      "step": 16350
    },
    {
      "epoch": 1.59703963384945,
      "grad_norm": 0.006719785742461681,
      "learning_rate": 9.353718310773526e-05,
      "loss": 0.0915,
      "step": 16400
    },
    {
      "epoch": 1.601908657123381,
      "grad_norm": 5.876412391662598,
      "learning_rate": 9.321258155613985e-05,
      "loss": 0.1962,
      "step": 16450
    },
    {
      "epoch": 1.6067776803973124,
      "grad_norm": 10.629067420959473,
      "learning_rate": 9.288798000454443e-05,
      "loss": 0.1371,
      "step": 16500
    },
    {
      "epoch": 1.6116467036712434,
      "grad_norm": 6.236868381500244,
      "learning_rate": 9.256337845294901e-05,
      "loss": 0.1562,
      "step": 16550
    },
    {
      "epoch": 1.6165157269451749,
      "grad_norm": 0.010921016335487366,
      "learning_rate": 9.22387769013536e-05,
      "loss": 0.1354,
      "step": 16600
    },
    {
      "epoch": 1.6213847502191059,
      "grad_norm": 6.632266044616699,
      "learning_rate": 9.191417534975818e-05,
      "loss": 0.0881,
      "step": 16650
    },
    {
      "epoch": 1.6262537734930373,
      "grad_norm": 0.13797470927238464,
      "learning_rate": 9.158957379816276e-05,
      "loss": 0.1771,
      "step": 16700
    },
    {
      "epoch": 1.6311227967669686,
      "grad_norm": 0.004331791773438454,
      "learning_rate": 9.126497224656735e-05,
      "loss": 0.0335,
      "step": 16750
    },
    {
      "epoch": 1.6359918200408998,
      "grad_norm": 0.9637914299964905,
      "learning_rate": 9.094037069497192e-05,
      "loss": 0.1578,
      "step": 16800
    },
    {
      "epoch": 1.640860843314831,
      "grad_norm": 2.947734832763672,
      "learning_rate": 9.061576914337651e-05,
      "loss": 0.0908,
      "step": 16850
    },
    {
      "epoch": 1.6457298665887623,
      "grad_norm": 1.6743407249450684,
      "learning_rate": 9.029116759178109e-05,
      "loss": 0.1298,
      "step": 16900
    },
    {
      "epoch": 1.6505988898626935,
      "grad_norm": 0.4400826692581177,
      "learning_rate": 8.996656604018567e-05,
      "loss": 0.1016,
      "step": 16950
    },
    {
      "epoch": 1.6554679131366248,
      "grad_norm": 4.970069408416748,
      "learning_rate": 8.964196448859026e-05,
      "loss": 0.1639,
      "step": 17000
    },
    {
      "epoch": 1.660336936410556,
      "grad_norm": 0.0064463685266673565,
      "learning_rate": 8.931736293699484e-05,
      "loss": 0.092,
      "step": 17050
    },
    {
      "epoch": 1.6652059596844873,
      "grad_norm": 0.08439406752586365,
      "learning_rate": 8.899276138539942e-05,
      "loss": 0.0768,
      "step": 17100
    },
    {
      "epoch": 1.6700749829584185,
      "grad_norm": 0.16578331589698792,
      "learning_rate": 8.866815983380401e-05,
      "loss": 0.1199,
      "step": 17150
    },
    {
      "epoch": 1.6749440062323497,
      "grad_norm": 7.700273513793945,
      "learning_rate": 8.83435582822086e-05,
      "loss": 0.1504,
      "step": 17200
    },
    {
      "epoch": 1.6798130295062812,
      "grad_norm": 3.852944850921631,
      "learning_rate": 8.801895673061317e-05,
      "loss": 0.1333,
      "step": 17250
    },
    {
      "epoch": 1.6846820527802122,
      "grad_norm": 0.016138391569256783,
      "learning_rate": 8.769435517901777e-05,
      "loss": 0.063,
      "step": 17300
    },
    {
      "epoch": 1.6895510760541437,
      "grad_norm": 0.22611212730407715,
      "learning_rate": 8.736975362742235e-05,
      "loss": 0.1154,
      "step": 17350
    },
    {
      "epoch": 1.6944200993280747,
      "grad_norm": 1.785327672958374,
      "learning_rate": 8.704515207582692e-05,
      "loss": 0.1674,
      "step": 17400
    },
    {
      "epoch": 1.6992891226020062,
      "grad_norm": 0.6208671927452087,
      "learning_rate": 8.672055052423152e-05,
      "loss": 0.1086,
      "step": 17450
    },
    {
      "epoch": 1.7041581458759372,
      "grad_norm": 0.014191536232829094,
      "learning_rate": 8.63959489726361e-05,
      "loss": 0.1501,
      "step": 17500
    },
    {
      "epoch": 1.7090271691498686,
      "grad_norm": 4.708483695983887,
      "learning_rate": 8.607134742104068e-05,
      "loss": 0.1048,
      "step": 17550
    },
    {
      "epoch": 1.7138961924237996,
      "grad_norm": 1.04117751121521,
      "learning_rate": 8.574674586944526e-05,
      "loss": 0.0486,
      "step": 17600
    },
    {
      "epoch": 1.718765215697731,
      "grad_norm": 0.007352515123784542,
      "learning_rate": 8.542214431784984e-05,
      "loss": 0.1278,
      "step": 17650
    },
    {
      "epoch": 1.7236342389716621,
      "grad_norm": 0.0027027775067836046,
      "learning_rate": 8.509754276625443e-05,
      "loss": 0.1137,
      "step": 17700
    },
    {
      "epoch": 1.7285032622455936,
      "grad_norm": 0.0388156957924366,
      "learning_rate": 8.477294121465901e-05,
      "loss": 0.1091,
      "step": 17750
    },
    {
      "epoch": 1.7333722855195248,
      "grad_norm": 0.03179394453763962,
      "learning_rate": 8.444833966306359e-05,
      "loss": 0.1729,
      "step": 17800
    },
    {
      "epoch": 1.738241308793456,
      "grad_norm": 0.29290369153022766,
      "learning_rate": 8.412373811146818e-05,
      "loss": 0.1175,
      "step": 17850
    },
    {
      "epoch": 1.7431103320673873,
      "grad_norm": 0.3051973879337311,
      "learning_rate": 8.379913655987276e-05,
      "loss": 0.0869,
      "step": 17900
    },
    {
      "epoch": 1.7479793553413185,
      "grad_norm": 0.11837631464004517,
      "learning_rate": 8.347453500827734e-05,
      "loss": 0.1663,
      "step": 17950
    },
    {
      "epoch": 1.7528483786152498,
      "grad_norm": 0.09823581576347351,
      "learning_rate": 8.314993345668193e-05,
      "loss": 0.0892,
      "step": 18000
    },
    {
      "epoch": 1.757717401889181,
      "grad_norm": 0.032039280980825424,
      "learning_rate": 8.282533190508651e-05,
      "loss": 0.1531,
      "step": 18050
    },
    {
      "epoch": 1.7625864251631123,
      "grad_norm": 0.04936499893665314,
      "learning_rate": 8.250073035349109e-05,
      "loss": 0.1204,
      "step": 18100
    },
    {
      "epoch": 1.7674554484370435,
      "grad_norm": 0.08067731559276581,
      "learning_rate": 8.217612880189568e-05,
      "loss": 0.1299,
      "step": 18150
    },
    {
      "epoch": 1.7723244717109747,
      "grad_norm": 0.12235665321350098,
      "learning_rate": 8.185152725030026e-05,
      "loss": 0.1194,
      "step": 18200
    },
    {
      "epoch": 1.777193494984906,
      "grad_norm": 7.276656150817871,
      "learning_rate": 8.152692569870484e-05,
      "loss": 0.0826,
      "step": 18250
    },
    {
      "epoch": 1.7820625182588374,
      "grad_norm": 0.02942677028477192,
      "learning_rate": 8.120232414710944e-05,
      "loss": 0.1637,
      "step": 18300
    },
    {
      "epoch": 1.7869315415327685,
      "grad_norm": 0.051336176693439484,
      "learning_rate": 8.0877722595514e-05,
      "loss": 0.1523,
      "step": 18350
    },
    {
      "epoch": 1.7918005648067,
      "grad_norm": 1.708411693572998,
      "learning_rate": 8.05531210439186e-05,
      "loss": 0.1256,
      "step": 18400
    },
    {
      "epoch": 1.796669588080631,
      "grad_norm": 0.011469000019133091,
      "learning_rate": 8.022851949232317e-05,
      "loss": 0.0991,
      "step": 18450
    },
    {
      "epoch": 1.8015386113545624,
      "grad_norm": 0.016026197001338005,
      "learning_rate": 7.990391794072775e-05,
      "loss": 0.1144,
      "step": 18500
    },
    {
      "epoch": 1.8064076346284934,
      "grad_norm": 0.007585600949823856,
      "learning_rate": 7.957931638913235e-05,
      "loss": 0.1233,
      "step": 18550
    },
    {
      "epoch": 1.8112766579024249,
      "grad_norm": 0.9803879261016846,
      "learning_rate": 7.925471483753693e-05,
      "loss": 0.129,
      "step": 18600
    },
    {
      "epoch": 1.8161456811763559,
      "grad_norm": 0.17537821829319,
      "learning_rate": 7.89301132859415e-05,
      "loss": 0.1973,
      "step": 18650
    },
    {
      "epoch": 1.8210147044502873,
      "grad_norm": 0.059120140969753265,
      "learning_rate": 7.86055117343461e-05,
      "loss": 0.1471,
      "step": 18700
    },
    {
      "epoch": 1.8258837277242184,
      "grad_norm": 0.007213826756924391,
      "learning_rate": 7.828091018275068e-05,
      "loss": 0.0865,
      "step": 18750
    },
    {
      "epoch": 1.8307527509981498,
      "grad_norm": 7.179749011993408,
      "learning_rate": 7.795630863115526e-05,
      "loss": 0.1185,
      "step": 18800
    },
    {
      "epoch": 1.835621774272081,
      "grad_norm": 0.03774496912956238,
      "learning_rate": 7.763170707955985e-05,
      "loss": 0.1272,
      "step": 18850
    },
    {
      "epoch": 1.8404907975460123,
      "grad_norm": 0.028620615601539612,
      "learning_rate": 7.730710552796443e-05,
      "loss": 0.1759,
      "step": 18900
    },
    {
      "epoch": 1.8453598208199435,
      "grad_norm": 2.152498483657837,
      "learning_rate": 7.698250397636901e-05,
      "loss": 0.0963,
      "step": 18950
    },
    {
      "epoch": 1.8502288440938748,
      "grad_norm": 0.025489255785942078,
      "learning_rate": 7.66579024247736e-05,
      "loss": 0.1381,
      "step": 19000
    },
    {
      "epoch": 1.855097867367806,
      "grad_norm": 0.020354151725769043,
      "learning_rate": 7.633330087317818e-05,
      "loss": 0.0826,
      "step": 19050
    },
    {
      "epoch": 1.8599668906417373,
      "grad_norm": 2.7402303218841553,
      "learning_rate": 7.600869932158276e-05,
      "loss": 0.1807,
      "step": 19100
    },
    {
      "epoch": 1.8648359139156685,
      "grad_norm": 0.09871262311935425,
      "learning_rate": 7.568409776998734e-05,
      "loss": 0.1259,
      "step": 19150
    },
    {
      "epoch": 1.8697049371895997,
      "grad_norm": 1.391491413116455,
      "learning_rate": 7.535949621839192e-05,
      "loss": 0.1493,
      "step": 19200
    },
    {
      "epoch": 1.874573960463531,
      "grad_norm": 0.2835901975631714,
      "learning_rate": 7.503489466679651e-05,
      "loss": 0.1192,
      "step": 19250
    },
    {
      "epoch": 1.8794429837374622,
      "grad_norm": 0.063763827085495,
      "learning_rate": 7.471029311520109e-05,
      "loss": 0.1278,
      "step": 19300
    },
    {
      "epoch": 1.8843120070113937,
      "grad_norm": 2.678070068359375,
      "learning_rate": 7.438569156360567e-05,
      "loss": 0.0553,
      "step": 19350
    },
    {
      "epoch": 1.8891810302853247,
      "grad_norm": 9.34135627746582,
      "learning_rate": 7.406109001201026e-05,
      "loss": 0.135,
      "step": 19400
    },
    {
      "epoch": 1.8940500535592562,
      "grad_norm": 1.844232439994812,
      "learning_rate": 7.373648846041484e-05,
      "loss": 0.1258,
      "step": 19450
    },
    {
      "epoch": 1.8989190768331872,
      "grad_norm": 0.07141181081533432,
      "learning_rate": 7.341188690881942e-05,
      "loss": 0.1202,
      "step": 19500
    },
    {
      "epoch": 1.9037881001071186,
      "grad_norm": 0.029702268540859222,
      "learning_rate": 7.308728535722402e-05,
      "loss": 0.1247,
      "step": 19550
    },
    {
      "epoch": 1.9086571233810496,
      "grad_norm": 0.010833168402314186,
      "learning_rate": 7.27626838056286e-05,
      "loss": 0.1318,
      "step": 19600
    },
    {
      "epoch": 1.913526146654981,
      "grad_norm": 0.023359831422567368,
      "learning_rate": 7.243808225403317e-05,
      "loss": 0.0748,
      "step": 19650
    },
    {
      "epoch": 1.9183951699289121,
      "grad_norm": 4.6153883934021,
      "learning_rate": 7.211348070243777e-05,
      "loss": 0.097,
      "step": 19700
    },
    {
      "epoch": 1.9232641932028436,
      "grad_norm": 7.841333389282227,
      "learning_rate": 7.178887915084235e-05,
      "loss": 0.1246,
      "step": 19750
    },
    {
      "epoch": 1.9281332164767746,
      "grad_norm": 0.13021275401115417,
      "learning_rate": 7.146427759924693e-05,
      "loss": 0.1499,
      "step": 19800
    },
    {
      "epoch": 1.933002239750706,
      "grad_norm": 1.4143942594528198,
      "learning_rate": 7.113967604765152e-05,
      "loss": 0.1282,
      "step": 19850
    },
    {
      "epoch": 1.9378712630246373,
      "grad_norm": 5.5917158126831055,
      "learning_rate": 7.08150744960561e-05,
      "loss": 0.1003,
      "step": 19900
    },
    {
      "epoch": 1.9427402862985685,
      "grad_norm": 0.14681462943553925,
      "learning_rate": 7.049047294446068e-05,
      "loss": 0.1485,
      "step": 19950
    },
    {
      "epoch": 1.9476093095724998,
      "grad_norm": 0.1156051754951477,
      "learning_rate": 7.016587139286526e-05,
      "loss": 0.1094,
      "step": 20000
    },
    {
      "epoch": 1.952478332846431,
      "grad_norm": 0.05546092987060547,
      "learning_rate": 6.984126984126984e-05,
      "loss": 0.0801,
      "step": 20050
    },
    {
      "epoch": 1.9573473561203623,
      "grad_norm": 0.3963356614112854,
      "learning_rate": 6.951666828967443e-05,
      "loss": 0.1344,
      "step": 20100
    },
    {
      "epoch": 1.9622163793942935,
      "grad_norm": 0.16916535794734955,
      "learning_rate": 6.919206673807901e-05,
      "loss": 0.1141,
      "step": 20150
    },
    {
      "epoch": 1.9670854026682247,
      "grad_norm": 5.91871976852417,
      "learning_rate": 6.886746518648359e-05,
      "loss": 0.1226,
      "step": 20200
    },
    {
      "epoch": 1.971954425942156,
      "grad_norm": 0.18474894762039185,
      "learning_rate": 6.854286363488818e-05,
      "loss": 0.077,
      "step": 20250
    },
    {
      "epoch": 1.9768234492160872,
      "grad_norm": 0.603420615196228,
      "learning_rate": 6.821826208329276e-05,
      "loss": 0.1583,
      "step": 20300
    },
    {
      "epoch": 1.9816924724900185,
      "grad_norm": 0.42256855964660645,
      "learning_rate": 6.789366053169734e-05,
      "loss": 0.1115,
      "step": 20350
    },
    {
      "epoch": 1.98656149576395,
      "grad_norm": 0.009762333706021309,
      "learning_rate": 6.756905898010193e-05,
      "loss": 0.0974,
      "step": 20400
    },
    {
      "epoch": 1.991430519037881,
      "grad_norm": 0.528457522392273,
      "learning_rate": 6.724445742850651e-05,
      "loss": 0.1537,
      "step": 20450
    },
    {
      "epoch": 1.9962995423118124,
      "grad_norm": 0.009230651892721653,
      "learning_rate": 6.691985587691109e-05,
      "loss": 0.0612,
      "step": 20500
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9717353198948291,
      "eval_loss": 0.12391405552625656,
      "eval_runtime": 80.5473,
      "eval_samples_per_second": 113.325,
      "eval_steps_per_second": 7.089,
      "step": 20538
    },
    {
      "epoch": 2.0011685655857434,
      "grad_norm": 0.1773892492055893,
      "learning_rate": 6.659525432531569e-05,
      "loss": 0.1086,
      "step": 20550
    },
    {
      "epoch": 2.006037588859675,
      "grad_norm": 0.08966024965047836,
      "learning_rate": 6.627065277372026e-05,
      "loss": 0.0931,
      "step": 20600
    },
    {
      "epoch": 2.010906612133606,
      "grad_norm": 0.1073208600282669,
      "learning_rate": 6.594605122212484e-05,
      "loss": 0.1434,
      "step": 20650
    },
    {
      "epoch": 2.0157756354075373,
      "grad_norm": 0.16707831621170044,
      "learning_rate": 6.562144967052944e-05,
      "loss": 0.1264,
      "step": 20700
    },
    {
      "epoch": 2.0206446586814684,
      "grad_norm": 4.137900352478027,
      "learning_rate": 6.5296848118934e-05,
      "loss": 0.0493,
      "step": 20750
    },
    {
      "epoch": 2.0255136819554,
      "grad_norm": 2.253532648086548,
      "learning_rate": 6.49722465673386e-05,
      "loss": 0.1509,
      "step": 20800
    },
    {
      "epoch": 2.030382705229331,
      "grad_norm": 4.100686550140381,
      "learning_rate": 6.464764501574318e-05,
      "loss": 0.1091,
      "step": 20850
    },
    {
      "epoch": 2.0352517285032623,
      "grad_norm": 0.0900341123342514,
      "learning_rate": 6.432304346414775e-05,
      "loss": 0.1279,
      "step": 20900
    },
    {
      "epoch": 2.0401207517771933,
      "grad_norm": 2.283261775970459,
      "learning_rate": 6.399844191255235e-05,
      "loss": 0.0872,
      "step": 20950
    },
    {
      "epoch": 2.044989775051125,
      "grad_norm": 0.30990538001060486,
      "learning_rate": 6.367384036095693e-05,
      "loss": 0.0491,
      "step": 21000
    },
    {
      "epoch": 2.049858798325056,
      "grad_norm": 2.1242291927337646,
      "learning_rate": 6.33492388093615e-05,
      "loss": 0.1217,
      "step": 21050
    },
    {
      "epoch": 2.0547278215989873,
      "grad_norm": 0.02266526222229004,
      "learning_rate": 6.30246372577661e-05,
      "loss": 0.0631,
      "step": 21100
    },
    {
      "epoch": 2.0595968448729183,
      "grad_norm": 2.777571439743042,
      "learning_rate": 6.270003570617068e-05,
      "loss": 0.0707,
      "step": 21150
    },
    {
      "epoch": 2.0644658681468497,
      "grad_norm": 9.222189903259277,
      "learning_rate": 6.237543415457526e-05,
      "loss": 0.118,
      "step": 21200
    },
    {
      "epoch": 2.069334891420781,
      "grad_norm": 0.024034695699810982,
      "learning_rate": 6.205083260297985e-05,
      "loss": 0.0833,
      "step": 21250
    },
    {
      "epoch": 2.074203914694712,
      "grad_norm": 7.98419713973999,
      "learning_rate": 6.172623105138443e-05,
      "loss": 0.1596,
      "step": 21300
    },
    {
      "epoch": 2.0790729379686437,
      "grad_norm": 0.16978272795677185,
      "learning_rate": 6.140162949978901e-05,
      "loss": 0.1031,
      "step": 21350
    },
    {
      "epoch": 2.0839419612425747,
      "grad_norm": 0.024934588000178337,
      "learning_rate": 6.10770279481936e-05,
      "loss": 0.1278,
      "step": 21400
    },
    {
      "epoch": 2.088810984516506,
      "grad_norm": 0.06901267170906067,
      "learning_rate": 6.075242639659818e-05,
      "loss": 0.0495,
      "step": 21450
    },
    {
      "epoch": 2.093680007790437,
      "grad_norm": 1.0984569787979126,
      "learning_rate": 6.042782484500277e-05,
      "loss": 0.1536,
      "step": 21500
    },
    {
      "epoch": 2.0985490310643686,
      "grad_norm": 0.012704677879810333,
      "learning_rate": 6.010322329340734e-05,
      "loss": 0.1015,
      "step": 21550
    },
    {
      "epoch": 2.1034180543382996,
      "grad_norm": 0.06687392294406891,
      "learning_rate": 5.977862174181193e-05,
      "loss": 0.1784,
      "step": 21600
    },
    {
      "epoch": 2.108287077612231,
      "grad_norm": 0.5156819224357605,
      "learning_rate": 5.945402019021651e-05,
      "loss": 0.101,
      "step": 21650
    },
    {
      "epoch": 2.113156100886162,
      "grad_norm": 0.007748306263238192,
      "learning_rate": 5.912941863862109e-05,
      "loss": 0.1141,
      "step": 21700
    },
    {
      "epoch": 2.1180251241600936,
      "grad_norm": 0.14294098317623138,
      "learning_rate": 5.880481708702568e-05,
      "loss": 0.1648,
      "step": 21750
    },
    {
      "epoch": 2.1228941474340246,
      "grad_norm": 0.0967368334531784,
      "learning_rate": 5.848021553543026e-05,
      "loss": 0.0289,
      "step": 21800
    },
    {
      "epoch": 2.127763170707956,
      "grad_norm": 0.8095375299453735,
      "learning_rate": 5.8155613983834845e-05,
      "loss": 0.1008,
      "step": 21850
    },
    {
      "epoch": 2.132632193981887,
      "grad_norm": 0.7067080736160278,
      "learning_rate": 5.783101243223943e-05,
      "loss": 0.1418,
      "step": 21900
    },
    {
      "epoch": 2.1375012172558185,
      "grad_norm": 2.935563564300537,
      "learning_rate": 5.750641088064401e-05,
      "loss": 0.0745,
      "step": 21950
    },
    {
      "epoch": 2.1423702405297496,
      "grad_norm": 8.421976089477539,
      "learning_rate": 5.7181809329048597e-05,
      "loss": 0.0886,
      "step": 22000
    },
    {
      "epoch": 2.147239263803681,
      "grad_norm": 2.8269474506378174,
      "learning_rate": 5.685720777745318e-05,
      "loss": 0.0899,
      "step": 22050
    },
    {
      "epoch": 2.152108287077612,
      "grad_norm": 0.650364875793457,
      "learning_rate": 5.653260622585776e-05,
      "loss": 0.1388,
      "step": 22100
    },
    {
      "epoch": 2.1569773103515435,
      "grad_norm": 3.1631295680999756,
      "learning_rate": 5.620800467426235e-05,
      "loss": 0.0824,
      "step": 22150
    },
    {
      "epoch": 2.1618463336254745,
      "grad_norm": 0.10922706872224808,
      "learning_rate": 5.5883403122666935e-05,
      "loss": 0.1175,
      "step": 22200
    },
    {
      "epoch": 2.166715356899406,
      "grad_norm": 0.03621095418930054,
      "learning_rate": 5.5558801571071514e-05,
      "loss": 0.1036,
      "step": 22250
    },
    {
      "epoch": 2.1715843801733374,
      "grad_norm": 0.1013006865978241,
      "learning_rate": 5.52342000194761e-05,
      "loss": 0.075,
      "step": 22300
    },
    {
      "epoch": 2.1764534034472685,
      "grad_norm": 7.225905418395996,
      "learning_rate": 5.490959846788067e-05,
      "loss": 0.0962,
      "step": 22350
    },
    {
      "epoch": 2.1813224267212,
      "grad_norm": 6.190199851989746,
      "learning_rate": 5.458499691628526e-05,
      "loss": 0.1248,
      "step": 22400
    },
    {
      "epoch": 2.186191449995131,
      "grad_norm": 0.021270476281642914,
      "learning_rate": 5.4260395364689845e-05,
      "loss": 0.0832,
      "step": 22450
    },
    {
      "epoch": 2.1910604732690624,
      "grad_norm": 0.009105805307626724,
      "learning_rate": 5.3935793813094425e-05,
      "loss": 0.0695,
      "step": 22500
    },
    {
      "epoch": 2.1959294965429934,
      "grad_norm": 0.10502753406763077,
      "learning_rate": 5.361119226149901e-05,
      "loss": 0.1103,
      "step": 22550
    },
    {
      "epoch": 2.200798519816925,
      "grad_norm": 6.3486785888671875,
      "learning_rate": 5.32865907099036e-05,
      "loss": 0.109,
      "step": 22600
    },
    {
      "epoch": 2.205667543090856,
      "grad_norm": 0.15586026012897491,
      "learning_rate": 5.2961989158308176e-05,
      "loss": 0.0851,
      "step": 22650
    },
    {
      "epoch": 2.2105365663647873,
      "grad_norm": 0.020296195521950722,
      "learning_rate": 5.263738760671276e-05,
      "loss": 0.0646,
      "step": 22700
    },
    {
      "epoch": 2.2154055896387184,
      "grad_norm": 0.03004387766122818,
      "learning_rate": 5.231278605511735e-05,
      "loss": 0.1024,
      "step": 22750
    },
    {
      "epoch": 2.22027461291265,
      "grad_norm": 0.03152253106236458,
      "learning_rate": 5.198818450352193e-05,
      "loss": 0.1609,
      "step": 22800
    },
    {
      "epoch": 2.225143636186581,
      "grad_norm": 1.0026425123214722,
      "learning_rate": 5.1663582951926514e-05,
      "loss": 0.0536,
      "step": 22850
    },
    {
      "epoch": 2.2300126594605123,
      "grad_norm": 0.08240393549203873,
      "learning_rate": 5.13389814003311e-05,
      "loss": 0.1249,
      "step": 22900
    },
    {
      "epoch": 2.2348816827344433,
      "grad_norm": 1.5369151830673218,
      "learning_rate": 5.101437984873568e-05,
      "loss": 0.087,
      "step": 22950
    },
    {
      "epoch": 2.239750706008375,
      "grad_norm": 0.1852826029062271,
      "learning_rate": 5.0689778297140266e-05,
      "loss": 0.1,
      "step": 23000
    },
    {
      "epoch": 2.244619729282306,
      "grad_norm": 0.12853048741817474,
      "learning_rate": 5.036517674554485e-05,
      "loss": 0.1037,
      "step": 23050
    },
    {
      "epoch": 2.2494887525562373,
      "grad_norm": 0.04103117808699608,
      "learning_rate": 5.004057519394943e-05,
      "loss": 0.111,
      "step": 23100
    },
    {
      "epoch": 2.2543577758301683,
      "grad_norm": 0.014077101834118366,
      "learning_rate": 4.971597364235401e-05,
      "loss": 0.0755,
      "step": 23150
    },
    {
      "epoch": 2.2592267991040997,
      "grad_norm": 0.031921498477458954,
      "learning_rate": 4.93913720907586e-05,
      "loss": 0.0884,
      "step": 23200
    },
    {
      "epoch": 2.2640958223780308,
      "grad_norm": 0.0516236238181591,
      "learning_rate": 4.9066770539163183e-05,
      "loss": 0.1094,
      "step": 23250
    },
    {
      "epoch": 2.268964845651962,
      "grad_norm": 1.02791428565979,
      "learning_rate": 4.874216898756776e-05,
      "loss": 0.1474,
      "step": 23300
    },
    {
      "epoch": 2.2738338689258937,
      "grad_norm": 0.18648265302181244,
      "learning_rate": 4.841756743597234e-05,
      "loss": 0.133,
      "step": 23350
    },
    {
      "epoch": 2.2787028921998247,
      "grad_norm": 0.006918859668076038,
      "learning_rate": 4.809296588437693e-05,
      "loss": 0.0792,
      "step": 23400
    },
    {
      "epoch": 2.283571915473756,
      "grad_norm": 1.184483289718628,
      "learning_rate": 4.7768364332781515e-05,
      "loss": 0.0824,
      "step": 23450
    },
    {
      "epoch": 2.288440938747687,
      "grad_norm": 0.024368641898036003,
      "learning_rate": 4.7443762781186094e-05,
      "loss": 0.1295,
      "step": 23500
    },
    {
      "epoch": 2.2933099620216186,
      "grad_norm": 1.997596263885498,
      "learning_rate": 4.711916122959068e-05,
      "loss": 0.1061,
      "step": 23550
    },
    {
      "epoch": 2.2981789852955496,
      "grad_norm": 0.038035839796066284,
      "learning_rate": 4.6794559677995266e-05,
      "loss": 0.0825,
      "step": 23600
    },
    {
      "epoch": 2.303048008569481,
      "grad_norm": 0.08631999045610428,
      "learning_rate": 4.6469958126399846e-05,
      "loss": 0.1082,
      "step": 23650
    },
    {
      "epoch": 2.307917031843412,
      "grad_norm": 0.0198319423943758,
      "learning_rate": 4.614535657480443e-05,
      "loss": 0.1667,
      "step": 23700
    },
    {
      "epoch": 2.3127860551173436,
      "grad_norm": 0.031269896775484085,
      "learning_rate": 4.582075502320901e-05,
      "loss": 0.0912,
      "step": 23750
    },
    {
      "epoch": 2.3176550783912746,
      "grad_norm": 0.12952587008476257,
      "learning_rate": 4.54961534716136e-05,
      "loss": 0.1517,
      "step": 23800
    },
    {
      "epoch": 2.322524101665206,
      "grad_norm": 0.021573059260845184,
      "learning_rate": 4.517155192001818e-05,
      "loss": 0.0651,
      "step": 23850
    },
    {
      "epoch": 2.327393124939137,
      "grad_norm": 0.0658419206738472,
      "learning_rate": 4.484695036842276e-05,
      "loss": 0.1435,
      "step": 23900
    },
    {
      "epoch": 2.3322621482130685,
      "grad_norm": 0.015414441004395485,
      "learning_rate": 4.452234881682735e-05,
      "loss": 0.0524,
      "step": 23950
    },
    {
      "epoch": 2.3371311714869996,
      "grad_norm": 2.821474552154541,
      "learning_rate": 4.419774726523193e-05,
      "loss": 0.0886,
      "step": 24000
    },
    {
      "epoch": 2.342000194760931,
      "grad_norm": 0.20806649327278137,
      "learning_rate": 4.3873145713636515e-05,
      "loss": 0.1215,
      "step": 24050
    },
    {
      "epoch": 2.346869218034862,
      "grad_norm": 3.358975648880005,
      "learning_rate": 4.3548544162041094e-05,
      "loss": 0.1342,
      "step": 24100
    },
    {
      "epoch": 2.3517382413087935,
      "grad_norm": 4.364194869995117,
      "learning_rate": 4.322394261044568e-05,
      "loss": 0.0535,
      "step": 24150
    },
    {
      "epoch": 2.3566072645827245,
      "grad_norm": 0.04768744111061096,
      "learning_rate": 4.289934105885026e-05,
      "loss": 0.0388,
      "step": 24200
    },
    {
      "epoch": 2.361476287856656,
      "grad_norm": 0.014490899629890919,
      "learning_rate": 4.2574739507254846e-05,
      "loss": 0.0728,
      "step": 24250
    },
    {
      "epoch": 2.366345311130587,
      "grad_norm": 6.433175563812256,
      "learning_rate": 4.225013795565943e-05,
      "loss": 0.1112,
      "step": 24300
    },
    {
      "epoch": 2.3712143344045185,
      "grad_norm": 5.177682876586914,
      "learning_rate": 4.192553640406401e-05,
      "loss": 0.0904,
      "step": 24350
    },
    {
      "epoch": 2.37608335767845,
      "grad_norm": 0.19691525399684906,
      "learning_rate": 4.16009348524686e-05,
      "loss": 0.1396,
      "step": 24400
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 0.10900843143463135,
      "learning_rate": 4.1276333300873184e-05,
      "loss": 0.0896,
      "step": 24450
    },
    {
      "epoch": 2.3858214042263124,
      "grad_norm": 0.10993927717208862,
      "learning_rate": 4.0951731749277764e-05,
      "loss": 0.0679,
      "step": 24500
    },
    {
      "epoch": 2.3906904275002434,
      "grad_norm": 0.012528883293271065,
      "learning_rate": 4.062713019768234e-05,
      "loss": 0.0903,
      "step": 24550
    },
    {
      "epoch": 2.395559450774175,
      "grad_norm": 3.5047645568847656,
      "learning_rate": 4.030252864608693e-05,
      "loss": 0.0401,
      "step": 24600
    },
    {
      "epoch": 2.400428474048106,
      "grad_norm": 0.16437765955924988,
      "learning_rate": 3.9977927094491515e-05,
      "loss": 0.1287,
      "step": 24650
    },
    {
      "epoch": 2.4052974973220373,
      "grad_norm": 0.10825445502996445,
      "learning_rate": 3.9653325542896095e-05,
      "loss": 0.1269,
      "step": 24700
    },
    {
      "epoch": 2.4101665205959684,
      "grad_norm": 0.006754408124834299,
      "learning_rate": 3.932872399130068e-05,
      "loss": 0.0654,
      "step": 24750
    },
    {
      "epoch": 2.4150355438699,
      "grad_norm": 0.3346136510372162,
      "learning_rate": 3.900412243970527e-05,
      "loss": 0.1349,
      "step": 24800
    },
    {
      "epoch": 2.419904567143831,
      "grad_norm": 0.011497479863464832,
      "learning_rate": 3.8679520888109847e-05,
      "loss": 0.0622,
      "step": 24850
    },
    {
      "epoch": 2.4247735904177623,
      "grad_norm": 0.010323571972548962,
      "learning_rate": 3.8354919336514426e-05,
      "loss": 0.1653,
      "step": 24900
    },
    {
      "epoch": 2.4296426136916933,
      "grad_norm": 0.016045643016695976,
      "learning_rate": 3.803031778491901e-05,
      "loss": 0.107,
      "step": 24950
    },
    {
      "epoch": 2.434511636965625,
      "grad_norm": 0.20718593895435333,
      "learning_rate": 3.77057162333236e-05,
      "loss": 0.1118,
      "step": 25000
    },
    {
      "epoch": 2.439380660239556,
      "grad_norm": 0.006039731204509735,
      "learning_rate": 3.738111468172818e-05,
      "loss": 0.029,
      "step": 25050
    },
    {
      "epoch": 2.4442496835134873,
      "grad_norm": 0.2302001714706421,
      "learning_rate": 3.7056513130132764e-05,
      "loss": 0.0881,
      "step": 25100
    },
    {
      "epoch": 2.4491187067874183,
      "grad_norm": 0.019764015451073647,
      "learning_rate": 3.673191157853735e-05,
      "loss": 0.103,
      "step": 25150
    },
    {
      "epoch": 2.4539877300613497,
      "grad_norm": 0.34558039903640747,
      "learning_rate": 3.640731002694193e-05,
      "loss": 0.0737,
      "step": 25200
    },
    {
      "epoch": 2.4588567533352808,
      "grad_norm": 6.164083480834961,
      "learning_rate": 3.6082708475346516e-05,
      "loss": 0.089,
      "step": 25250
    },
    {
      "epoch": 2.463725776609212,
      "grad_norm": 1.2542868852615356,
      "learning_rate": 3.5758106923751095e-05,
      "loss": 0.136,
      "step": 25300
    },
    {
      "epoch": 2.4685947998831432,
      "grad_norm": 8.079890251159668,
      "learning_rate": 3.543350537215568e-05,
      "loss": 0.1124,
      "step": 25350
    },
    {
      "epoch": 2.4734638231570747,
      "grad_norm": 2.5826401710510254,
      "learning_rate": 3.510890382056026e-05,
      "loss": 0.0435,
      "step": 25400
    },
    {
      "epoch": 2.478332846431006,
      "grad_norm": 0.15106022357940674,
      "learning_rate": 3.478430226896485e-05,
      "loss": 0.0682,
      "step": 25450
    },
    {
      "epoch": 2.483201869704937,
      "grad_norm": 0.17923150956630707,
      "learning_rate": 3.445970071736943e-05,
      "loss": 0.0369,
      "step": 25500
    },
    {
      "epoch": 2.4880708929788686,
      "grad_norm": 0.003621788928285241,
      "learning_rate": 3.413509916577401e-05,
      "loss": 0.108,
      "step": 25550
    },
    {
      "epoch": 2.4929399162527996,
      "grad_norm": 0.47727900743484497,
      "learning_rate": 3.38104976141786e-05,
      "loss": 0.0859,
      "step": 25600
    },
    {
      "epoch": 2.497808939526731,
      "grad_norm": 0.3862193524837494,
      "learning_rate": 3.3485896062583185e-05,
      "loss": 0.014,
      "step": 25650
    },
    {
      "epoch": 2.502677962800662,
      "grad_norm": 0.00444734375923872,
      "learning_rate": 3.3161294510987764e-05,
      "loss": 0.1088,
      "step": 25700
    },
    {
      "epoch": 2.5075469860745936,
      "grad_norm": 9.509864807128906,
      "learning_rate": 3.2836692959392344e-05,
      "loss": 0.0979,
      "step": 25750
    },
    {
      "epoch": 2.5124160093485246,
      "grad_norm": 6.703450679779053,
      "learning_rate": 3.251209140779693e-05,
      "loss": 0.1672,
      "step": 25800
    },
    {
      "epoch": 2.517285032622456,
      "grad_norm": 0.03804744780063629,
      "learning_rate": 3.2187489856201516e-05,
      "loss": 0.0822,
      "step": 25850
    },
    {
      "epoch": 2.522154055896387,
      "grad_norm": 5.888245105743408,
      "learning_rate": 3.1862888304606096e-05,
      "loss": 0.0921,
      "step": 25900
    },
    {
      "epoch": 2.5270230791703185,
      "grad_norm": 0.282844215631485,
      "learning_rate": 3.153828675301068e-05,
      "loss": 0.0744,
      "step": 25950
    },
    {
      "epoch": 2.5318921024442496,
      "grad_norm": 6.17412805557251,
      "learning_rate": 3.121368520141527e-05,
      "loss": 0.1071,
      "step": 26000
    },
    {
      "epoch": 2.536761125718181,
      "grad_norm": 0.009913926012814045,
      "learning_rate": 3.088908364981985e-05,
      "loss": 0.0979,
      "step": 26050
    },
    {
      "epoch": 2.541630148992112,
      "grad_norm": 0.07125384360551834,
      "learning_rate": 3.056448209822443e-05,
      "loss": 0.1393,
      "step": 26100
    },
    {
      "epoch": 2.5464991722660435,
      "grad_norm": 0.04815342649817467,
      "learning_rate": 3.0239880546629013e-05,
      "loss": 0.1144,
      "step": 26150
    },
    {
      "epoch": 2.5513681955399745,
      "grad_norm": 0.010380841791629791,
      "learning_rate": 2.9915278995033596e-05,
      "loss": 0.0892,
      "step": 26200
    },
    {
      "epoch": 2.556237218813906,
      "grad_norm": 0.061318133026361465,
      "learning_rate": 2.9590677443438182e-05,
      "loss": 0.0801,
      "step": 26250
    },
    {
      "epoch": 2.5611062420878374,
      "grad_norm": 5.617293834686279,
      "learning_rate": 2.9266075891842765e-05,
      "loss": 0.1411,
      "step": 26300
    },
    {
      "epoch": 2.5659752653617685,
      "grad_norm": 0.05994335189461708,
      "learning_rate": 2.8941474340247347e-05,
      "loss": 0.1302,
      "step": 26350
    },
    {
      "epoch": 2.5708442886356995,
      "grad_norm": 1.6795700788497925,
      "learning_rate": 2.8616872788651934e-05,
      "loss": 0.0913,
      "step": 26400
    },
    {
      "epoch": 2.575713311909631,
      "grad_norm": 0.4491456151008606,
      "learning_rate": 2.8292271237056516e-05,
      "loss": 0.1546,
      "step": 26450
    },
    {
      "epoch": 2.5805823351835624,
      "grad_norm": 0.009321977384388447,
      "learning_rate": 2.7967669685461096e-05,
      "loss": 0.0946,
      "step": 26500
    },
    {
      "epoch": 2.5854513584574934,
      "grad_norm": 0.005425420124083757,
      "learning_rate": 2.764306813386568e-05,
      "loss": 0.1236,
      "step": 26550
    },
    {
      "epoch": 2.5903203817314244,
      "grad_norm": 0.016563447192311287,
      "learning_rate": 2.7318466582270265e-05,
      "loss": 0.0505,
      "step": 26600
    },
    {
      "epoch": 2.595189405005356,
      "grad_norm": 0.12241107225418091,
      "learning_rate": 2.6993865030674848e-05,
      "loss": 0.0946,
      "step": 26650
    },
    {
      "epoch": 2.6000584282792873,
      "grad_norm": 0.03531889617443085,
      "learning_rate": 2.666926347907943e-05,
      "loss": 0.0897,
      "step": 26700
    },
    {
      "epoch": 2.6049274515532184,
      "grad_norm": 0.0047677927650511265,
      "learning_rate": 2.6344661927484017e-05,
      "loss": 0.0966,
      "step": 26750
    },
    {
      "epoch": 2.60979647482715,
      "grad_norm": 0.01294638030230999,
      "learning_rate": 2.60200603758886e-05,
      "loss": 0.0592,
      "step": 26800
    },
    {
      "epoch": 2.614665498101081,
      "grad_norm": 3.951315402984619,
      "learning_rate": 2.5695458824293182e-05,
      "loss": 0.1357,
      "step": 26850
    },
    {
      "epoch": 2.6195345213750123,
      "grad_norm": 0.018616706132888794,
      "learning_rate": 2.537085727269776e-05,
      "loss": 0.0807,
      "step": 26900
    },
    {
      "epoch": 2.6244035446489433,
      "grad_norm": 0.034542594105005264,
      "learning_rate": 2.5046255721102348e-05,
      "loss": 0.0875,
      "step": 26950
    },
    {
      "epoch": 2.629272567922875,
      "grad_norm": 0.007186925038695335,
      "learning_rate": 2.472165416950693e-05,
      "loss": 0.1289,
      "step": 27000
    },
    {
      "epoch": 2.634141591196806,
      "grad_norm": 0.045602019876241684,
      "learning_rate": 2.4397052617911513e-05,
      "loss": 0.0747,
      "step": 27050
    },
    {
      "epoch": 2.6390106144707373,
      "grad_norm": 5.252548694610596,
      "learning_rate": 2.40724510663161e-05,
      "loss": 0.1845,
      "step": 27100
    },
    {
      "epoch": 2.6438796377446683,
      "grad_norm": 0.006716326344758272,
      "learning_rate": 2.3747849514720682e-05,
      "loss": 0.0906,
      "step": 27150
    },
    {
      "epoch": 2.6487486610185997,
      "grad_norm": 6.9290080070495605,
      "learning_rate": 2.3423247963125265e-05,
      "loss": 0.0996,
      "step": 27200
    },
    {
      "epoch": 2.6536176842925308,
      "grad_norm": 0.0761556625366211,
      "learning_rate": 2.3098646411529848e-05,
      "loss": 0.1246,
      "step": 27250
    },
    {
      "epoch": 2.658486707566462,
      "grad_norm": 7.445903301239014,
      "learning_rate": 2.277404485993443e-05,
      "loss": 0.1222,
      "step": 27300
    },
    {
      "epoch": 2.6633557308403937,
      "grad_norm": 0.2622351050376892,
      "learning_rate": 2.2449443308339017e-05,
      "loss": 0.1295,
      "step": 27350
    },
    {
      "epoch": 2.6682247541143247,
      "grad_norm": 0.00893612951040268,
      "learning_rate": 2.2124841756743596e-05,
      "loss": 0.0706,
      "step": 27400
    },
    {
      "epoch": 2.6730937773882557,
      "grad_norm": 0.04996282979846001,
      "learning_rate": 2.1800240205148183e-05,
      "loss": 0.1294,
      "step": 27450
    },
    {
      "epoch": 2.677962800662187,
      "grad_norm": 0.03652796894311905,
      "learning_rate": 2.1475638653552765e-05,
      "loss": 0.0727,
      "step": 27500
    },
    {
      "epoch": 2.6828318239361186,
      "grad_norm": 0.04863516986370087,
      "learning_rate": 2.1151037101957348e-05,
      "loss": 0.1136,
      "step": 27550
    },
    {
      "epoch": 2.6877008472100496,
      "grad_norm": 4.204079627990723,
      "learning_rate": 2.082643555036193e-05,
      "loss": 0.1659,
      "step": 27600
    },
    {
      "epoch": 2.6925698704839807,
      "grad_norm": 0.01144359540194273,
      "learning_rate": 2.0501833998766514e-05,
      "loss": 0.0716,
      "step": 27650
    },
    {
      "epoch": 2.697438893757912,
      "grad_norm": 0.1366744190454483,
      "learning_rate": 2.01772324471711e-05,
      "loss": 0.0695,
      "step": 27700
    },
    {
      "epoch": 2.7023079170318436,
      "grad_norm": 0.004882486537098885,
      "learning_rate": 1.9852630895575683e-05,
      "loss": 0.076,
      "step": 27750
    },
    {
      "epoch": 2.7071769403057746,
      "grad_norm": 0.0354093573987484,
      "learning_rate": 1.9528029343980266e-05,
      "loss": 0.0927,
      "step": 27800
    },
    {
      "epoch": 2.712045963579706,
      "grad_norm": 5.327573299407959,
      "learning_rate": 1.920342779238485e-05,
      "loss": 0.0916,
      "step": 27850
    },
    {
      "epoch": 2.716914986853637,
      "grad_norm": 0.3239422142505646,
      "learning_rate": 1.887882624078943e-05,
      "loss": 0.0852,
      "step": 27900
    },
    {
      "epoch": 2.7217840101275685,
      "grad_norm": 0.011026385240256786,
      "learning_rate": 1.8554224689194017e-05,
      "loss": 0.0855,
      "step": 27950
    },
    {
      "epoch": 2.7266530334014996,
      "grad_norm": 0.011958216316998005,
      "learning_rate": 1.8229623137598597e-05,
      "loss": 0.0839,
      "step": 28000
    },
    {
      "epoch": 2.731522056675431,
      "grad_norm": 0.020396968349814415,
      "learning_rate": 1.7905021586003183e-05,
      "loss": 0.0899,
      "step": 28050
    },
    {
      "epoch": 2.736391079949362,
      "grad_norm": 0.6716866493225098,
      "learning_rate": 1.7580420034407766e-05,
      "loss": 0.0989,
      "step": 28100
    },
    {
      "epoch": 2.7412601032232935,
      "grad_norm": 0.024655763059854507,
      "learning_rate": 1.725581848281235e-05,
      "loss": 0.1429,
      "step": 28150
    },
    {
      "epoch": 2.7461291264972245,
      "grad_norm": 0.34156811237335205,
      "learning_rate": 1.693121693121693e-05,
      "loss": 0.0809,
      "step": 28200
    },
    {
      "epoch": 2.750998149771156,
      "grad_norm": 7.256634712219238,
      "learning_rate": 1.6606615379621514e-05,
      "loss": 0.1169,
      "step": 28250
    },
    {
      "epoch": 2.755867173045087,
      "grad_norm": 4.254350662231445,
      "learning_rate": 1.62820138280261e-05,
      "loss": 0.0842,
      "step": 28300
    },
    {
      "epoch": 2.7607361963190185,
      "grad_norm": 0.008091273717582226,
      "learning_rate": 1.5957412276430683e-05,
      "loss": 0.0614,
      "step": 28350
    },
    {
      "epoch": 2.76560521959295,
      "grad_norm": 0.01896391250193119,
      "learning_rate": 1.5632810724835266e-05,
      "loss": 0.0706,
      "step": 28400
    },
    {
      "epoch": 2.770474242866881,
      "grad_norm": 0.10449540615081787,
      "learning_rate": 1.530820917323985e-05,
      "loss": 0.127,
      "step": 28450
    },
    {
      "epoch": 2.775343266140812,
      "grad_norm": 5.592945575714111,
      "learning_rate": 1.4983607621644433e-05,
      "loss": 0.1182,
      "step": 28500
    },
    {
      "epoch": 2.7802122894147434,
      "grad_norm": 0.28256794810295105,
      "learning_rate": 1.4659006070049016e-05,
      "loss": 0.0842,
      "step": 28550
    },
    {
      "epoch": 2.785081312688675,
      "grad_norm": 0.01405288279056549,
      "learning_rate": 1.4334404518453597e-05,
      "loss": 0.096,
      "step": 28600
    },
    {
      "epoch": 2.789950335962606,
      "grad_norm": 12.097625732421875,
      "learning_rate": 1.4009802966858182e-05,
      "loss": 0.0705,
      "step": 28650
    },
    {
      "epoch": 2.794819359236537,
      "grad_norm": 0.12454355508089066,
      "learning_rate": 1.3685201415262766e-05,
      "loss": 0.0576,
      "step": 28700
    },
    {
      "epoch": 2.7996883825104684,
      "grad_norm": 0.1331385225057602,
      "learning_rate": 1.336059986366735e-05,
      "loss": 0.1245,
      "step": 28750
    },
    {
      "epoch": 2.8045574057844,
      "grad_norm": 0.009469171054661274,
      "learning_rate": 1.3035998312071932e-05,
      "loss": 0.0862,
      "step": 28800
    },
    {
      "epoch": 2.809426429058331,
      "grad_norm": 0.05871571600437164,
      "learning_rate": 1.2711396760476516e-05,
      "loss": 0.0559,
      "step": 28850
    },
    {
      "epoch": 2.8142954523322623,
      "grad_norm": 0.2939232587814331,
      "learning_rate": 1.2386795208881099e-05,
      "loss": 0.0892,
      "step": 28900
    },
    {
      "epoch": 2.8191644756061933,
      "grad_norm": 0.00935431383550167,
      "learning_rate": 1.2062193657285682e-05,
      "loss": 0.1017,
      "step": 28950
    },
    {
      "epoch": 2.824033498880125,
      "grad_norm": 0.010015220381319523,
      "learning_rate": 1.1737592105690266e-05,
      "loss": 0.1122,
      "step": 29000
    },
    {
      "epoch": 2.828902522154056,
      "grad_norm": 0.294158399105072,
      "learning_rate": 1.1412990554094849e-05,
      "loss": 0.1421,
      "step": 29050
    },
    {
      "epoch": 2.8337715454279873,
      "grad_norm": 0.05517008155584335,
      "learning_rate": 1.1088389002499434e-05,
      "loss": 0.0972,
      "step": 29100
    },
    {
      "epoch": 2.8386405687019183,
      "grad_norm": 0.49130120873451233,
      "learning_rate": 1.0763787450904016e-05,
      "loss": 0.13,
      "step": 29150
    },
    {
      "epoch": 2.8435095919758497,
      "grad_norm": 0.02315596304833889,
      "learning_rate": 1.04391858993086e-05,
      "loss": 0.0498,
      "step": 29200
    },
    {
      "epoch": 2.8483786152497808,
      "grad_norm": 0.009261571802198887,
      "learning_rate": 1.0114584347713182e-05,
      "loss": 0.102,
      "step": 29250
    },
    {
      "epoch": 2.853247638523712,
      "grad_norm": 0.03771670162677765,
      "learning_rate": 9.789982796117767e-06,
      "loss": 0.0896,
      "step": 29300
    },
    {
      "epoch": 2.8581166617976432,
      "grad_norm": 6.3489179611206055,
      "learning_rate": 9.46538124452235e-06,
      "loss": 0.0929,
      "step": 29350
    },
    {
      "epoch": 2.8629856850715747,
      "grad_norm": 1.4430208206176758,
      "learning_rate": 9.140779692926934e-06,
      "loss": 0.0466,
      "step": 29400
    },
    {
      "epoch": 2.867854708345506,
      "grad_norm": 0.07703330367803574,
      "learning_rate": 8.816178141331517e-06,
      "loss": 0.1424,
      "step": 29450
    },
    {
      "epoch": 2.872723731619437,
      "grad_norm": 0.002962529892101884,
      "learning_rate": 8.4915765897361e-06,
      "loss": 0.114,
      "step": 29500
    },
    {
      "epoch": 2.877592754893368,
      "grad_norm": 2.387927770614624,
      "learning_rate": 8.166975038140682e-06,
      "loss": 0.101,
      "step": 29550
    },
    {
      "epoch": 2.8824617781672996,
      "grad_norm": 5.151456832885742,
      "learning_rate": 7.842373486545267e-06,
      "loss": 0.2021,
      "step": 29600
    },
    {
      "epoch": 2.887330801441231,
      "grad_norm": 0.12774421274662018,
      "learning_rate": 7.5177719349498495e-06,
      "loss": 0.0992,
      "step": 29650
    },
    {
      "epoch": 2.892199824715162,
      "grad_norm": 0.09454923868179321,
      "learning_rate": 7.193170383354433e-06,
      "loss": 0.0891,
      "step": 29700
    },
    {
      "epoch": 2.897068847989093,
      "grad_norm": 0.011025218293070793,
      "learning_rate": 6.868568831759016e-06,
      "loss": 0.0655,
      "step": 29750
    },
    {
      "epoch": 2.9019378712630246,
      "grad_norm": 0.03313419967889786,
      "learning_rate": 6.5439672801636004e-06,
      "loss": 0.0968,
      "step": 29800
    },
    {
      "epoch": 2.906806894536956,
      "grad_norm": 0.25370314717292786,
      "learning_rate": 6.219365728568182e-06,
      "loss": 0.1445,
      "step": 29850
    },
    {
      "epoch": 2.911675917810887,
      "grad_norm": 0.009819175116717815,
      "learning_rate": 5.894764176972766e-06,
      "loss": 0.1023,
      "step": 29900
    },
    {
      "epoch": 2.9165449410848185,
      "grad_norm": 0.0405968576669693,
      "learning_rate": 5.57016262537735e-06,
      "loss": 0.0395,
      "step": 29950
    },
    {
      "epoch": 2.9214139643587496,
      "grad_norm": 1.4044722318649292,
      "learning_rate": 5.2455610737819325e-06,
      "loss": 0.0695,
      "step": 30000
    },
    {
      "epoch": 2.926282987632681,
      "grad_norm": 0.11206701397895813,
      "learning_rate": 4.920959522186516e-06,
      "loss": 0.0927,
      "step": 30050
    },
    {
      "epoch": 2.931152010906612,
      "grad_norm": 0.022548507899045944,
      "learning_rate": 4.5963579705911e-06,
      "loss": 0.1613,
      "step": 30100
    },
    {
      "epoch": 2.9360210341805435,
      "grad_norm": 0.017089994624257088,
      "learning_rate": 4.2717564189956826e-06,
      "loss": 0.0988,
      "step": 30150
    },
    {
      "epoch": 2.9408900574544745,
      "grad_norm": 0.023357020691037178,
      "learning_rate": 3.947154867400266e-06,
      "loss": 0.049,
      "step": 30200
    },
    {
      "epoch": 2.945759080728406,
      "grad_norm": 0.03176746144890785,
      "learning_rate": 3.62255331580485e-06,
      "loss": 0.1194,
      "step": 30250
    },
    {
      "epoch": 2.950628104002337,
      "grad_norm": 5.269527435302734,
      "learning_rate": 3.297951764209433e-06,
      "loss": 0.1759,
      "step": 30300
    },
    {
      "epoch": 2.9554971272762685,
      "grad_norm": 0.010243800468742847,
      "learning_rate": 2.9733502126140163e-06,
      "loss": 0.1239,
      "step": 30350
    },
    {
      "epoch": 2.9603661505501995,
      "grad_norm": 0.8710947036743164,
      "learning_rate": 2.6487486610186e-06,
      "loss": 0.0884,
      "step": 30400
    },
    {
      "epoch": 2.965235173824131,
      "grad_norm": 0.013553702272474766,
      "learning_rate": 2.324147109423183e-06,
      "loss": 0.0511,
      "step": 30450
    },
    {
      "epoch": 2.9701041970980624,
      "grad_norm": 0.6602165102958679,
      "learning_rate": 1.9995455578277664e-06,
      "loss": 0.0938,
      "step": 30500
    },
    {
      "epoch": 2.9749732203719934,
      "grad_norm": 0.01840139366686344,
      "learning_rate": 1.6749440062323498e-06,
      "loss": 0.075,
      "step": 30550
    },
    {
      "epoch": 2.9798422436459244,
      "grad_norm": 7.60942268371582,
      "learning_rate": 1.3503424546369333e-06,
      "loss": 0.0595,
      "step": 30600
    },
    {
      "epoch": 2.984711266919856,
      "grad_norm": 0.10182466357946396,
      "learning_rate": 1.0257409030415167e-06,
      "loss": 0.1083,
      "step": 30650
    },
    {
      "epoch": 2.9895802901937873,
      "grad_norm": 4.832775592803955,
      "learning_rate": 7.011393514460999e-07,
      "loss": 0.2315,
      "step": 30700
    },
    {
      "epoch": 2.9944493134677184,
      "grad_norm": 0.20459260046482086,
      "learning_rate": 3.765377998506833e-07,
      "loss": 0.0795,
      "step": 30750
    },
    {
      "epoch": 2.9993183367416494,
      "grad_norm": 0.02778891660273075,
      "learning_rate": 5.193624825526667e-08,
      "loss": 0.1503,
      "step": 30800
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9751314636283961,
      "eval_loss": 0.11114534735679626,
      "eval_runtime": 80.5083,
      "eval_samples_per_second": 113.38,
      "eval_steps_per_second": 7.092,
      "step": 30807
    }
  ],
  "logging_steps": 50,
  "max_steps": 30807,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.95946722179342e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
