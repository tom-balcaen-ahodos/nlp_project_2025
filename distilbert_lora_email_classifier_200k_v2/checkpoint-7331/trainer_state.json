{
  "best_global_step": 7331,
  "best_metric": 0.9779789764444103,
  "best_model_checkpoint": "./distilbert_lora_email_classifier_200k_v2\\checkpoint-7331",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 7331,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006820351930159597,
      "grad_norm": 0.6565218567848206,
      "learning_rate": 0.00019866321102168872,
      "loss": 0.2864,
      "step": 50
    },
    {
      "epoch": 0.013640703860319193,
      "grad_norm": 1.6958614587783813,
      "learning_rate": 0.0001972991406356568,
      "loss": 0.2799,
      "step": 100
    },
    {
      "epoch": 0.02046105579047879,
      "grad_norm": 1.5150078535079956,
      "learning_rate": 0.00019593507024962488,
      "loss": 0.1996,
      "step": 150
    },
    {
      "epoch": 0.027281407720638386,
      "grad_norm": 1.0914299488067627,
      "learning_rate": 0.00019457099986359296,
      "loss": 0.171,
      "step": 200
    },
    {
      "epoch": 0.03410175965079798,
      "grad_norm": 0.3266277313232422,
      "learning_rate": 0.00019320692947756105,
      "loss": 0.1523,
      "step": 250
    },
    {
      "epoch": 0.04092211158095758,
      "grad_norm": 0.22369997203350067,
      "learning_rate": 0.00019184285909152913,
      "loss": 0.1408,
      "step": 300
    },
    {
      "epoch": 0.047742463511117175,
      "grad_norm": 0.14824369549751282,
      "learning_rate": 0.0001904787887054972,
      "loss": 0.1125,
      "step": 350
    },
    {
      "epoch": 0.05456281544127677,
      "grad_norm": 0.7631741166114807,
      "learning_rate": 0.0001891147183194653,
      "loss": 0.1452,
      "step": 400
    },
    {
      "epoch": 0.06138316737143636,
      "grad_norm": 0.4790585935115814,
      "learning_rate": 0.00018775064793343337,
      "loss": 0.1423,
      "step": 450
    },
    {
      "epoch": 0.06820351930159596,
      "grad_norm": 0.09780961275100708,
      "learning_rate": 0.00018638657754740145,
      "loss": 0.119,
      "step": 500
    },
    {
      "epoch": 0.07502387123175557,
      "grad_norm": 1.2285807132720947,
      "learning_rate": 0.00018502250716136953,
      "loss": 0.1449,
      "step": 550
    },
    {
      "epoch": 0.08184422316191516,
      "grad_norm": 0.11868440359830856,
      "learning_rate": 0.00018365843677533761,
      "loss": 0.1418,
      "step": 600
    },
    {
      "epoch": 0.08866457509207475,
      "grad_norm": 0.1289055347442627,
      "learning_rate": 0.0001822943663893057,
      "loss": 0.0986,
      "step": 650
    },
    {
      "epoch": 0.09548492702223435,
      "grad_norm": 0.6421812176704407,
      "learning_rate": 0.00018093029600327378,
      "loss": 0.1684,
      "step": 700
    },
    {
      "epoch": 0.10230527895239394,
      "grad_norm": 1.0893235206604004,
      "learning_rate": 0.00017956622561724186,
      "loss": 0.1178,
      "step": 750
    },
    {
      "epoch": 0.10912563088255355,
      "grad_norm": 0.14906124770641327,
      "learning_rate": 0.00017820215523120994,
      "loss": 0.1003,
      "step": 800
    },
    {
      "epoch": 0.11594598281271314,
      "grad_norm": 0.23727618157863617,
      "learning_rate": 0.00017683808484517802,
      "loss": 0.1293,
      "step": 850
    },
    {
      "epoch": 0.12276633474287273,
      "grad_norm": 0.18046851456165314,
      "learning_rate": 0.0001754740144591461,
      "loss": 0.1123,
      "step": 900
    },
    {
      "epoch": 0.12958668667303233,
      "grad_norm": 0.1012127622961998,
      "learning_rate": 0.00017410994407311418,
      "loss": 0.1105,
      "step": 950
    },
    {
      "epoch": 0.13640703860319192,
      "grad_norm": 1.3035821914672852,
      "learning_rate": 0.00017274587368708226,
      "loss": 0.1489,
      "step": 1000
    },
    {
      "epoch": 0.1432273905333515,
      "grad_norm": 1.3226304054260254,
      "learning_rate": 0.00017138180330105034,
      "loss": 0.101,
      "step": 1050
    },
    {
      "epoch": 0.15004774246351113,
      "grad_norm": 0.5309241414070129,
      "learning_rate": 0.00017001773291501842,
      "loss": 0.1232,
      "step": 1100
    },
    {
      "epoch": 0.15686809439367072,
      "grad_norm": 1.3184473514556885,
      "learning_rate": 0.0001686536625289865,
      "loss": 0.105,
      "step": 1150
    },
    {
      "epoch": 0.1636884463238303,
      "grad_norm": 2.2960877418518066,
      "learning_rate": 0.0001672895921429546,
      "loss": 0.1395,
      "step": 1200
    },
    {
      "epoch": 0.1705087982539899,
      "grad_norm": 1.4435700178146362,
      "learning_rate": 0.00016592552175692267,
      "loss": 0.1059,
      "step": 1250
    },
    {
      "epoch": 0.1773291501841495,
      "grad_norm": 2.558826208114624,
      "learning_rate": 0.00016456145137089075,
      "loss": 0.0916,
      "step": 1300
    },
    {
      "epoch": 0.1841495021143091,
      "grad_norm": 1.2581326961517334,
      "learning_rate": 0.0001631973809848588,
      "loss": 0.1191,
      "step": 1350
    },
    {
      "epoch": 0.1909698540444687,
      "grad_norm": 1.7096537351608276,
      "learning_rate": 0.0001618333105988269,
      "loss": 0.1152,
      "step": 1400
    },
    {
      "epoch": 0.1977902059746283,
      "grad_norm": 3.448120594024658,
      "learning_rate": 0.000160469240212795,
      "loss": 0.0901,
      "step": 1450
    },
    {
      "epoch": 0.20461055790478788,
      "grad_norm": 0.3275609612464905,
      "learning_rate": 0.00015910516982676307,
      "loss": 0.12,
      "step": 1500
    },
    {
      "epoch": 0.21143090983494747,
      "grad_norm": 1.7140767574310303,
      "learning_rate": 0.00015774109944073115,
      "loss": 0.1314,
      "step": 1550
    },
    {
      "epoch": 0.2182512617651071,
      "grad_norm": 0.10904519259929657,
      "learning_rate": 0.0001563770290546992,
      "loss": 0.0889,
      "step": 1600
    },
    {
      "epoch": 0.22507161369526668,
      "grad_norm": 0.23065948486328125,
      "learning_rate": 0.00015501295866866732,
      "loss": 0.106,
      "step": 1650
    },
    {
      "epoch": 0.23189196562542627,
      "grad_norm": 1.991782546043396,
      "learning_rate": 0.0001536488882826354,
      "loss": 0.0998,
      "step": 1700
    },
    {
      "epoch": 0.23871231755558586,
      "grad_norm": 0.16478188335895538,
      "learning_rate": 0.00015228481789660348,
      "loss": 0.107,
      "step": 1750
    },
    {
      "epoch": 0.24553266948574545,
      "grad_norm": 0.13939253985881805,
      "learning_rate": 0.00015092074751057156,
      "loss": 0.0787,
      "step": 1800
    },
    {
      "epoch": 0.25235302141590504,
      "grad_norm": 1.4067331552505493,
      "learning_rate": 0.00014955667712453961,
      "loss": 0.0921,
      "step": 1850
    },
    {
      "epoch": 0.25917337334606466,
      "grad_norm": 1.4012291431427002,
      "learning_rate": 0.00014819260673850772,
      "loss": 0.0945,
      "step": 1900
    },
    {
      "epoch": 0.2659937252762243,
      "grad_norm": 0.4972184896469116,
      "learning_rate": 0.0001468285363524758,
      "loss": 0.0975,
      "step": 1950
    },
    {
      "epoch": 0.27281407720638384,
      "grad_norm": 0.5868608951568604,
      "learning_rate": 0.00014546446596644389,
      "loss": 0.1033,
      "step": 2000
    },
    {
      "epoch": 0.27963442913654346,
      "grad_norm": 0.09678611159324646,
      "learning_rate": 0.00014410039558041194,
      "loss": 0.0883,
      "step": 2050
    },
    {
      "epoch": 0.286454781066703,
      "grad_norm": 1.6808252334594727,
      "learning_rate": 0.00014273632519438002,
      "loss": 0.0773,
      "step": 2100
    },
    {
      "epoch": 0.29327513299686264,
      "grad_norm": 2.4182398319244385,
      "learning_rate": 0.00014137225480834813,
      "loss": 0.0967,
      "step": 2150
    },
    {
      "epoch": 0.30009548492702226,
      "grad_norm": 1.1235723495483398,
      "learning_rate": 0.0001400081844223162,
      "loss": 0.1068,
      "step": 2200
    },
    {
      "epoch": 0.3069158368571818,
      "grad_norm": 2.164094924926758,
      "learning_rate": 0.0001386441140362843,
      "loss": 0.0932,
      "step": 2250
    },
    {
      "epoch": 0.31373618878734144,
      "grad_norm": 0.8293538689613342,
      "learning_rate": 0.00013728004365025234,
      "loss": 0.0962,
      "step": 2300
    },
    {
      "epoch": 0.320556540717501,
      "grad_norm": 0.7766249775886536,
      "learning_rate": 0.00013591597326422043,
      "loss": 0.0835,
      "step": 2350
    },
    {
      "epoch": 0.3273768926476606,
      "grad_norm": 1.1470553874969482,
      "learning_rate": 0.00013455190287818853,
      "loss": 0.0923,
      "step": 2400
    },
    {
      "epoch": 0.33419724457782024,
      "grad_norm": 3.1214334964752197,
      "learning_rate": 0.00013318783249215662,
      "loss": 0.1026,
      "step": 2450
    },
    {
      "epoch": 0.3410175965079798,
      "grad_norm": 1.2580174207687378,
      "learning_rate": 0.00013182376210612467,
      "loss": 0.0847,
      "step": 2500
    },
    {
      "epoch": 0.3478379484381394,
      "grad_norm": 0.15330375730991364,
      "learning_rate": 0.00013045969172009275,
      "loss": 0.1025,
      "step": 2550
    },
    {
      "epoch": 0.354658300368299,
      "grad_norm": 1.5736335515975952,
      "learning_rate": 0.00012909562133406083,
      "loss": 0.0717,
      "step": 2600
    },
    {
      "epoch": 0.3614786522984586,
      "grad_norm": 1.7529922723770142,
      "learning_rate": 0.00012773155094802894,
      "loss": 0.1247,
      "step": 2650
    },
    {
      "epoch": 0.3682990042286182,
      "grad_norm": 1.7776360511779785,
      "learning_rate": 0.00012636748056199702,
      "loss": 0.1124,
      "step": 2700
    },
    {
      "epoch": 0.3751193561587778,
      "grad_norm": 1.495261311531067,
      "learning_rate": 0.00012500341017596507,
      "loss": 0.1242,
      "step": 2750
    },
    {
      "epoch": 0.3819397080889374,
      "grad_norm": 0.9115184545516968,
      "learning_rate": 0.00012363933978993316,
      "loss": 0.1164,
      "step": 2800
    },
    {
      "epoch": 0.38876006001909696,
      "grad_norm": 0.03448610380291939,
      "learning_rate": 0.00012227526940390124,
      "loss": 0.0733,
      "step": 2850
    },
    {
      "epoch": 0.3955804119492566,
      "grad_norm": 2.9463348388671875,
      "learning_rate": 0.00012091119901786933,
      "loss": 0.0818,
      "step": 2900
    },
    {
      "epoch": 0.4024007638794162,
      "grad_norm": 1.2210170030593872,
      "learning_rate": 0.00011954712863183741,
      "loss": 0.1111,
      "step": 2950
    },
    {
      "epoch": 0.40922111580957576,
      "grad_norm": 0.13864780962467194,
      "learning_rate": 0.0001181830582458055,
      "loss": 0.097,
      "step": 3000
    },
    {
      "epoch": 0.4160414677397354,
      "grad_norm": 2.240746259689331,
      "learning_rate": 0.00011681898785977356,
      "loss": 0.0794,
      "step": 3050
    },
    {
      "epoch": 0.42286181966989494,
      "grad_norm": 0.3030146658420563,
      "learning_rate": 0.00011545491747374164,
      "loss": 0.0916,
      "step": 3100
    },
    {
      "epoch": 0.42968217160005456,
      "grad_norm": 0.16579699516296387,
      "learning_rate": 0.00011409084708770974,
      "loss": 0.0811,
      "step": 3150
    },
    {
      "epoch": 0.4365025235302142,
      "grad_norm": 0.1674370914697647,
      "learning_rate": 0.00011272677670167782,
      "loss": 0.0721,
      "step": 3200
    },
    {
      "epoch": 0.44332287546037374,
      "grad_norm": 3.0351622104644775,
      "learning_rate": 0.0001113627063156459,
      "loss": 0.103,
      "step": 3250
    },
    {
      "epoch": 0.45014322739053336,
      "grad_norm": 0.25664207339286804,
      "learning_rate": 0.00010999863592961397,
      "loss": 0.0798,
      "step": 3300
    },
    {
      "epoch": 0.4569635793206929,
      "grad_norm": 0.6197370886802673,
      "learning_rate": 0.00010863456554358205,
      "loss": 0.0981,
      "step": 3350
    },
    {
      "epoch": 0.46378393125085254,
      "grad_norm": 2.04634690284729,
      "learning_rate": 0.00010727049515755014,
      "loss": 0.0872,
      "step": 3400
    },
    {
      "epoch": 0.47060428318101216,
      "grad_norm": 0.8053659796714783,
      "learning_rate": 0.00010590642477151822,
      "loss": 0.0899,
      "step": 3450
    },
    {
      "epoch": 0.4774246351111717,
      "grad_norm": 0.9309519529342651,
      "learning_rate": 0.00010454235438548629,
      "loss": 0.0391,
      "step": 3500
    },
    {
      "epoch": 0.48424498704133134,
      "grad_norm": 2.383859157562256,
      "learning_rate": 0.00010317828399945437,
      "loss": 0.1076,
      "step": 3550
    },
    {
      "epoch": 0.4910653389714909,
      "grad_norm": 0.07400316745042801,
      "learning_rate": 0.00010181421361342245,
      "loss": 0.0708,
      "step": 3600
    },
    {
      "epoch": 0.4978856909016505,
      "grad_norm": 0.5775966048240662,
      "learning_rate": 0.00010045014322739055,
      "loss": 0.0909,
      "step": 3650
    },
    {
      "epoch": 0.5047060428318101,
      "grad_norm": 0.19565685093402863,
      "learning_rate": 9.908607284135863e-05,
      "loss": 0.0968,
      "step": 3700
    },
    {
      "epoch": 0.5115263947619697,
      "grad_norm": 2.823364019393921,
      "learning_rate": 9.77220024553267e-05,
      "loss": 0.075,
      "step": 3750
    },
    {
      "epoch": 0.5183467466921293,
      "grad_norm": 0.18413643538951874,
      "learning_rate": 9.635793206929478e-05,
      "loss": 0.0925,
      "step": 3800
    },
    {
      "epoch": 0.5251670986222889,
      "grad_norm": 0.28409871459007263,
      "learning_rate": 9.499386168326286e-05,
      "loss": 0.115,
      "step": 3850
    },
    {
      "epoch": 0.5319874505524486,
      "grad_norm": 1.2897062301635742,
      "learning_rate": 9.362979129723094e-05,
      "loss": 0.1327,
      "step": 3900
    },
    {
      "epoch": 0.5388078024826081,
      "grad_norm": 0.14924509823322296,
      "learning_rate": 9.226572091119902e-05,
      "loss": 0.0836,
      "step": 3950
    },
    {
      "epoch": 0.5456281544127677,
      "grad_norm": 0.30304232239723206,
      "learning_rate": 9.09016505251671e-05,
      "loss": 0.1232,
      "step": 4000
    },
    {
      "epoch": 0.5524485063429273,
      "grad_norm": 0.17036442458629608,
      "learning_rate": 8.953758013913518e-05,
      "loss": 0.1065,
      "step": 4050
    },
    {
      "epoch": 0.5592688582730869,
      "grad_norm": 1.4926286935806274,
      "learning_rate": 8.817350975310326e-05,
      "loss": 0.0886,
      "step": 4100
    },
    {
      "epoch": 0.5660892102032465,
      "grad_norm": 0.7092735171318054,
      "learning_rate": 8.680943936707135e-05,
      "loss": 0.071,
      "step": 4150
    },
    {
      "epoch": 0.572909562133406,
      "grad_norm": 0.22205038368701935,
      "learning_rate": 8.544536898103943e-05,
      "loss": 0.0929,
      "step": 4200
    },
    {
      "epoch": 0.5797299140635657,
      "grad_norm": 1.6171231269836426,
      "learning_rate": 8.408129859500751e-05,
      "loss": 0.0829,
      "step": 4250
    },
    {
      "epoch": 0.5865502659937253,
      "grad_norm": 0.3361441195011139,
      "learning_rate": 8.271722820897559e-05,
      "loss": 0.0635,
      "step": 4300
    },
    {
      "epoch": 0.5933706179238849,
      "grad_norm": 0.17639464139938354,
      "learning_rate": 8.135315782294367e-05,
      "loss": 0.0788,
      "step": 4350
    },
    {
      "epoch": 0.6001909698540445,
      "grad_norm": 0.6084955930709839,
      "learning_rate": 7.998908743691175e-05,
      "loss": 0.075,
      "step": 4400
    },
    {
      "epoch": 0.607011321784204,
      "grad_norm": 0.46884453296661377,
      "learning_rate": 7.862501705087983e-05,
      "loss": 0.0723,
      "step": 4450
    },
    {
      "epoch": 0.6138316737143636,
      "grad_norm": 0.1478203386068344,
      "learning_rate": 7.726094666484791e-05,
      "loss": 0.0835,
      "step": 4500
    },
    {
      "epoch": 0.6206520256445233,
      "grad_norm": 0.18091970682144165,
      "learning_rate": 7.589687627881598e-05,
      "loss": 0.0849,
      "step": 4550
    },
    {
      "epoch": 0.6274723775746829,
      "grad_norm": 0.05177577957510948,
      "learning_rate": 7.453280589278408e-05,
      "loss": 0.0685,
      "step": 4600
    },
    {
      "epoch": 0.6342927295048425,
      "grad_norm": 1.115023136138916,
      "learning_rate": 7.316873550675216e-05,
      "loss": 0.0906,
      "step": 4650
    },
    {
      "epoch": 0.641113081435002,
      "grad_norm": 0.9967670440673828,
      "learning_rate": 7.180466512072024e-05,
      "loss": 0.0398,
      "step": 4700
    },
    {
      "epoch": 0.6479334333651616,
      "grad_norm": 1.913278579711914,
      "learning_rate": 7.044059473468832e-05,
      "loss": 0.0732,
      "step": 4750
    },
    {
      "epoch": 0.6547537852953212,
      "grad_norm": 0.8246878981590271,
      "learning_rate": 6.907652434865639e-05,
      "loss": 0.0801,
      "step": 4800
    },
    {
      "epoch": 0.6615741372254809,
      "grad_norm": 0.14463283121585846,
      "learning_rate": 6.771245396262448e-05,
      "loss": 0.1194,
      "step": 4850
    },
    {
      "epoch": 0.6683944891556405,
      "grad_norm": 0.17662718892097473,
      "learning_rate": 6.634838357659255e-05,
      "loss": 0.0932,
      "step": 4900
    },
    {
      "epoch": 0.6752148410858,
      "grad_norm": 0.40582630038261414,
      "learning_rate": 6.498431319056063e-05,
      "loss": 0.0814,
      "step": 4950
    },
    {
      "epoch": 0.6820351930159596,
      "grad_norm": 0.444558322429657,
      "learning_rate": 6.362024280452871e-05,
      "loss": 0.0585,
      "step": 5000
    },
    {
      "epoch": 0.6888555449461192,
      "grad_norm": 2.1582412719726562,
      "learning_rate": 6.225617241849679e-05,
      "loss": 0.1178,
      "step": 5050
    },
    {
      "epoch": 0.6956758968762788,
      "grad_norm": 1.6856212615966797,
      "learning_rate": 6.089210203246488e-05,
      "loss": 0.096,
      "step": 5100
    },
    {
      "epoch": 0.7024962488064385,
      "grad_norm": 1.45680570602417,
      "learning_rate": 5.9528031646432955e-05,
      "loss": 0.0792,
      "step": 5150
    },
    {
      "epoch": 0.709316600736598,
      "grad_norm": 0.7494940161705017,
      "learning_rate": 5.8163961260401036e-05,
      "loss": 0.0482,
      "step": 5200
    },
    {
      "epoch": 0.7161369526667576,
      "grad_norm": 0.1018027737736702,
      "learning_rate": 5.6799890874369124e-05,
      "loss": 0.0766,
      "step": 5250
    },
    {
      "epoch": 0.7229573045969172,
      "grad_norm": 0.5473459959030151,
      "learning_rate": 5.54358204883372e-05,
      "loss": 0.0854,
      "step": 5300
    },
    {
      "epoch": 0.7297776565270768,
      "grad_norm": 6.024042129516602,
      "learning_rate": 5.4071750102305286e-05,
      "loss": 0.076,
      "step": 5350
    },
    {
      "epoch": 0.7365980084572364,
      "grad_norm": 0.11344782263040543,
      "learning_rate": 5.270767971627336e-05,
      "loss": 0.0752,
      "step": 5400
    },
    {
      "epoch": 0.743418360387396,
      "grad_norm": 0.08957064896821976,
      "learning_rate": 5.1343609330241435e-05,
      "loss": 0.0824,
      "step": 5450
    },
    {
      "epoch": 0.7502387123175556,
      "grad_norm": 1.9776631593704224,
      "learning_rate": 4.997953894420952e-05,
      "loss": 0.0881,
      "step": 5500
    },
    {
      "epoch": 0.7570590642477152,
      "grad_norm": 2.700916051864624,
      "learning_rate": 4.861546855817761e-05,
      "loss": 0.0742,
      "step": 5550
    },
    {
      "epoch": 0.7638794161778748,
      "grad_norm": 0.7074301242828369,
      "learning_rate": 4.7251398172145685e-05,
      "loss": 0.0651,
      "step": 5600
    },
    {
      "epoch": 0.7706997681080344,
      "grad_norm": 0.1386859267950058,
      "learning_rate": 4.5887327786113766e-05,
      "loss": 0.0961,
      "step": 5650
    },
    {
      "epoch": 0.7775201200381939,
      "grad_norm": 0.18212011456489563,
      "learning_rate": 4.452325740008185e-05,
      "loss": 0.0854,
      "step": 5700
    },
    {
      "epoch": 0.7843404719683535,
      "grad_norm": 0.26860618591308594,
      "learning_rate": 4.315918701404993e-05,
      "loss": 0.074,
      "step": 5750
    },
    {
      "epoch": 0.7911608238985132,
      "grad_norm": 0.16757161915302277,
      "learning_rate": 4.1795116628018e-05,
      "loss": 0.0999,
      "step": 5800
    },
    {
      "epoch": 0.7979811758286728,
      "grad_norm": 0.4615209400653839,
      "learning_rate": 4.0431046241986084e-05,
      "loss": 0.0476,
      "step": 5850
    },
    {
      "epoch": 0.8048015277588324,
      "grad_norm": 0.14392153918743134,
      "learning_rate": 3.906697585595417e-05,
      "loss": 0.0558,
      "step": 5900
    },
    {
      "epoch": 0.8116218796889919,
      "grad_norm": 2.2208101749420166,
      "learning_rate": 3.770290546992225e-05,
      "loss": 0.108,
      "step": 5950
    },
    {
      "epoch": 0.8184422316191515,
      "grad_norm": 0.18052271008491516,
      "learning_rate": 3.6338835083890334e-05,
      "loss": 0.0662,
      "step": 6000
    },
    {
      "epoch": 0.8252625835493111,
      "grad_norm": 1.240738034248352,
      "learning_rate": 3.497476469785841e-05,
      "loss": 0.0548,
      "step": 6050
    },
    {
      "epoch": 0.8320829354794708,
      "grad_norm": 0.4012220501899719,
      "learning_rate": 3.361069431182649e-05,
      "loss": 0.0514,
      "step": 6100
    },
    {
      "epoch": 0.8389032874096304,
      "grad_norm": 0.13537994027137756,
      "learning_rate": 3.224662392579457e-05,
      "loss": 0.0551,
      "step": 6150
    },
    {
      "epoch": 0.8457236393397899,
      "grad_norm": 0.028622282668948174,
      "learning_rate": 3.088255353976265e-05,
      "loss": 0.0972,
      "step": 6200
    },
    {
      "epoch": 0.8525439912699495,
      "grad_norm": 0.34165680408477783,
      "learning_rate": 2.9518483153730736e-05,
      "loss": 0.0886,
      "step": 6250
    },
    {
      "epoch": 0.8593643432001091,
      "grad_norm": 1.7463241815567017,
      "learning_rate": 2.8154412767698814e-05,
      "loss": 0.0548,
      "step": 6300
    },
    {
      "epoch": 0.8661846951302687,
      "grad_norm": 0.041574928909540176,
      "learning_rate": 2.6790342381666895e-05,
      "loss": 0.0618,
      "step": 6350
    },
    {
      "epoch": 0.8730050470604284,
      "grad_norm": 0.06039295718073845,
      "learning_rate": 2.5426271995634976e-05,
      "loss": 0.0448,
      "step": 6400
    },
    {
      "epoch": 0.8798253989905879,
      "grad_norm": 0.04253740608692169,
      "learning_rate": 2.4062201609603057e-05,
      "loss": 0.0733,
      "step": 6450
    },
    {
      "epoch": 0.8866457509207475,
      "grad_norm": 3.533109664916992,
      "learning_rate": 2.2698131223571138e-05,
      "loss": 0.0918,
      "step": 6500
    },
    {
      "epoch": 0.8934661028509071,
      "grad_norm": 2.7767281532287598,
      "learning_rate": 2.133406083753922e-05,
      "loss": 0.0837,
      "step": 6550
    },
    {
      "epoch": 0.9002864547810667,
      "grad_norm": 0.05919407308101654,
      "learning_rate": 1.9969990451507297e-05,
      "loss": 0.0635,
      "step": 6600
    },
    {
      "epoch": 0.9071068067112263,
      "grad_norm": 0.3109517991542816,
      "learning_rate": 1.8605920065475378e-05,
      "loss": 0.092,
      "step": 6650
    },
    {
      "epoch": 0.9139271586413859,
      "grad_norm": 0.056262679398059845,
      "learning_rate": 1.7241849679443463e-05,
      "loss": 0.0766,
      "step": 6700
    },
    {
      "epoch": 0.9207475105715455,
      "grad_norm": 0.25695452094078064,
      "learning_rate": 1.587777929341154e-05,
      "loss": 0.1022,
      "step": 6750
    },
    {
      "epoch": 0.9275678625017051,
      "grad_norm": 0.08933079242706299,
      "learning_rate": 1.4513708907379623e-05,
      "loss": 0.0811,
      "step": 6800
    },
    {
      "epoch": 0.9343882144318647,
      "grad_norm": 0.09207475930452347,
      "learning_rate": 1.31496385213477e-05,
      "loss": 0.0735,
      "step": 6850
    },
    {
      "epoch": 0.9412085663620243,
      "grad_norm": 0.749980628490448,
      "learning_rate": 1.1785568135315784e-05,
      "loss": 0.067,
      "step": 6900
    },
    {
      "epoch": 0.9480289182921838,
      "grad_norm": 5.882554531097412,
      "learning_rate": 1.0421497749283863e-05,
      "loss": 0.0474,
      "step": 6950
    },
    {
      "epoch": 0.9548492702223434,
      "grad_norm": 0.15048767626285553,
      "learning_rate": 9.057427363251944e-06,
      "loss": 0.0694,
      "step": 7000
    },
    {
      "epoch": 0.9616696221525031,
      "grad_norm": 3.153898000717163,
      "learning_rate": 7.693356977220025e-06,
      "loss": 0.0591,
      "step": 7050
    },
    {
      "epoch": 0.9684899740826627,
      "grad_norm": 3.577335834503174,
      "learning_rate": 6.329286591188105e-06,
      "loss": 0.0494,
      "step": 7100
    },
    {
      "epoch": 0.9753103260128223,
      "grad_norm": 2.1908469200134277,
      "learning_rate": 4.965216205156186e-06,
      "loss": 0.0752,
      "step": 7150
    },
    {
      "epoch": 0.9821306779429818,
      "grad_norm": 0.08259302377700806,
      "learning_rate": 3.6011458191242674e-06,
      "loss": 0.0835,
      "step": 7200
    },
    {
      "epoch": 0.9889510298731414,
      "grad_norm": 0.08415159583091736,
      "learning_rate": 2.2370754330923476e-06,
      "loss": 0.0685,
      "step": 7250
    },
    {
      "epoch": 0.995771381803301,
      "grad_norm": 1.8100590705871582,
      "learning_rate": 8.730050470604283e-07,
      "loss": 0.0838,
      "step": 7300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9779789764444103,
      "eval_loss": 0.07342293113470078,
      "eval_runtime": 108.1633,
      "eval_samples_per_second": 120.494,
      "eval_steps_per_second": 3.772,
      "step": 7331
    }
  ],
  "logging_steps": 50,
  "max_steps": 7331,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.5483093950085888e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
