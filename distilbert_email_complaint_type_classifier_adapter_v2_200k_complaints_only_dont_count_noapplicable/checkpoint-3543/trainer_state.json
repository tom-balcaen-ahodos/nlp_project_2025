{
  "best_global_step": 3543,
  "best_metric": 0.9076190476190477,
  "best_model_checkpoint": "./distilbert_email_complaint_type_classifier_adapter_v2_200k_complaints_only_dont_count_noapplicable\\checkpoint-3543",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 3543,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04233700254022015,
      "grad_norm": 1.9319058656692505,
      "learning_rate": 0.0001972339825007056,
      "loss": 1.1675,
      "step": 50
    },
    {
      "epoch": 0.0846740050804403,
      "grad_norm": 1.8554344177246094,
      "learning_rate": 0.00019441151566469095,
      "loss": 1.0615,
      "step": 100
    },
    {
      "epoch": 0.12701100762066045,
      "grad_norm": 4.9786763191223145,
      "learning_rate": 0.00019158904882867628,
      "loss": 0.7952,
      "step": 150
    },
    {
      "epoch": 0.1693480101608806,
      "grad_norm": 5.093390941619873,
      "learning_rate": 0.0001887665819926616,
      "loss": 0.7476,
      "step": 200
    },
    {
      "epoch": 0.21168501270110077,
      "grad_norm": 6.543839931488037,
      "learning_rate": 0.00018594411515664692,
      "loss": 0.6602,
      "step": 250
    },
    {
      "epoch": 0.2540220152413209,
      "grad_norm": 5.355769634246826,
      "learning_rate": 0.00018312164832063224,
      "loss": 0.6419,
      "step": 300
    },
    {
      "epoch": 0.29635901778154106,
      "grad_norm": 11.072619438171387,
      "learning_rate": 0.00018029918148461757,
      "loss": 0.6058,
      "step": 350
    },
    {
      "epoch": 0.3386960203217612,
      "grad_norm": 4.19959831237793,
      "learning_rate": 0.0001774767146486029,
      "loss": 0.5893,
      "step": 400
    },
    {
      "epoch": 0.3810330228619814,
      "grad_norm": 4.498571395874023,
      "learning_rate": 0.0001746542478125882,
      "loss": 0.5726,
      "step": 450
    },
    {
      "epoch": 0.42337002540220153,
      "grad_norm": 5.24044132232666,
      "learning_rate": 0.00017183178097657353,
      "loss": 0.6078,
      "step": 500
    },
    {
      "epoch": 0.4657070279424217,
      "grad_norm": 5.221506118774414,
      "learning_rate": 0.00016900931414055886,
      "loss": 0.5591,
      "step": 550
    },
    {
      "epoch": 0.5080440304826418,
      "grad_norm": 5.683713912963867,
      "learning_rate": 0.00016618684730454418,
      "loss": 0.4569,
      "step": 600
    },
    {
      "epoch": 0.550381033022862,
      "grad_norm": 1.3916338682174683,
      "learning_rate": 0.0001633643804685295,
      "loss": 0.513,
      "step": 650
    },
    {
      "epoch": 0.5927180355630821,
      "grad_norm": 1.7609145641326904,
      "learning_rate": 0.00016054191363251482,
      "loss": 0.5441,
      "step": 700
    },
    {
      "epoch": 0.6350550381033023,
      "grad_norm": 5.4414238929748535,
      "learning_rate": 0.00015771944679650015,
      "loss": 0.4737,
      "step": 750
    },
    {
      "epoch": 0.6773920406435224,
      "grad_norm": 5.710789203643799,
      "learning_rate": 0.00015489697996048547,
      "loss": 0.5466,
      "step": 800
    },
    {
      "epoch": 0.7197290431837426,
      "grad_norm": 3.255445718765259,
      "learning_rate": 0.0001520745131244708,
      "loss": 0.4635,
      "step": 850
    },
    {
      "epoch": 0.7620660457239627,
      "grad_norm": 6.965051174163818,
      "learning_rate": 0.00014925204628845611,
      "loss": 0.5045,
      "step": 900
    },
    {
      "epoch": 0.8044030482641829,
      "grad_norm": 2.8612403869628906,
      "learning_rate": 0.00014642957945244144,
      "loss": 0.5091,
      "step": 950
    },
    {
      "epoch": 0.8467400508044031,
      "grad_norm": 4.2300310134887695,
      "learning_rate": 0.00014360711261642676,
      "loss": 0.4394,
      "step": 1000
    },
    {
      "epoch": 0.8890770533446232,
      "grad_norm": 4.737188816070557,
      "learning_rate": 0.00014078464578041208,
      "loss": 0.4177,
      "step": 1050
    },
    {
      "epoch": 0.9314140558848434,
      "grad_norm": 7.772960662841797,
      "learning_rate": 0.0001379621789443974,
      "loss": 0.5195,
      "step": 1100
    },
    {
      "epoch": 0.9737510584250635,
      "grad_norm": 7.004505634307861,
      "learning_rate": 0.00013513971210838275,
      "loss": 0.4914,
      "step": 1150
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8504761904761905,
      "eval_loss": 0.37277883291244507,
      "eval_runtime": 8.6844,
      "eval_samples_per_second": 120.907,
      "eval_steps_per_second": 7.6,
      "step": 1181
    },
    {
      "epoch": 1.0160880609652836,
      "grad_norm": 6.049444675445557,
      "learning_rate": 0.00013231724527236805,
      "loss": 0.4204,
      "step": 1200
    },
    {
      "epoch": 1.058425063505504,
      "grad_norm": 0.9770016074180603,
      "learning_rate": 0.00012949477843635337,
      "loss": 0.405,
      "step": 1250
    },
    {
      "epoch": 1.100762066045724,
      "grad_norm": 3.718984365463257,
      "learning_rate": 0.0001266723116003387,
      "loss": 0.3378,
      "step": 1300
    },
    {
      "epoch": 1.1430990685859441,
      "grad_norm": 4.046963691711426,
      "learning_rate": 0.00012384984476432402,
      "loss": 0.3816,
      "step": 1350
    },
    {
      "epoch": 1.1854360711261642,
      "grad_norm": 6.194491863250732,
      "learning_rate": 0.00012102737792830934,
      "loss": 0.3642,
      "step": 1400
    },
    {
      "epoch": 1.2277730736663843,
      "grad_norm": 1.3832485675811768,
      "learning_rate": 0.00011820491109229468,
      "loss": 0.3517,
      "step": 1450
    },
    {
      "epoch": 1.2701100762066047,
      "grad_norm": 3.095257520675659,
      "learning_rate": 0.00011538244425628,
      "loss": 0.4585,
      "step": 1500
    },
    {
      "epoch": 1.3124470787468248,
      "grad_norm": 3.6776387691497803,
      "learning_rate": 0.00011255997742026532,
      "loss": 0.3555,
      "step": 1550
    },
    {
      "epoch": 1.3547840812870449,
      "grad_norm": 2.740973472595215,
      "learning_rate": 0.00010973751058425063,
      "loss": 0.3815,
      "step": 1600
    },
    {
      "epoch": 1.397121083827265,
      "grad_norm": 4.998585224151611,
      "learning_rate": 0.00010691504374823595,
      "loss": 0.3566,
      "step": 1650
    },
    {
      "epoch": 1.4394580863674853,
      "grad_norm": 3.0350117683410645,
      "learning_rate": 0.0001040925769122213,
      "loss": 0.3157,
      "step": 1700
    },
    {
      "epoch": 1.4817950889077054,
      "grad_norm": 6.12073278427124,
      "learning_rate": 0.00010127011007620661,
      "loss": 0.3538,
      "step": 1750
    },
    {
      "epoch": 1.5241320914479255,
      "grad_norm": 4.694882392883301,
      "learning_rate": 9.844764324019193e-05,
      "loss": 0.3482,
      "step": 1800
    },
    {
      "epoch": 1.5664690939881456,
      "grad_norm": 4.440726280212402,
      "learning_rate": 9.562517640417726e-05,
      "loss": 0.3161,
      "step": 1850
    },
    {
      "epoch": 1.6088060965283657,
      "grad_norm": 7.827319622039795,
      "learning_rate": 9.280270956816258e-05,
      "loss": 0.3849,
      "step": 1900
    },
    {
      "epoch": 1.651143099068586,
      "grad_norm": 5.721121788024902,
      "learning_rate": 8.99802427321479e-05,
      "loss": 0.3342,
      "step": 1950
    },
    {
      "epoch": 1.6934801016088061,
      "grad_norm": 5.512495994567871,
      "learning_rate": 8.715777589613322e-05,
      "loss": 0.3518,
      "step": 2000
    },
    {
      "epoch": 1.7358171041490262,
      "grad_norm": 4.171668529510498,
      "learning_rate": 8.433530906011855e-05,
      "loss": 0.3065,
      "step": 2050
    },
    {
      "epoch": 1.7781541066892466,
      "grad_norm": 7.688955307006836,
      "learning_rate": 8.151284222410387e-05,
      "loss": 0.3384,
      "step": 2100
    },
    {
      "epoch": 1.8204911092294664,
      "grad_norm": 7.012387752532959,
      "learning_rate": 7.86903753880892e-05,
      "loss": 0.3272,
      "step": 2150
    },
    {
      "epoch": 1.8628281117696868,
      "grad_norm": 5.038949489593506,
      "learning_rate": 7.586790855207451e-05,
      "loss": 0.3134,
      "step": 2200
    },
    {
      "epoch": 1.9051651143099069,
      "grad_norm": 6.396595001220703,
      "learning_rate": 7.304544171605984e-05,
      "loss": 0.482,
      "step": 2250
    },
    {
      "epoch": 1.947502116850127,
      "grad_norm": 7.3630852699279785,
      "learning_rate": 7.022297488004517e-05,
      "loss": 0.3861,
      "step": 2300
    },
    {
      "epoch": 1.9898391193903473,
      "grad_norm": 5.228825092315674,
      "learning_rate": 6.740050804403048e-05,
      "loss": 0.382,
      "step": 2350
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8866666666666667,
      "eval_loss": 0.3194538950920105,
      "eval_runtime": 8.6994,
      "eval_samples_per_second": 120.698,
      "eval_steps_per_second": 7.587,
      "step": 2362
    },
    {
      "epoch": 2.032176121930567,
      "grad_norm": 7.243467807769775,
      "learning_rate": 6.45780412080158e-05,
      "loss": 0.4099,
      "step": 2400
    },
    {
      "epoch": 2.0745131244707875,
      "grad_norm": 5.091193675994873,
      "learning_rate": 6.175557437200114e-05,
      "loss": 0.415,
      "step": 2450
    },
    {
      "epoch": 2.116850127011008,
      "grad_norm": 4.335748672485352,
      "learning_rate": 5.8933107535986456e-05,
      "loss": 0.3073,
      "step": 2500
    },
    {
      "epoch": 2.1591871295512277,
      "grad_norm": 0.7179305553436279,
      "learning_rate": 5.611064069997177e-05,
      "loss": 0.2727,
      "step": 2550
    },
    {
      "epoch": 2.201524132091448,
      "grad_norm": 5.613266944885254,
      "learning_rate": 5.32881738639571e-05,
      "loss": 0.2458,
      "step": 2600
    },
    {
      "epoch": 2.243861134631668,
      "grad_norm": 1.0576444864273071,
      "learning_rate": 5.0465707027942424e-05,
      "loss": 0.2459,
      "step": 2650
    },
    {
      "epoch": 2.2861981371718882,
      "grad_norm": 4.872332572937012,
      "learning_rate": 4.7643240191927746e-05,
      "loss": 0.2573,
      "step": 2700
    },
    {
      "epoch": 2.3285351397121086,
      "grad_norm": 7.145998477935791,
      "learning_rate": 4.482077335591307e-05,
      "loss": 0.3128,
      "step": 2750
    },
    {
      "epoch": 2.3708721422523285,
      "grad_norm": 5.764747142791748,
      "learning_rate": 4.19983065198984e-05,
      "loss": 0.2418,
      "step": 2800
    },
    {
      "epoch": 2.4132091447925488,
      "grad_norm": 4.500432968139648,
      "learning_rate": 3.9175839683883714e-05,
      "loss": 0.2454,
      "step": 2850
    },
    {
      "epoch": 2.4555461473327687,
      "grad_norm": 1.6843781471252441,
      "learning_rate": 3.6353372847869037e-05,
      "loss": 0.3784,
      "step": 2900
    },
    {
      "epoch": 2.497883149872989,
      "grad_norm": 5.795602798461914,
      "learning_rate": 3.3530906011854366e-05,
      "loss": 0.3143,
      "step": 2950
    },
    {
      "epoch": 2.5402201524132093,
      "grad_norm": 8.760055541992188,
      "learning_rate": 3.070843917583969e-05,
      "loss": 0.2705,
      "step": 3000
    },
    {
      "epoch": 2.582557154953429,
      "grad_norm": 3.173201322555542,
      "learning_rate": 2.7885972339825008e-05,
      "loss": 0.2943,
      "step": 3050
    },
    {
      "epoch": 2.6248941574936495,
      "grad_norm": 5.253972053527832,
      "learning_rate": 2.506350550381033e-05,
      "loss": 0.2967,
      "step": 3100
    },
    {
      "epoch": 2.66723116003387,
      "grad_norm": 8.190191268920898,
      "learning_rate": 2.2241038667795656e-05,
      "loss": 0.2767,
      "step": 3150
    },
    {
      "epoch": 2.7095681625740897,
      "grad_norm": 4.896036148071289,
      "learning_rate": 1.9418571831780975e-05,
      "loss": 0.2941,
      "step": 3200
    },
    {
      "epoch": 2.75190516511431,
      "grad_norm": 6.3814239501953125,
      "learning_rate": 1.65961049957663e-05,
      "loss": 0.2177,
      "step": 3250
    },
    {
      "epoch": 2.79424216765453,
      "grad_norm": 4.188165664672852,
      "learning_rate": 1.3773638159751622e-05,
      "loss": 0.272,
      "step": 3300
    },
    {
      "epoch": 2.8365791701947503,
      "grad_norm": 3.2966363430023193,
      "learning_rate": 1.0951171323736946e-05,
      "loss": 0.2971,
      "step": 3350
    },
    {
      "epoch": 2.8789161727349706,
      "grad_norm": 1.4983822107315063,
      "learning_rate": 8.128704487722269e-06,
      "loss": 0.2317,
      "step": 3400
    },
    {
      "epoch": 2.9212531752751905,
      "grad_norm": 5.006903171539307,
      "learning_rate": 5.306237651707593e-06,
      "loss": 0.2248,
      "step": 3450
    },
    {
      "epoch": 2.963590177815411,
      "grad_norm": 10.448288917541504,
      "learning_rate": 2.4837708156929157e-06,
      "loss": 0.3016,
      "step": 3500
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9076190476190477,
      "eval_loss": 0.2757331132888794,
      "eval_runtime": 8.8816,
      "eval_samples_per_second": 118.222,
      "eval_steps_per_second": 7.431,
      "step": 3543
    }
  ],
  "logging_steps": 50,
  "max_steps": 3543,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3520263071773536.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
