{
  "best_global_step": 14662,
  "best_metric": 0.9815084784777104,
  "best_model_checkpoint": "./distilbert_lora_email_classifier_200k_v1\\checkpoint-14662",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 14662,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0034101759650797983,
      "grad_norm": 0.5148999094963074,
      "learning_rate": 0.00019933160551084437,
      "loss": 0.2823,
      "step": 50
    },
    {
      "epoch": 0.006820351930159597,
      "grad_norm": 0.9008091688156128,
      "learning_rate": 0.0001986495703178284,
      "loss": 0.2947,
      "step": 100
    },
    {
      "epoch": 0.010230527895239394,
      "grad_norm": 0.5860163569450378,
      "learning_rate": 0.00019796753512481245,
      "loss": 0.2512,
      "step": 150
    },
    {
      "epoch": 0.013640703860319193,
      "grad_norm": 2.050515651702881,
      "learning_rate": 0.0001972854999317965,
      "loss": 0.2197,
      "step": 200
    },
    {
      "epoch": 0.01705087982539899,
      "grad_norm": 0.500971257686615,
      "learning_rate": 0.00019660346473878053,
      "loss": 0.1892,
      "step": 250
    },
    {
      "epoch": 0.02046105579047879,
      "grad_norm": 0.18479979038238525,
      "learning_rate": 0.00019592142954576457,
      "loss": 0.1556,
      "step": 300
    },
    {
      "epoch": 0.023871231755558588,
      "grad_norm": 0.04947952553629875,
      "learning_rate": 0.0001952393943527486,
      "loss": 0.118,
      "step": 350
    },
    {
      "epoch": 0.027281407720638386,
      "grad_norm": 2.8588852882385254,
      "learning_rate": 0.00019455735915973265,
      "loss": 0.2343,
      "step": 400
    },
    {
      "epoch": 0.03069158368571818,
      "grad_norm": 1.7033774852752686,
      "learning_rate": 0.0001938753239667167,
      "loss": 0.1483,
      "step": 450
    },
    {
      "epoch": 0.03410175965079798,
      "grad_norm": 2.05242657661438,
      "learning_rate": 0.00019319328877370073,
      "loss": 0.1467,
      "step": 500
    },
    {
      "epoch": 0.03751193561587778,
      "grad_norm": 0.0902288630604744,
      "learning_rate": 0.00019251125358068477,
      "loss": 0.1686,
      "step": 550
    },
    {
      "epoch": 0.04092211158095758,
      "grad_norm": 0.7339128851890564,
      "learning_rate": 0.0001918292183876688,
      "loss": 0.1346,
      "step": 600
    },
    {
      "epoch": 0.04433228754603737,
      "grad_norm": 0.2976880967617035,
      "learning_rate": 0.00019114718319465285,
      "loss": 0.1575,
      "step": 650
    },
    {
      "epoch": 0.047742463511117175,
      "grad_norm": 2.569204092025757,
      "learning_rate": 0.0001904651480016369,
      "loss": 0.1599,
      "step": 700
    },
    {
      "epoch": 0.05115263947619697,
      "grad_norm": 5.159341812133789,
      "learning_rate": 0.00018978311280862093,
      "loss": 0.1515,
      "step": 750
    },
    {
      "epoch": 0.05456281544127677,
      "grad_norm": 0.05498411878943443,
      "learning_rate": 0.00018910107761560497,
      "loss": 0.1424,
      "step": 800
    },
    {
      "epoch": 0.05797299140635657,
      "grad_norm": 2.491986036300659,
      "learning_rate": 0.00018841904242258901,
      "loss": 0.1447,
      "step": 850
    },
    {
      "epoch": 0.06138316737143636,
      "grad_norm": 2.07114315032959,
      "learning_rate": 0.00018773700722957306,
      "loss": 0.1319,
      "step": 900
    },
    {
      "epoch": 0.06479334333651617,
      "grad_norm": 0.5871169567108154,
      "learning_rate": 0.0001870549720365571,
      "loss": 0.1213,
      "step": 950
    },
    {
      "epoch": 0.06820351930159596,
      "grad_norm": 0.08369778841733932,
      "learning_rate": 0.00018637293684354114,
      "loss": 0.1165,
      "step": 1000
    },
    {
      "epoch": 0.07161369526667576,
      "grad_norm": 0.3532344400882721,
      "learning_rate": 0.00018569090165052518,
      "loss": 0.1409,
      "step": 1050
    },
    {
      "epoch": 0.07502387123175557,
      "grad_norm": 3.3267428874969482,
      "learning_rate": 0.00018500886645750922,
      "loss": 0.103,
      "step": 1100
    },
    {
      "epoch": 0.07843404719683536,
      "grad_norm": 0.06920797377824783,
      "learning_rate": 0.00018432683126449326,
      "loss": 0.0866,
      "step": 1150
    },
    {
      "epoch": 0.08184422316191516,
      "grad_norm": 0.034856829792261124,
      "learning_rate": 0.0001836447960714773,
      "loss": 0.1113,
      "step": 1200
    },
    {
      "epoch": 0.08525439912699495,
      "grad_norm": 0.06494294852018356,
      "learning_rate": 0.00018296276087846134,
      "loss": 0.1469,
      "step": 1250
    },
    {
      "epoch": 0.08866457509207475,
      "grad_norm": 2.572706699371338,
      "learning_rate": 0.00018228072568544538,
      "loss": 0.1822,
      "step": 1300
    },
    {
      "epoch": 0.09207475105715456,
      "grad_norm": 0.10673487186431885,
      "learning_rate": 0.00018159869049242942,
      "loss": 0.1075,
      "step": 1350
    },
    {
      "epoch": 0.09548492702223435,
      "grad_norm": 3.623622179031372,
      "learning_rate": 0.00018091665529941346,
      "loss": 0.1392,
      "step": 1400
    },
    {
      "epoch": 0.09889510298731415,
      "grad_norm": 0.4112500250339508,
      "learning_rate": 0.0001802346201063975,
      "loss": 0.1734,
      "step": 1450
    },
    {
      "epoch": 0.10230527895239394,
      "grad_norm": 0.22621691226959229,
      "learning_rate": 0.00017955258491338154,
      "loss": 0.0825,
      "step": 1500
    },
    {
      "epoch": 0.10571545491747374,
      "grad_norm": 3.478180170059204,
      "learning_rate": 0.00017887054972036558,
      "loss": 0.1541,
      "step": 1550
    },
    {
      "epoch": 0.10912563088255355,
      "grad_norm": 0.9401648640632629,
      "learning_rate": 0.00017818851452734962,
      "loss": 0.1598,
      "step": 1600
    },
    {
      "epoch": 0.11253580684763334,
      "grad_norm": 2.148366928100586,
      "learning_rate": 0.00017750647933433366,
      "loss": 0.126,
      "step": 1650
    },
    {
      "epoch": 0.11594598281271314,
      "grad_norm": 3.5502047538757324,
      "learning_rate": 0.0001768244441413177,
      "loss": 0.1404,
      "step": 1700
    },
    {
      "epoch": 0.11935615877779293,
      "grad_norm": 3.6771295070648193,
      "learning_rate": 0.00017614240894830174,
      "loss": 0.1303,
      "step": 1750
    },
    {
      "epoch": 0.12276633474287273,
      "grad_norm": 0.14774757623672485,
      "learning_rate": 0.00017546037375528579,
      "loss": 0.1337,
      "step": 1800
    },
    {
      "epoch": 0.12617651070795252,
      "grad_norm": 0.2949675917625427,
      "learning_rate": 0.00017477833856226983,
      "loss": 0.155,
      "step": 1850
    },
    {
      "epoch": 0.12958668667303233,
      "grad_norm": 0.1261541247367859,
      "learning_rate": 0.00017409630336925387,
      "loss": 0.1622,
      "step": 1900
    },
    {
      "epoch": 0.13299686263811214,
      "grad_norm": 0.0739862471818924,
      "learning_rate": 0.00017341426817623788,
      "loss": 0.0895,
      "step": 1950
    },
    {
      "epoch": 0.13640703860319192,
      "grad_norm": 1.2244913578033447,
      "learning_rate": 0.00017273223298322195,
      "loss": 0.118,
      "step": 2000
    },
    {
      "epoch": 0.13981721456827173,
      "grad_norm": 0.07389707118272781,
      "learning_rate": 0.000172050197790206,
      "loss": 0.1211,
      "step": 2050
    },
    {
      "epoch": 0.1432273905333515,
      "grad_norm": 0.5522181987762451,
      "learning_rate": 0.00017136816259719003,
      "loss": 0.1383,
      "step": 2100
    },
    {
      "epoch": 0.14663756649843132,
      "grad_norm": 0.06517970561981201,
      "learning_rate": 0.00017068612740417407,
      "loss": 0.1155,
      "step": 2150
    },
    {
      "epoch": 0.15004774246351113,
      "grad_norm": 0.06850122660398483,
      "learning_rate": 0.00017000409221115808,
      "loss": 0.0938,
      "step": 2200
    },
    {
      "epoch": 0.1534579184285909,
      "grad_norm": 0.10975775122642517,
      "learning_rate": 0.00016932205701814215,
      "loss": 0.1102,
      "step": 2250
    },
    {
      "epoch": 0.15686809439367072,
      "grad_norm": 0.028586745262145996,
      "learning_rate": 0.0001686400218251262,
      "loss": 0.1058,
      "step": 2300
    },
    {
      "epoch": 0.1602782703587505,
      "grad_norm": 0.04761885106563568,
      "learning_rate": 0.00016795798663211023,
      "loss": 0.1287,
      "step": 2350
    },
    {
      "epoch": 0.1636884463238303,
      "grad_norm": 0.1573585569858551,
      "learning_rate": 0.00016727595143909427,
      "loss": 0.1315,
      "step": 2400
    },
    {
      "epoch": 0.16709862228891012,
      "grad_norm": 0.18019069731235504,
      "learning_rate": 0.00016659391624607829,
      "loss": 0.1005,
      "step": 2450
    },
    {
      "epoch": 0.1705087982539899,
      "grad_norm": 3.6364951133728027,
      "learning_rate": 0.00016591188105306235,
      "loss": 0.1223,
      "step": 2500
    },
    {
      "epoch": 0.1739189742190697,
      "grad_norm": 0.1591717153787613,
      "learning_rate": 0.0001652298458600464,
      "loss": 0.1091,
      "step": 2550
    },
    {
      "epoch": 0.1773291501841495,
      "grad_norm": 0.018326355144381523,
      "learning_rate": 0.00016454781066703043,
      "loss": 0.1354,
      "step": 2600
    },
    {
      "epoch": 0.1807393261492293,
      "grad_norm": 0.08176342397928238,
      "learning_rate": 0.00016386577547401447,
      "loss": 0.1241,
      "step": 2650
    },
    {
      "epoch": 0.1841495021143091,
      "grad_norm": 0.7010168433189392,
      "learning_rate": 0.0001631837402809985,
      "loss": 0.0941,
      "step": 2700
    },
    {
      "epoch": 0.1875596780793889,
      "grad_norm": 0.07850351929664612,
      "learning_rate": 0.00016250170508798256,
      "loss": 0.0986,
      "step": 2750
    },
    {
      "epoch": 0.1909698540444687,
      "grad_norm": 2.9378018379211426,
      "learning_rate": 0.0001618196698949666,
      "loss": 0.158,
      "step": 2800
    },
    {
      "epoch": 0.19438003000954848,
      "grad_norm": 4.883297443389893,
      "learning_rate": 0.00016113763470195064,
      "loss": 0.2268,
      "step": 2850
    },
    {
      "epoch": 0.1977902059746283,
      "grad_norm": 5.702879428863525,
      "learning_rate": 0.00016045559950893468,
      "loss": 0.1205,
      "step": 2900
    },
    {
      "epoch": 0.2012003819397081,
      "grad_norm": 3.0288610458374023,
      "learning_rate": 0.0001597735643159187,
      "loss": 0.1288,
      "step": 2950
    },
    {
      "epoch": 0.20461055790478788,
      "grad_norm": 0.12632907927036285,
      "learning_rate": 0.00015909152912290276,
      "loss": 0.0951,
      "step": 3000
    },
    {
      "epoch": 0.2080207338698677,
      "grad_norm": 0.16676980257034302,
      "learning_rate": 0.0001584094939298868,
      "loss": 0.1382,
      "step": 3050
    },
    {
      "epoch": 0.21143090983494747,
      "grad_norm": 3.143674850463867,
      "learning_rate": 0.0001577274587368708,
      "loss": 0.1255,
      "step": 3100
    },
    {
      "epoch": 0.21484108580002728,
      "grad_norm": 0.21980570256710052,
      "learning_rate": 0.00015704542354385488,
      "loss": 0.089,
      "step": 3150
    },
    {
      "epoch": 0.2182512617651071,
      "grad_norm": 0.06668069958686829,
      "learning_rate": 0.0001563633883508389,
      "loss": 0.0638,
      "step": 3200
    },
    {
      "epoch": 0.22166143773018687,
      "grad_norm": 4.706871509552002,
      "learning_rate": 0.00015568135315782296,
      "loss": 0.1208,
      "step": 3250
    },
    {
      "epoch": 0.22507161369526668,
      "grad_norm": 0.04791845753788948,
      "learning_rate": 0.000154999317964807,
      "loss": 0.1049,
      "step": 3300
    },
    {
      "epoch": 0.22848178966034646,
      "grad_norm": 0.7047096490859985,
      "learning_rate": 0.00015431728277179102,
      "loss": 0.0791,
      "step": 3350
    },
    {
      "epoch": 0.23189196562542627,
      "grad_norm": 0.008875422179698944,
      "learning_rate": 0.00015363524757877508,
      "loss": 0.0885,
      "step": 3400
    },
    {
      "epoch": 0.23530214159050608,
      "grad_norm": 0.07512422651052475,
      "learning_rate": 0.0001529532123857591,
      "loss": 0.1487,
      "step": 3450
    },
    {
      "epoch": 0.23871231755558586,
      "grad_norm": 3.2592813968658447,
      "learning_rate": 0.00015227117719274316,
      "loss": 0.1076,
      "step": 3500
    },
    {
      "epoch": 0.24212249352066567,
      "grad_norm": 0.10929161310195923,
      "learning_rate": 0.0001515891419997272,
      "loss": 0.1218,
      "step": 3550
    },
    {
      "epoch": 0.24553266948574545,
      "grad_norm": 0.0040662093088030815,
      "learning_rate": 0.00015090710680671122,
      "loss": 0.0855,
      "step": 3600
    },
    {
      "epoch": 0.24894284545082526,
      "grad_norm": 0.04548148065805435,
      "learning_rate": 0.00015022507161369529,
      "loss": 0.0804,
      "step": 3650
    },
    {
      "epoch": 0.25235302141590504,
      "grad_norm": 0.044574588537216187,
      "learning_rate": 0.0001495430364206793,
      "loss": 0.0776,
      "step": 3700
    },
    {
      "epoch": 0.25576319738098485,
      "grad_norm": 2.8792858123779297,
      "learning_rate": 0.00014886100122766337,
      "loss": 0.0999,
      "step": 3750
    },
    {
      "epoch": 0.25917337334606466,
      "grad_norm": 0.8447338938713074,
      "learning_rate": 0.0001481789660346474,
      "loss": 0.1947,
      "step": 3800
    },
    {
      "epoch": 0.26258354931114447,
      "grad_norm": 0.01134155597537756,
      "learning_rate": 0.00014749693084163142,
      "loss": 0.084,
      "step": 3850
    },
    {
      "epoch": 0.2659937252762243,
      "grad_norm": 2.328242540359497,
      "learning_rate": 0.0001468148956486155,
      "loss": 0.1238,
      "step": 3900
    },
    {
      "epoch": 0.26940390124130403,
      "grad_norm": 0.03177502006292343,
      "learning_rate": 0.0001461328604555995,
      "loss": 0.0988,
      "step": 3950
    },
    {
      "epoch": 0.27281407720638384,
      "grad_norm": 0.024406366050243378,
      "learning_rate": 0.00014545082526258357,
      "loss": 0.1108,
      "step": 4000
    },
    {
      "epoch": 0.27622425317146365,
      "grad_norm": 2.795151948928833,
      "learning_rate": 0.0001447687900695676,
      "loss": 0.1074,
      "step": 4050
    },
    {
      "epoch": 0.27963442913654346,
      "grad_norm": 0.9251158237457275,
      "learning_rate": 0.00014408675487655162,
      "loss": 0.1222,
      "step": 4100
    },
    {
      "epoch": 0.28304460510162327,
      "grad_norm": 0.5593193769454956,
      "learning_rate": 0.0001434047196835357,
      "loss": 0.114,
      "step": 4150
    },
    {
      "epoch": 0.286454781066703,
      "grad_norm": 0.3184158205986023,
      "learning_rate": 0.0001427226844905197,
      "loss": 0.1199,
      "step": 4200
    },
    {
      "epoch": 0.28986495703178283,
      "grad_norm": 0.07215830683708191,
      "learning_rate": 0.00014204064929750375,
      "loss": 0.0632,
      "step": 4250
    },
    {
      "epoch": 0.29327513299686264,
      "grad_norm": 0.037935856729745865,
      "learning_rate": 0.0001413586141044878,
      "loss": 0.1081,
      "step": 4300
    },
    {
      "epoch": 0.29668530896194245,
      "grad_norm": 0.029020050540566444,
      "learning_rate": 0.00014067657891147183,
      "loss": 0.0658,
      "step": 4350
    },
    {
      "epoch": 0.30009548492702226,
      "grad_norm": 0.0745619684457779,
      "learning_rate": 0.0001399945437184559,
      "loss": 0.1009,
      "step": 4400
    },
    {
      "epoch": 0.303505660892102,
      "grad_norm": 2.2507951259613037,
      "learning_rate": 0.0001393125085254399,
      "loss": 0.1379,
      "step": 4450
    },
    {
      "epoch": 0.3069158368571818,
      "grad_norm": 4.059320449829102,
      "learning_rate": 0.00013863047333242395,
      "loss": 0.1027,
      "step": 4500
    },
    {
      "epoch": 0.31032601282226163,
      "grad_norm": 2.7235593795776367,
      "learning_rate": 0.00013794843813940802,
      "loss": 0.1362,
      "step": 4550
    },
    {
      "epoch": 0.31373618878734144,
      "grad_norm": 0.120814248919487,
      "learning_rate": 0.00013726640294639203,
      "loss": 0.0902,
      "step": 4600
    },
    {
      "epoch": 0.31714636475242125,
      "grad_norm": 1.0489689111709595,
      "learning_rate": 0.0001365843677533761,
      "loss": 0.1135,
      "step": 4650
    },
    {
      "epoch": 0.320556540717501,
      "grad_norm": 5.011481761932373,
      "learning_rate": 0.0001359023325603601,
      "loss": 0.1212,
      "step": 4700
    },
    {
      "epoch": 0.3239667166825808,
      "grad_norm": 0.289955198764801,
      "learning_rate": 0.00013522029736734415,
      "loss": 0.0962,
      "step": 4750
    },
    {
      "epoch": 0.3273768926476606,
      "grad_norm": 0.4914931356906891,
      "learning_rate": 0.00013453826217432822,
      "loss": 0.0905,
      "step": 4800
    },
    {
      "epoch": 0.33078706861274043,
      "grad_norm": 5.673484802246094,
      "learning_rate": 0.00013385622698131223,
      "loss": 0.1427,
      "step": 4850
    },
    {
      "epoch": 0.33419724457782024,
      "grad_norm": 0.07713384926319122,
      "learning_rate": 0.0001331741917882963,
      "loss": 0.0671,
      "step": 4900
    },
    {
      "epoch": 0.3376074205429,
      "grad_norm": 3.898261070251465,
      "learning_rate": 0.0001324921565952803,
      "loss": 0.048,
      "step": 4950
    },
    {
      "epoch": 0.3410175965079798,
      "grad_norm": 0.07909536361694336,
      "learning_rate": 0.00013181012140226435,
      "loss": 0.1317,
      "step": 5000
    },
    {
      "epoch": 0.3444277724730596,
      "grad_norm": 0.04690678417682648,
      "learning_rate": 0.00013112808620924842,
      "loss": 0.0869,
      "step": 5050
    },
    {
      "epoch": 0.3478379484381394,
      "grad_norm": 0.13131354749202728,
      "learning_rate": 0.00013044605101623243,
      "loss": 0.1207,
      "step": 5100
    },
    {
      "epoch": 0.35124812440321923,
      "grad_norm": 0.6475599408149719,
      "learning_rate": 0.0001297640158232165,
      "loss": 0.1627,
      "step": 5150
    },
    {
      "epoch": 0.354658300368299,
      "grad_norm": 0.19097571074962616,
      "learning_rate": 0.00012908198063020052,
      "loss": 0.0891,
      "step": 5200
    },
    {
      "epoch": 0.3580684763333788,
      "grad_norm": 3.6504828929901123,
      "learning_rate": 0.00012839994543718456,
      "loss": 0.1246,
      "step": 5250
    },
    {
      "epoch": 0.3614786522984586,
      "grad_norm": 3.7547805309295654,
      "learning_rate": 0.00012771791024416862,
      "loss": 0.0875,
      "step": 5300
    },
    {
      "epoch": 0.3648888282635384,
      "grad_norm": 1.8538302183151245,
      "learning_rate": 0.00012703587505115264,
      "loss": 0.055,
      "step": 5350
    },
    {
      "epoch": 0.3682990042286182,
      "grad_norm": 0.064237579703331,
      "learning_rate": 0.00012635383985813668,
      "loss": 0.0721,
      "step": 5400
    },
    {
      "epoch": 0.371709180193698,
      "grad_norm": 0.4577503502368927,
      "learning_rate": 0.00012567180466512072,
      "loss": 0.1256,
      "step": 5450
    },
    {
      "epoch": 0.3751193561587778,
      "grad_norm": 0.047971274703741074,
      "learning_rate": 0.00012498976947210476,
      "loss": 0.0955,
      "step": 5500
    },
    {
      "epoch": 0.3785295321238576,
      "grad_norm": 0.20013883709907532,
      "learning_rate": 0.00012430773427908883,
      "loss": 0.1117,
      "step": 5550
    },
    {
      "epoch": 0.3819397080889374,
      "grad_norm": 0.03598841279745102,
      "learning_rate": 0.00012362569908607284,
      "loss": 0.0969,
      "step": 5600
    },
    {
      "epoch": 0.3853498840540172,
      "grad_norm": 1.4624297618865967,
      "learning_rate": 0.00012294366389305688,
      "loss": 0.0794,
      "step": 5650
    },
    {
      "epoch": 0.38876006001909696,
      "grad_norm": 0.042316336184740067,
      "learning_rate": 0.00012226162870004092,
      "loss": 0.0488,
      "step": 5700
    },
    {
      "epoch": 0.3921702359841768,
      "grad_norm": 1.2679623365402222,
      "learning_rate": 0.00012157959350702498,
      "loss": 0.0665,
      "step": 5750
    },
    {
      "epoch": 0.3955804119492566,
      "grad_norm": 0.07106984406709671,
      "learning_rate": 0.00012089755831400902,
      "loss": 0.0752,
      "step": 5800
    },
    {
      "epoch": 0.3989905879143364,
      "grad_norm": 0.017719633877277374,
      "learning_rate": 0.00012021552312099304,
      "loss": 0.1339,
      "step": 5850
    },
    {
      "epoch": 0.4024007638794162,
      "grad_norm": 0.10147462040185928,
      "learning_rate": 0.0001195334879279771,
      "loss": 0.1254,
      "step": 5900
    },
    {
      "epoch": 0.40581093984449595,
      "grad_norm": 5.2290167808532715,
      "learning_rate": 0.00011885145273496112,
      "loss": 0.0986,
      "step": 5950
    },
    {
      "epoch": 0.40922111580957576,
      "grad_norm": 0.07923611998558044,
      "learning_rate": 0.00011816941754194516,
      "loss": 0.1373,
      "step": 6000
    },
    {
      "epoch": 0.4126312917746556,
      "grad_norm": 0.0335371270775795,
      "learning_rate": 0.00011748738234892922,
      "loss": 0.0405,
      "step": 6050
    },
    {
      "epoch": 0.4160414677397354,
      "grad_norm": 0.021284490823745728,
      "learning_rate": 0.00011680534715591325,
      "loss": 0.0874,
      "step": 6100
    },
    {
      "epoch": 0.4194516437048152,
      "grad_norm": 0.05103297531604767,
      "learning_rate": 0.0001161233119628973,
      "loss": 0.105,
      "step": 6150
    },
    {
      "epoch": 0.42286181966989494,
      "grad_norm": 0.05742048844695091,
      "learning_rate": 0.00011544127676988133,
      "loss": 0.0612,
      "step": 6200
    },
    {
      "epoch": 0.42627199563497475,
      "grad_norm": 0.15084703266620636,
      "learning_rate": 0.00011475924157686537,
      "loss": 0.1258,
      "step": 6250
    },
    {
      "epoch": 0.42968217160005456,
      "grad_norm": 0.08085772395133972,
      "learning_rate": 0.00011407720638384942,
      "loss": 0.0755,
      "step": 6300
    },
    {
      "epoch": 0.4330923475651344,
      "grad_norm": 0.07799951732158661,
      "learning_rate": 0.00011339517119083345,
      "loss": 0.0915,
      "step": 6350
    },
    {
      "epoch": 0.4365025235302142,
      "grad_norm": 0.1549525260925293,
      "learning_rate": 0.0001127131359978175,
      "loss": 0.088,
      "step": 6400
    },
    {
      "epoch": 0.43991269949529394,
      "grad_norm": 0.030327601358294487,
      "learning_rate": 0.00011203110080480153,
      "loss": 0.0868,
      "step": 6450
    },
    {
      "epoch": 0.44332287546037374,
      "grad_norm": 0.09071130305528641,
      "learning_rate": 0.00011134906561178557,
      "loss": 0.1201,
      "step": 6500
    },
    {
      "epoch": 0.44673305142545355,
      "grad_norm": 0.3823140859603882,
      "learning_rate": 0.00011066703041876962,
      "loss": 0.0988,
      "step": 6550
    },
    {
      "epoch": 0.45014322739053336,
      "grad_norm": 4.9176025390625,
      "learning_rate": 0.00010998499522575365,
      "loss": 0.1535,
      "step": 6600
    },
    {
      "epoch": 0.45355340335561317,
      "grad_norm": 0.03907785937190056,
      "learning_rate": 0.0001093029600327377,
      "loss": 0.0902,
      "step": 6650
    },
    {
      "epoch": 0.4569635793206929,
      "grad_norm": 0.028264246881008148,
      "learning_rate": 0.00010862092483972173,
      "loss": 0.0336,
      "step": 6700
    },
    {
      "epoch": 0.46037375528577273,
      "grad_norm": 1.7627265453338623,
      "learning_rate": 0.00010793888964670577,
      "loss": 0.0751,
      "step": 6750
    },
    {
      "epoch": 0.46378393125085254,
      "grad_norm": 0.015595288015902042,
      "learning_rate": 0.00010725685445368983,
      "loss": 0.0757,
      "step": 6800
    },
    {
      "epoch": 0.46719410721593235,
      "grad_norm": 0.24393756687641144,
      "learning_rate": 0.00010657481926067385,
      "loss": 0.0856,
      "step": 6850
    },
    {
      "epoch": 0.47060428318101216,
      "grad_norm": 0.040478743612766266,
      "learning_rate": 0.00010589278406765791,
      "loss": 0.1375,
      "step": 6900
    },
    {
      "epoch": 0.4740144591460919,
      "grad_norm": 5.496279716491699,
      "learning_rate": 0.00010521074887464194,
      "loss": 0.1061,
      "step": 6950
    },
    {
      "epoch": 0.4774246351111717,
      "grad_norm": 6.036158084869385,
      "learning_rate": 0.00010452871368162598,
      "loss": 0.1112,
      "step": 7000
    },
    {
      "epoch": 0.48083481107625153,
      "grad_norm": 0.04073697328567505,
      "learning_rate": 0.00010384667848861003,
      "loss": 0.0727,
      "step": 7050
    },
    {
      "epoch": 0.48424498704133134,
      "grad_norm": 0.010007885284721851,
      "learning_rate": 0.00010316464329559406,
      "loss": 0.0886,
      "step": 7100
    },
    {
      "epoch": 0.48765516300641115,
      "grad_norm": 0.41580724716186523,
      "learning_rate": 0.0001024826081025781,
      "loss": 0.1392,
      "step": 7150
    },
    {
      "epoch": 0.4910653389714909,
      "grad_norm": 0.04226147010922432,
      "learning_rate": 0.00010180057290956212,
      "loss": 0.0643,
      "step": 7200
    },
    {
      "epoch": 0.4944755149365707,
      "grad_norm": 1.0037128925323486,
      "learning_rate": 0.00010111853771654618,
      "loss": 0.067,
      "step": 7250
    },
    {
      "epoch": 0.4978856909016505,
      "grad_norm": 0.0579398050904274,
      "learning_rate": 0.00010043650252353023,
      "loss": 0.0674,
      "step": 7300
    },
    {
      "epoch": 0.5012958668667303,
      "grad_norm": 4.87916898727417,
      "learning_rate": 9.975446733051426e-05,
      "loss": 0.094,
      "step": 7350
    },
    {
      "epoch": 0.5047060428318101,
      "grad_norm": 0.32282182574272156,
      "learning_rate": 9.90724321374983e-05,
      "loss": 0.0976,
      "step": 7400
    },
    {
      "epoch": 0.50811621879689,
      "grad_norm": 0.05601687356829643,
      "learning_rate": 9.839039694448234e-05,
      "loss": 0.0731,
      "step": 7450
    },
    {
      "epoch": 0.5115263947619697,
      "grad_norm": 0.4033273458480835,
      "learning_rate": 9.770836175146638e-05,
      "loss": 0.0238,
      "step": 7500
    },
    {
      "epoch": 0.5149365707270496,
      "grad_norm": 0.021747475489974022,
      "learning_rate": 9.702632655845042e-05,
      "loss": 0.1017,
      "step": 7550
    },
    {
      "epoch": 0.5183467466921293,
      "grad_norm": 0.025380920618772507,
      "learning_rate": 9.634429136543446e-05,
      "loss": 0.0912,
      "step": 7600
    },
    {
      "epoch": 0.5217569226572091,
      "grad_norm": 3.976748466491699,
      "learning_rate": 9.566225617241849e-05,
      "loss": 0.1564,
      "step": 7650
    },
    {
      "epoch": 0.5251670986222889,
      "grad_norm": 0.033737778663635254,
      "learning_rate": 9.498022097940254e-05,
      "loss": 0.0357,
      "step": 7700
    },
    {
      "epoch": 0.5285772745873687,
      "grad_norm": 0.05351856350898743,
      "learning_rate": 9.429818578638658e-05,
      "loss": 0.1062,
      "step": 7750
    },
    {
      "epoch": 0.5319874505524486,
      "grad_norm": 0.10144967585802078,
      "learning_rate": 9.361615059337062e-05,
      "loss": 0.0742,
      "step": 7800
    },
    {
      "epoch": 0.5353976265175283,
      "grad_norm": 3.509326219558716,
      "learning_rate": 9.293411540035467e-05,
      "loss": 0.1129,
      "step": 7850
    },
    {
      "epoch": 0.5388078024826081,
      "grad_norm": 3.4695513248443604,
      "learning_rate": 9.225208020733869e-05,
      "loss": 0.067,
      "step": 7900
    },
    {
      "epoch": 0.5422179784476879,
      "grad_norm": 5.0037078857421875,
      "learning_rate": 9.157004501432275e-05,
      "loss": 0.0769,
      "step": 7950
    },
    {
      "epoch": 0.5456281544127677,
      "grad_norm": 0.06062762439250946,
      "learning_rate": 9.088800982130679e-05,
      "loss": 0.0608,
      "step": 8000
    },
    {
      "epoch": 0.5490383303778475,
      "grad_norm": 0.03962782025337219,
      "learning_rate": 9.020597462829083e-05,
      "loss": 0.1356,
      "step": 8050
    },
    {
      "epoch": 0.5524485063429273,
      "grad_norm": 0.19266748428344727,
      "learning_rate": 8.952393943527487e-05,
      "loss": 0.1128,
      "step": 8100
    },
    {
      "epoch": 0.5558586823080071,
      "grad_norm": 0.0544624850153923,
      "learning_rate": 8.88419042422589e-05,
      "loss": 0.0761,
      "step": 8150
    },
    {
      "epoch": 0.5592688582730869,
      "grad_norm": 0.09467655420303345,
      "learning_rate": 8.815986904924295e-05,
      "loss": 0.0816,
      "step": 8200
    },
    {
      "epoch": 0.5626790342381667,
      "grad_norm": 0.3303080201148987,
      "learning_rate": 8.747783385622699e-05,
      "loss": 0.069,
      "step": 8250
    },
    {
      "epoch": 0.5660892102032465,
      "grad_norm": 3.2032124996185303,
      "learning_rate": 8.679579866321103e-05,
      "loss": 0.1275,
      "step": 8300
    },
    {
      "epoch": 0.5694993861683263,
      "grad_norm": 3.714301824569702,
      "learning_rate": 8.611376347019506e-05,
      "loss": 0.0824,
      "step": 8350
    },
    {
      "epoch": 0.572909562133406,
      "grad_norm": 0.11559810489416122,
      "learning_rate": 8.54317282771791e-05,
      "loss": 0.0874,
      "step": 8400
    },
    {
      "epoch": 0.5763197380984859,
      "grad_norm": 0.1339702010154724,
      "learning_rate": 8.474969308416315e-05,
      "loss": 0.0665,
      "step": 8450
    },
    {
      "epoch": 0.5797299140635657,
      "grad_norm": 0.08071958273649216,
      "learning_rate": 8.406765789114719e-05,
      "loss": 0.1549,
      "step": 8500
    },
    {
      "epoch": 0.5831400900286455,
      "grad_norm": 0.132334902882576,
      "learning_rate": 8.338562269813123e-05,
      "loss": 0.0623,
      "step": 8550
    },
    {
      "epoch": 0.5865502659937253,
      "grad_norm": 5.847298622131348,
      "learning_rate": 8.270358750511526e-05,
      "loss": 0.0712,
      "step": 8600
    },
    {
      "epoch": 0.589960441958805,
      "grad_norm": 0.048538580536842346,
      "learning_rate": 8.20215523120993e-05,
      "loss": 0.1119,
      "step": 8650
    },
    {
      "epoch": 0.5933706179238849,
      "grad_norm": 0.03349008038640022,
      "learning_rate": 8.133951711908336e-05,
      "loss": 0.1241,
      "step": 8700
    },
    {
      "epoch": 0.5967807938889647,
      "grad_norm": 1.4978926181793213,
      "learning_rate": 8.06574819260674e-05,
      "loss": 0.1109,
      "step": 8750
    },
    {
      "epoch": 0.6001909698540445,
      "grad_norm": 0.18829087913036346,
      "learning_rate": 7.997544673305142e-05,
      "loss": 0.119,
      "step": 8800
    },
    {
      "epoch": 0.6036011458191243,
      "grad_norm": 0.2583030164241791,
      "learning_rate": 7.929341154003546e-05,
      "loss": 0.1238,
      "step": 8850
    },
    {
      "epoch": 0.607011321784204,
      "grad_norm": 0.03660832345485687,
      "learning_rate": 7.86113763470195e-05,
      "loss": 0.0729,
      "step": 8900
    },
    {
      "epoch": 0.6104214977492839,
      "grad_norm": 3.11295747756958,
      "learning_rate": 7.792934115400356e-05,
      "loss": 0.0557,
      "step": 8950
    },
    {
      "epoch": 0.6138316737143636,
      "grad_norm": 4.311800479888916,
      "learning_rate": 7.72473059609876e-05,
      "loss": 0.086,
      "step": 9000
    },
    {
      "epoch": 0.6172418496794435,
      "grad_norm": 0.05292617157101631,
      "learning_rate": 7.656527076797163e-05,
      "loss": 0.0619,
      "step": 9050
    },
    {
      "epoch": 0.6206520256445233,
      "grad_norm": 0.0725429356098175,
      "learning_rate": 7.588323557495567e-05,
      "loss": 0.1288,
      "step": 9100
    },
    {
      "epoch": 0.624062201609603,
      "grad_norm": 0.0904058963060379,
      "learning_rate": 7.52012003819397e-05,
      "loss": 0.0674,
      "step": 9150
    },
    {
      "epoch": 0.6274723775746829,
      "grad_norm": 4.169546604156494,
      "learning_rate": 7.451916518892376e-05,
      "loss": 0.0825,
      "step": 9200
    },
    {
      "epoch": 0.6308825535397626,
      "grad_norm": 0.06766670942306519,
      "learning_rate": 7.38371299959078e-05,
      "loss": 0.072,
      "step": 9250
    },
    {
      "epoch": 0.6342927295048425,
      "grad_norm": 0.2175462543964386,
      "learning_rate": 7.315509480289183e-05,
      "loss": 0.1011,
      "step": 9300
    },
    {
      "epoch": 0.6377029054699223,
      "grad_norm": 9.026124954223633,
      "learning_rate": 7.247305960987587e-05,
      "loss": 0.1474,
      "step": 9350
    },
    {
      "epoch": 0.641113081435002,
      "grad_norm": 0.4404829442501068,
      "learning_rate": 7.179102441685991e-05,
      "loss": 0.0881,
      "step": 9400
    },
    {
      "epoch": 0.6445232574000819,
      "grad_norm": 0.1882842481136322,
      "learning_rate": 7.110898922384396e-05,
      "loss": 0.0885,
      "step": 9450
    },
    {
      "epoch": 0.6479334333651616,
      "grad_norm": 0.08359139412641525,
      "learning_rate": 7.042695403082799e-05,
      "loss": 0.0977,
      "step": 9500
    },
    {
      "epoch": 0.6513436093302415,
      "grad_norm": 0.051861830055713654,
      "learning_rate": 6.974491883781203e-05,
      "loss": 0.0753,
      "step": 9550
    },
    {
      "epoch": 0.6547537852953212,
      "grad_norm": 2.641634464263916,
      "learning_rate": 6.906288364479607e-05,
      "loss": 0.1187,
      "step": 9600
    },
    {
      "epoch": 0.658163961260401,
      "grad_norm": 2.6933441162109375,
      "learning_rate": 6.838084845178011e-05,
      "loss": 0.0684,
      "step": 9650
    },
    {
      "epoch": 0.6615741372254809,
      "grad_norm": 4.488220691680908,
      "learning_rate": 6.769881325876417e-05,
      "loss": 0.1196,
      "step": 9700
    },
    {
      "epoch": 0.6649843131905606,
      "grad_norm": 0.05883673205971718,
      "learning_rate": 6.701677806574819e-05,
      "loss": 0.0713,
      "step": 9750
    },
    {
      "epoch": 0.6683944891556405,
      "grad_norm": 0.06535510718822479,
      "learning_rate": 6.633474287273223e-05,
      "loss": 0.1395,
      "step": 9800
    },
    {
      "epoch": 0.6718046651207202,
      "grad_norm": 4.0141682624816895,
      "learning_rate": 6.565270767971627e-05,
      "loss": 0.1098,
      "step": 9850
    },
    {
      "epoch": 0.6752148410858,
      "grad_norm": 4.501753807067871,
      "learning_rate": 6.497067248670031e-05,
      "loss": 0.1245,
      "step": 9900
    },
    {
      "epoch": 0.6786250170508799,
      "grad_norm": 0.0822865217924118,
      "learning_rate": 6.428863729368436e-05,
      "loss": 0.0488,
      "step": 9950
    },
    {
      "epoch": 0.6820351930159596,
      "grad_norm": 0.145527184009552,
      "learning_rate": 6.36066021006684e-05,
      "loss": 0.0906,
      "step": 10000
    },
    {
      "epoch": 0.6854453689810395,
      "grad_norm": 4.890286445617676,
      "learning_rate": 6.292456690765244e-05,
      "loss": 0.0932,
      "step": 10050
    },
    {
      "epoch": 0.6888555449461192,
      "grad_norm": 7.066033363342285,
      "learning_rate": 6.224253171463648e-05,
      "loss": 0.0722,
      "step": 10100
    },
    {
      "epoch": 0.692265720911199,
      "grad_norm": 0.6892660856246948,
      "learning_rate": 6.156049652162052e-05,
      "loss": 0.1218,
      "step": 10150
    },
    {
      "epoch": 0.6956758968762788,
      "grad_norm": 6.06453275680542,
      "learning_rate": 6.0878461328604565e-05,
      "loss": 0.0472,
      "step": 10200
    },
    {
      "epoch": 0.6990860728413586,
      "grad_norm": 0.037128835916519165,
      "learning_rate": 6.01964261355886e-05,
      "loss": 0.0936,
      "step": 10250
    },
    {
      "epoch": 0.7024962488064385,
      "grad_norm": 0.04380132257938385,
      "learning_rate": 5.951439094257264e-05,
      "loss": 0.0547,
      "step": 10300
    },
    {
      "epoch": 0.7059064247715182,
      "grad_norm": 0.09580855071544647,
      "learning_rate": 5.883235574955668e-05,
      "loss": 0.1273,
      "step": 10350
    },
    {
      "epoch": 0.709316600736598,
      "grad_norm": 0.1125132218003273,
      "learning_rate": 5.8150320556540714e-05,
      "loss": 0.1718,
      "step": 10400
    },
    {
      "epoch": 0.7127267767016778,
      "grad_norm": 0.43033671379089355,
      "learning_rate": 5.746828536352477e-05,
      "loss": 0.1332,
      "step": 10450
    },
    {
      "epoch": 0.7161369526667576,
      "grad_norm": 0.11972801387310028,
      "learning_rate": 5.67862501705088e-05,
      "loss": 0.0595,
      "step": 10500
    },
    {
      "epoch": 0.7195471286318375,
      "grad_norm": 0.026782238855957985,
      "learning_rate": 5.610421497749284e-05,
      "loss": 0.0529,
      "step": 10550
    },
    {
      "epoch": 0.7229573045969172,
      "grad_norm": 0.05453561618924141,
      "learning_rate": 5.542217978447688e-05,
      "loss": 0.04,
      "step": 10600
    },
    {
      "epoch": 0.726367480561997,
      "grad_norm": 4.292778491973877,
      "learning_rate": 5.4740144591460916e-05,
      "loss": 0.0686,
      "step": 10650
    },
    {
      "epoch": 0.7297776565270768,
      "grad_norm": 0.02673104964196682,
      "learning_rate": 5.4058109398444964e-05,
      "loss": 0.12,
      "step": 10700
    },
    {
      "epoch": 0.7331878324921566,
      "grad_norm": 0.020274989306926727,
      "learning_rate": 5.3376074205429004e-05,
      "loss": 0.0709,
      "step": 10750
    },
    {
      "epoch": 0.7365980084572364,
      "grad_norm": 1.9614250659942627,
      "learning_rate": 5.2694039012413045e-05,
      "loss": 0.0453,
      "step": 10800
    },
    {
      "epoch": 0.7400081844223162,
      "grad_norm": 5.45938777923584,
      "learning_rate": 5.201200381939708e-05,
      "loss": 0.067,
      "step": 10850
    },
    {
      "epoch": 0.743418360387396,
      "grad_norm": 0.11218445003032684,
      "learning_rate": 5.132996862638112e-05,
      "loss": 0.0784,
      "step": 10900
    },
    {
      "epoch": 0.7468285363524758,
      "grad_norm": 0.054453663527965546,
      "learning_rate": 5.0647933433365167e-05,
      "loss": 0.1256,
      "step": 10950
    },
    {
      "epoch": 0.7502387123175556,
      "grad_norm": 0.06216542050242424,
      "learning_rate": 4.996589824034921e-05,
      "loss": 0.0689,
      "step": 11000
    },
    {
      "epoch": 0.7536488882826354,
      "grad_norm": 4.009100437164307,
      "learning_rate": 4.928386304733325e-05,
      "loss": 0.0796,
      "step": 11050
    },
    {
      "epoch": 0.7570590642477152,
      "grad_norm": 0.22239762544631958,
      "learning_rate": 4.860182785431728e-05,
      "loss": 0.0795,
      "step": 11100
    },
    {
      "epoch": 0.7604692402127949,
      "grad_norm": 0.021248774603009224,
      "learning_rate": 4.791979266130133e-05,
      "loss": 0.057,
      "step": 11150
    },
    {
      "epoch": 0.7638794161778748,
      "grad_norm": 6.593769550323486,
      "learning_rate": 4.723775746828536e-05,
      "loss": 0.1108,
      "step": 11200
    },
    {
      "epoch": 0.7672895921429546,
      "grad_norm": 0.06846190989017487,
      "learning_rate": 4.655572227526941e-05,
      "loss": 0.0883,
      "step": 11250
    },
    {
      "epoch": 0.7706997681080344,
      "grad_norm": 0.039881546050310135,
      "learning_rate": 4.5873687082253444e-05,
      "loss": 0.107,
      "step": 11300
    },
    {
      "epoch": 0.7741099440731142,
      "grad_norm": 4.646385669708252,
      "learning_rate": 4.5191651889237484e-05,
      "loss": 0.0715,
      "step": 11350
    },
    {
      "epoch": 0.7775201200381939,
      "grad_norm": 0.12973615527153015,
      "learning_rate": 4.450961669622153e-05,
      "loss": 0.0717,
      "step": 11400
    },
    {
      "epoch": 0.7809302960032738,
      "grad_norm": 0.05816646292805672,
      "learning_rate": 4.3827581503205565e-05,
      "loss": 0.0458,
      "step": 11450
    },
    {
      "epoch": 0.7843404719683535,
      "grad_norm": 6.536689281463623,
      "learning_rate": 4.3145546310189606e-05,
      "loss": 0.0829,
      "step": 11500
    },
    {
      "epoch": 0.7877506479334334,
      "grad_norm": 0.028638068586587906,
      "learning_rate": 4.2463511117173646e-05,
      "loss": 0.034,
      "step": 11550
    },
    {
      "epoch": 0.7911608238985132,
      "grad_norm": 0.7023332118988037,
      "learning_rate": 4.178147592415769e-05,
      "loss": 0.0882,
      "step": 11600
    },
    {
      "epoch": 0.7945709998635929,
      "grad_norm": 0.4245104193687439,
      "learning_rate": 4.109944073114173e-05,
      "loss": 0.0751,
      "step": 11650
    },
    {
      "epoch": 0.7979811758286728,
      "grad_norm": 0.009060302749276161,
      "learning_rate": 4.041740553812577e-05,
      "loss": 0.0615,
      "step": 11700
    },
    {
      "epoch": 0.8013913517937525,
      "grad_norm": 0.1467268466949463,
      "learning_rate": 3.973537034510981e-05,
      "loss": 0.1355,
      "step": 11750
    },
    {
      "epoch": 0.8048015277588324,
      "grad_norm": 0.16049441695213318,
      "learning_rate": 3.905333515209385e-05,
      "loss": 0.0921,
      "step": 11800
    },
    {
      "epoch": 0.8082117037239122,
      "grad_norm": 0.07527278363704681,
      "learning_rate": 3.837129995907789e-05,
      "loss": 0.1189,
      "step": 11850
    },
    {
      "epoch": 0.8116218796889919,
      "grad_norm": 0.38781070709228516,
      "learning_rate": 3.768926476606193e-05,
      "loss": 0.0419,
      "step": 11900
    },
    {
      "epoch": 0.8150320556540718,
      "grad_norm": 0.051737040281295776,
      "learning_rate": 3.700722957304597e-05,
      "loss": 0.0981,
      "step": 11950
    },
    {
      "epoch": 0.8184422316191515,
      "grad_norm": 0.019923804327845573,
      "learning_rate": 3.632519438003001e-05,
      "loss": 0.1106,
      "step": 12000
    },
    {
      "epoch": 0.8218524075842314,
      "grad_norm": 0.016574237495660782,
      "learning_rate": 3.564315918701405e-05,
      "loss": 0.0752,
      "step": 12050
    },
    {
      "epoch": 0.8252625835493111,
      "grad_norm": 0.033608369529247284,
      "learning_rate": 3.496112399399809e-05,
      "loss": 0.1423,
      "step": 12100
    },
    {
      "epoch": 0.8286727595143909,
      "grad_norm": 0.20384566485881805,
      "learning_rate": 3.427908880098213e-05,
      "loss": 0.0934,
      "step": 12150
    },
    {
      "epoch": 0.8320829354794708,
      "grad_norm": 0.006325548514723778,
      "learning_rate": 3.3597053607966174e-05,
      "loss": 0.0646,
      "step": 12200
    },
    {
      "epoch": 0.8354931114445505,
      "grad_norm": 0.06274902820587158,
      "learning_rate": 3.291501841495021e-05,
      "loss": 0.0994,
      "step": 12250
    },
    {
      "epoch": 0.8389032874096304,
      "grad_norm": 0.023795368149876595,
      "learning_rate": 3.2232983221934255e-05,
      "loss": 0.0902,
      "step": 12300
    },
    {
      "epoch": 0.8423134633747101,
      "grad_norm": 0.16757731139659882,
      "learning_rate": 3.1550948028918295e-05,
      "loss": 0.0354,
      "step": 12350
    },
    {
      "epoch": 0.8457236393397899,
      "grad_norm": 0.02443048357963562,
      "learning_rate": 3.0868912835902336e-05,
      "loss": 0.0646,
      "step": 12400
    },
    {
      "epoch": 0.8491338153048698,
      "grad_norm": 0.07155352830886841,
      "learning_rate": 3.0186877642886373e-05,
      "loss": 0.0288,
      "step": 12450
    },
    {
      "epoch": 0.8525439912699495,
      "grad_norm": 0.0055917673744261265,
      "learning_rate": 2.9504842449870414e-05,
      "loss": 0.0672,
      "step": 12500
    },
    {
      "epoch": 0.8559541672350294,
      "grad_norm": 0.009634092450141907,
      "learning_rate": 2.8822807256854458e-05,
      "loss": 0.0389,
      "step": 12550
    },
    {
      "epoch": 0.8593643432001091,
      "grad_norm": 0.010512011125683784,
      "learning_rate": 2.8140772063838495e-05,
      "loss": 0.0608,
      "step": 12600
    },
    {
      "epoch": 0.8627745191651889,
      "grad_norm": 0.24260307848453522,
      "learning_rate": 2.745873687082254e-05,
      "loss": 0.1332,
      "step": 12650
    },
    {
      "epoch": 0.8661846951302687,
      "grad_norm": 0.03807380795478821,
      "learning_rate": 2.6776701677806576e-05,
      "loss": 0.0349,
      "step": 12700
    },
    {
      "epoch": 0.8695948710953485,
      "grad_norm": 0.09958341717720032,
      "learning_rate": 2.6094666484790613e-05,
      "loss": 0.0172,
      "step": 12750
    },
    {
      "epoch": 0.8730050470604284,
      "grad_norm": 5.351806640625,
      "learning_rate": 2.5412631291774657e-05,
      "loss": 0.0892,
      "step": 12800
    },
    {
      "epoch": 0.8764152230255081,
      "grad_norm": 0.05027718469500542,
      "learning_rate": 2.4730596098758698e-05,
      "loss": 0.0781,
      "step": 12850
    },
    {
      "epoch": 0.8798253989905879,
      "grad_norm": 3.3532679080963135,
      "learning_rate": 2.4048560905742738e-05,
      "loss": 0.0869,
      "step": 12900
    },
    {
      "epoch": 0.8832355749556677,
      "grad_norm": 7.258913993835449,
      "learning_rate": 2.336652571272678e-05,
      "loss": 0.0823,
      "step": 12950
    },
    {
      "epoch": 0.8866457509207475,
      "grad_norm": 0.044212665408849716,
      "learning_rate": 2.268449051971082e-05,
      "loss": 0.0582,
      "step": 13000
    },
    {
      "epoch": 0.8900559268858274,
      "grad_norm": 4.941271781921387,
      "learning_rate": 2.200245532669486e-05,
      "loss": 0.1114,
      "step": 13050
    },
    {
      "epoch": 0.8934661028509071,
      "grad_norm": 6.36160945892334,
      "learning_rate": 2.1320420133678897e-05,
      "loss": 0.1448,
      "step": 13100
    },
    {
      "epoch": 0.8968762788159869,
      "grad_norm": 0.11006052047014236,
      "learning_rate": 2.0638384940662938e-05,
      "loss": 0.0874,
      "step": 13150
    },
    {
      "epoch": 0.9002864547810667,
      "grad_norm": 4.075218200683594,
      "learning_rate": 1.9956349747646978e-05,
      "loss": 0.1133,
      "step": 13200
    },
    {
      "epoch": 0.9036966307461465,
      "grad_norm": 0.044055528938770294,
      "learning_rate": 1.9274314554631022e-05,
      "loss": 0.0775,
      "step": 13250
    },
    {
      "epoch": 0.9071068067112263,
      "grad_norm": 0.07494708150625229,
      "learning_rate": 1.8592279361615063e-05,
      "loss": 0.05,
      "step": 13300
    },
    {
      "epoch": 0.9105169826763061,
      "grad_norm": 2.9842166900634766,
      "learning_rate": 1.79102441685991e-05,
      "loss": 0.1183,
      "step": 13350
    },
    {
      "epoch": 0.9139271586413859,
      "grad_norm": 4.673551559448242,
      "learning_rate": 1.722820897558314e-05,
      "loss": 0.0575,
      "step": 13400
    },
    {
      "epoch": 0.9173373346064657,
      "grad_norm": 0.05972890928387642,
      "learning_rate": 1.654617378256718e-05,
      "loss": 0.0538,
      "step": 13450
    },
    {
      "epoch": 0.9207475105715455,
      "grad_norm": 0.0452602244913578,
      "learning_rate": 1.586413858955122e-05,
      "loss": 0.092,
      "step": 13500
    },
    {
      "epoch": 0.9241576865366253,
      "grad_norm": 6.238017559051514,
      "learning_rate": 1.5182103396535264e-05,
      "loss": 0.0758,
      "step": 13550
    },
    {
      "epoch": 0.9275678625017051,
      "grad_norm": 0.015908896923065186,
      "learning_rate": 1.4500068203519301e-05,
      "loss": 0.0645,
      "step": 13600
    },
    {
      "epoch": 0.9309780384667848,
      "grad_norm": 0.11583802849054337,
      "learning_rate": 1.3818033010503341e-05,
      "loss": 0.1134,
      "step": 13650
    },
    {
      "epoch": 0.9343882144318647,
      "grad_norm": 0.019968897104263306,
      "learning_rate": 1.3135997817487384e-05,
      "loss": 0.1307,
      "step": 13700
    },
    {
      "epoch": 0.9377983903969445,
      "grad_norm": 0.049400072544813156,
      "learning_rate": 1.2453962624471423e-05,
      "loss": 0.0516,
      "step": 13750
    },
    {
      "epoch": 0.9412085663620243,
      "grad_norm": 0.06546303629875183,
      "learning_rate": 1.1771927431455463e-05,
      "loss": 0.0843,
      "step": 13800
    },
    {
      "epoch": 0.9446187423271041,
      "grad_norm": 0.11155923455953598,
      "learning_rate": 1.1089892238439505e-05,
      "loss": 0.0682,
      "step": 13850
    },
    {
      "epoch": 0.9480289182921838,
      "grad_norm": 0.09243100881576538,
      "learning_rate": 1.0407857045423544e-05,
      "loss": 0.098,
      "step": 13900
    },
    {
      "epoch": 0.9514390942572637,
      "grad_norm": 0.31381210684776306,
      "learning_rate": 9.725821852407585e-06,
      "loss": 0.0865,
      "step": 13950
    },
    {
      "epoch": 0.9548492702223434,
      "grad_norm": 0.06926140189170837,
      "learning_rate": 9.043786659391625e-06,
      "loss": 0.0664,
      "step": 14000
    },
    {
      "epoch": 0.9582594461874233,
      "grad_norm": 0.2936329245567322,
      "learning_rate": 8.361751466375666e-06,
      "loss": 0.0864,
      "step": 14050
    },
    {
      "epoch": 0.9616696221525031,
      "grad_norm": 0.14738167822360992,
      "learning_rate": 7.679716273359706e-06,
      "loss": 0.1027,
      "step": 14100
    },
    {
      "epoch": 0.9650797981175828,
      "grad_norm": 1.7564151287078857,
      "learning_rate": 6.997681080343746e-06,
      "loss": 0.0392,
      "step": 14150
    },
    {
      "epoch": 0.9684899740826627,
      "grad_norm": 0.17695492506027222,
      "learning_rate": 6.315645887327787e-06,
      "loss": 0.0779,
      "step": 14200
    },
    {
      "epoch": 0.9719001500477424,
      "grad_norm": 4.989443302154541,
      "learning_rate": 5.633610694311827e-06,
      "loss": 0.1163,
      "step": 14250
    },
    {
      "epoch": 0.9753103260128223,
      "grad_norm": 4.426638126373291,
      "learning_rate": 4.951575501295867e-06,
      "loss": 0.0852,
      "step": 14300
    },
    {
      "epoch": 0.9787205019779021,
      "grad_norm": 0.126810684800148,
      "learning_rate": 4.269540308279908e-06,
      "loss": 0.147,
      "step": 14350
    },
    {
      "epoch": 0.9821306779429818,
      "grad_norm": 0.029765645042061806,
      "learning_rate": 3.5875051152639477e-06,
      "loss": 0.0698,
      "step": 14400
    },
    {
      "epoch": 0.9855408539080617,
      "grad_norm": 0.6099611520767212,
      "learning_rate": 2.9054699222479883e-06,
      "loss": 0.1316,
      "step": 14450
    },
    {
      "epoch": 0.9889510298731414,
      "grad_norm": 4.458786964416504,
      "learning_rate": 2.2234347292320284e-06,
      "loss": 0.1167,
      "step": 14500
    },
    {
      "epoch": 0.9923612058382213,
      "grad_norm": 2.6417105197906494,
      "learning_rate": 1.5413995362160688e-06,
      "loss": 0.1159,
      "step": 14550
    },
    {
      "epoch": 0.995771381803301,
      "grad_norm": 0.07720689475536346,
      "learning_rate": 8.593643432001091e-07,
      "loss": 0.1134,
      "step": 14600
    },
    {
      "epoch": 0.9991815577683808,
      "grad_norm": 0.9398098587989807,
      "learning_rate": 1.7732915018414952e-07,
      "loss": 0.0957,
      "step": 14650
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9815084784777104,
      "eval_loss": 0.07698259502649307,
      "eval_runtime": 111.8302,
      "eval_samples_per_second": 116.543,
      "eval_steps_per_second": 7.288,
      "step": 14662
    }
  ],
  "logging_steps": 50,
  "max_steps": 14662,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4150480728754496e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
